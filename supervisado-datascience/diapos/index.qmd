---
title: "Aprendizaje Supervisado I"
subtitle: "M√©todos de predicci√≥n lineal"
title-slide-attributes:
  data-background-image: img/data-science-2.jpeg
  data-background-size: cover
  data-background-opacity: "0.2"
author: "Grado en Ciencia de Datos Aplicada ‚Ä¢ curso 2024-2025"
affiliation: Facultad de Estudios Estad√≠sticos (UCM)
lang: es
language: custom_lang.yml
format: 
  revealjs:
    theme: [default, style.scss]
    chalkboard: true
    multiplex: true
    menu:
      side: left
      width: normal
    footer: "[<strong>Javier √Ålvarez Li√©bana</strong>](...) ‚Ä¢ Grado en Ciencia de Datos Aplicada (UCM) ‚Ä¢ curso 2024-2025"
    slide-number: c/t
execute:
  echo: true
---

# Empieza lo bueno...empieza la modelizaci√≥n

[**Vamos a juntar las piezas del puzzle para hacer ¬´magia¬ª**]{style="color:#444442;"}

```{r}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
```

---

## ¬°Buenas!

[**Correo**]{.hl-green}: **<javalv09@ucm.es>**. [**Despacho**]{.hl-green}: 722 (3¬™ planta).

::: columns
::: {.column width="30%"}
![](img/me.jpeg)
:::

::: {.column width="70%"}
::: incremental
-   [**Javier √Ålvarez Li√©bana**]{.hl-yellow}, de Carabanchel (Bajo).

-   Licenciado en Matem√°ticas (UCM). [**Doctorado en estad√≠stica**]{.hl-yellow} (UGR).

-   Encargado de la [**visualizaci√≥n y an√°lisis de datos covid**]{.hl-yellow} del Principado de Asturias (2021-2022).

-   Miembro de la [**Sociedad Espa√±ola de Estad√≠stica e IO**]{.hl-yellow} y la [**Real Sociedad Matem√°tica Espa√±ola**]{.hl-yellow}.
:::
:::
:::

. . .

Actualmente, [**investigador y docente en la Facultad de Estad√≠stica de la UCM**]{.hl-yellow}. Divulgando por [**Twitter**](https://twitter.com/dadosdelaplace) e [**Instagram**](https://instagram.com/javieralvarezliebana)


---

## Objetivos

::: columns
::: {.column width="37%"}
![](https://assets-global.website-files.com/6092cb6b4ac959f39728dd26/6188a97fa499b5fbfe410417_target%20(1).png)
:::

::: {.column width="63%"}
::: incremental
- Empezar a [**relacionar asignaturas**]{.hl-yellow} como matem√°ticas, inferencia y R.

- Aprender los fundamentos del [**aprendizaje estad√≠stico**]{.hl-yellow} (ahora llamado Machine Learning o data science)

- Pasar de los descriptivo a lo predictivo: [**construir nuestros primeros modelos**]{.hl-yellow}

- Entender en profundidad el contexto de la [**predicci√≥n lineal**]{.hl-yellow}.


:::
:::
:::

---

## Evaluaci√≥n

-   [**Asistencia**]{.hl-yellow}. Se [**valorar√° muy positivamente**]{.hl-purple} la participaci√≥n. 

. . .

- [**Evaluaci√≥n continua**]{.hl-yellow}: 1 **examen te√≥rico a papel** (30%) y **3 entregas R en clase** (10%-25%-35%).
  
. . .

- [**Examen final**]{.hl-yellow}:
  - [**M√°s de 7 de continua**]{.hl-purple} -> podr√°s decidir **peso del final entre 0% y 100%**.
  - [**Entre 6 y 7 de continua**]{.hl-purple} -> decidir **peso del final entre un 30% y un 100%**.
  - [**Entre 5 y 6 de continua**]{.hl-purple} ->**peso del final entre un 50% y un 100%**.
  - [**Entre 3.5 y 5 de continua**]{.hl-purple} -> **peso del final entre un 70% y un 100%**.
  - [**Por debajo de 3.5 de continua**]{.hl-purple} -> **peso del final del 100%**.
  
Para que haga [**media el final**]{.hl-red} debes de sacar m√°s de un 3 sobre 10.

---

## Planificaci√≥n


* [**Entrega I (10%)**]{.hl-yellow}: 6 de febrero.

* [**Entrega II (25%)**]{.hl-yellow}: 15 o 22 de abril.

* [**Te√≥rico con papel y boli (30%)**]{.hl-yellow}: 8 de mayo.

* [**Entrega III (35%)**]{.hl-yellow}: 13 de mayo.


---

## Materiales

* [**Diapositivas**]{.hl-yellow}: las diapositivas que usaremos en el aula a lo largo del curso, estructuradas por clases, estar√°n disponibles y actualizadas en **<https://javieralvarezliebana.es/docencia-R-supervisado-2324/diapos>** 

En el men√∫ de las diapositivas (abajo a la izquierda) tienes una [**opci√≥n para descargarlas en pdf**]{.hl-yellow} en `Tools` (consejo: no lo hagas hasta el final del curso ya que ir√°n modific√°ndose)
  
&nbsp;

* [**Material**]{.hl-yellow}: [**scripts de cada tema**](https://github.com/dadosdelaplace/docencia-R-supervisado-2324/tree/main/material) y materiales extras

* [**Res√∫menes de paquetes**]{.hl-yellow}: [**chuletas de los paquetes**](https://github.com/dadosdelaplace/docencia-R-supervisado-2324/tree/main/fichas%20paquetes) en formato .pdf

---


## Requisitos

Para el curso los √∫nicos requisitos ser√°n:

1.  [**Conexi√≥n a internet**]{.hl-yellow} (para la descarga de algunos datos y paquetes).

2.  [**Instalar R y RStudio**]{.hl-yellow}: la descarga la haremos (gratuitamente) desde <https://cran.r-project.org/> y  <https://posit.co/download/rstudio-desktop/>

3. Se dar√°n por asumido conocimientos aprendidos de [**R base, tidyverse y ggplot**]{.hl-yellow}

4. Se dar√°n por asumido conocimientos aprendidos de [**Quarto, diapositivas en Quarto y Github**]{.hl-yellow}. Para las entregas [**SOLO SE VALORAR√Å**]{.hl-purple} la salida html correspondiente.

5. [**Recomendable**]{.hl-yellow}: saber usar la calculadora en modo estad√≠stico.


---

## Planificaci√≥n  {#planificacion}

::: column-screen-inset-right
::: {style="font-size:20px"}
|  CLASE | SEMANA | FECHAS | TOPIC | EJ. | WORKBOOK | ENTREGA | 
|:------:|:--------:|:--------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| [1](#clase-1) | S1 | 23 ene | Repaso descriptiva | [üíª](#tu-turno-1-1) [üíª](#tu-turno-1-2) [üíª](#tu-turno-1-3) | [üê£](#caso-practico-1-1) [üê£](#caso-practico-1-2) [üê£](#caso-practico-1-3) [üê£](#caso-practico-1-4)  |  | 
| [2](#clase-2) | S2 | 28 ene | Medidas de asociaci√≥n | ... |  |  | 
| [3](#clase-3) | S2 | 30 ene | An√°lisis de la varianza | ... |  |  | 
| [4](#clase-4) | S3 | 4 feb | An√°lisis de la varianza | ... |  |  | 
| [5](#clase-5) | S3 | 6 feb | Entrega I  | ... |  | [üéØ 10%](#clase-5)  | 
:::
:::



# Clase 1: repaso {#clase-1}

[**Objetivo de la predicci√≥n lineal. Concepto de linealidad. Repaso de estad√≠stica descriptiva (23 de enero de 2025)**]{style="color:#444442;"}



---

## ¬øQu√© es predecir?

En esta asignatura vamos a tratar principalmente lo que se conoce en el aprendizaje estad√≠stico como [**predicci√≥n (continua)**]{.hl-yellow}

. . .

Dada una [**variable objetivo (variable dependiente)**]{.hl-yellow}, y con la informaci√≥n aportada por un conjunto de [**variables predictoras (covariables)**]{.hl-yellow}, el objetivo ser√° obtener una estimaci√≥n/predicci√≥n lo ¬´mejor posible¬ª haciendo uso de un

&nbsp;


[**modelo supervisado**]{.hl-yellow} de [**predicci√≥n**]{.hl-purple} [**lineal**]{.hl-green} (conocido como regresi√≥n lineal)


---


## Ciencia de Datos


La [**ciencia de datos**]{.hl-yellow} es precisamente la rama que integra las matem√°ticas, la estad√≠stica, la probabilidad, el Machine Learning e incluso el Big Data

![](img/stats-ml.jpg)

---


## ¬øModelo supervisado?


[**modelo supervisado**]{.hl-yellow} de predicci√≥n lineal

&nbsp;

En esta asignatura veremos el modelo m√°s simple de lo que se conoce como [**aprendizaje estad√≠stico (Machine Learning)**]{.hl-yellow}, en concreto del conocido como [**aprendizaje supervisado**]{.hl-yellow}

![](img/ml.jpg)


---


## Aprendizaje ¬øsupervisado?

![](img/unsupervised-learning.jpg)

---

## Aprendizaje ¬øsupervisado?

En el campo del Machine Learning hay principalmente dos tipos de modelos:

:::: columns
::: {.column width="50%"}

* [**Aprendizaje supervisado**]{.hl-yellow}: tendremos dos tipos de variables, la [**variable dependiente (output/target)**]{.hl-yellow} que se quiere predecir/clasificar, normalmente denotada como $Y$, y las [**variables independientes (inputs) o explicativas o predictoras**]{.hl-yellow}, que contienen la informaci√≥n disponible. Ejemplos: regresi√≥n, knn, √°rboles, etc.
 

:::

::: {.column width="50%"}

![](img/supervised.jpg)
:::
::::

---

## Aprendizaje ¬øsupervisado?

En el campo del Machine Learning hay principalmente dos tipos de modelos:

:::: columns
::: {.column width="50%"}

* [**Aprendizaje no supervisado**]{.hl-yellow}: no existe la distinci√≥n entre target y variables explicativas ya que [**no tenemos etiquetados los datos**]{.hl-yellow}, no sabemos a priori la respuesta correcta. El aprendizaje no supervisado [**buscar√° patrones**]{.hl-yellow} basados en similitudes/diferencias. Ejemplos: PCA, clustering, redes neuronales, etc.

:::


::: {.column width="50%"}

![](img/unsupervised.jpg)

:::
::::

---

## Modelo predictivo

Dentro del marco de un [**modelo de predicci√≥n supervisada**]{.hl-yellow} tendr√° siempre la siguiente forma:

$$Y = f(\mathbf{X}) + \varepsilon = f\left(X_1, \ldots, X_p \right) + \varepsilon, \quad E \left[Y | \boldsymbol{X} = x \right] =f\left(X_1, \ldots, X_p \right) $$

* $\mathbf{X}$ ser√°n los [**datos**]{.hl-yellow}

* $f(\cdot)$ ser√° nuestro [**modelo**]{.hl-yellow}, es decir, el [**valor esperado de $Y$**]{.hl-yellow} (con la informaci√≥n que tenemos $\mathbf{X}$).

* $\mathbf{X} = \left(X_1, \ldots, X_p \right)$ ser√°n nuestras [**predictoras o variables independientes**]{.hl-yellow}

* $\varepsilon$ ser√° el [**error o ruido**]{.hl-yellow}, una [**variable aleatoria de media 0**]{.hl-yellow} $E \left[\varepsilon | \boldsymbol{X} = x \right] = 0$ (el error deber√≠a ser reducido a **algo aleatorio (irreducible)**, aunque en estad√≠stica SIEMPRE nos vamos a equivocar).



---


## Clasificaci√≥n vs predicci√≥n

modelo supervisado de [**predicci√≥n**]{.hl-purple} lineal

&nbsp;

La **regresi√≥n lineal** se enmarca dentro del [**predicci√≥n**]{.hl-purple} supervisada

* [**Predicci√≥n**]{.hl-purple}: la [**variable objetivo es una variable cuantitativa continua**]{.hl-purple} (por ejemplo, precio, glucosa, peso, etc).

* [**Clasificaci√≥n**]{.hl-purple}: la [**variable objetivo es una variable cualitativa**]{.hl-purple} (por ejemplo, especie de flor, ausencia/presencia de enfermedad, si/no, etc) o **cuantitativa discreta** (por ejemplo, n√∫mero de accidentes). La etiqueta tomar√° un valor dentro del conjunto de modalidades permitidas, pudiendo ser **binaria** (si/no) o **multiclase** (A, B, C, D).

&nbsp;

üìö Ver ¬´The elements of Statistical Learning¬ª (Hastie et al., 2008)

---

## ¬øQu√© es predecir?


modelo de [**predicci√≥n**]{.hl-purple} lineal


&nbsp;

Es importante que - de momento - distingamos dos conceptos:

* [**Estimaci√≥n**]{.hl-purple}: el modelo aprende de unos datos e intenta estimar dichos valores que ha usado.
* [**Predicci√≥n**]{.hl-purple}: el modelo aprende de unos datos e intenta estimar valores que el **modelo no conoce**.

M√°s adelante los llamaremos ¬´predicci√≥n en train¬ª y ¬´predicci√≥n en test¬ª

---

## ¬øQu√© es la linealidad?


modelo de predicci√≥n [**lineal**]{.hl-green}

&nbsp;

En matem√°ticas decimos que una funci√≥n $f(x)$ es [**lineal**]{.hl-green} cuando se cumple:

* [**Propiedad aditiva**]{.hl-green}: $f(x + y) = f(x) + f(y)$

* [**Propiedad homog√©nea**]{.hl-green}: $f(k*x) = k*f(x)$ (donde $k$ es una constante en $\mathbb{R}$).

Ambas se pueden resumir en $f(a*x + b*y) = a*f(x) + b*f(y)$

. . .

En estad√≠stica llamamos [**modelo de predicci√≥n lineal**]{.hl-yellow} a un modelo que usa la informaci√≥n de covariables $X_1, X_2, \ldots, X_p$, de manera que su informaci√≥n siempre [**se relacionen entre s√≠ con sumas y restas**]{.hl-yellow}.

- [**Ejemplos lineales**]{.hl-green}: $y = 2*x_1 - 3$ o  $y = 4 - \frac{x_1}{2} + 3*x_2$

- [**Ejemplos no lineales**]{.hl-red}: $y = 2*\frac{1}{x_1}$ o  $y = 4 - x_{1}^{2} - x_2$ o $y = ln(x_1) + cos(x_2)$



---


## Repaso descriptiva


La estad√≠stica descriptiva es una rama de la estad√≠stica que se dedica a [**recolectar, organizar, presentar y analizar un conjunto de datos**]{.hl-yellow} para describir las caracter√≠sticas y comportamientos de dicho conjunto.

&nbsp;

Adem√°s de para conocer y entender los datos es la fase en la que [**detectaremos errores e incongruencias**]{.hl-yellow}, teniendo muchas veces que hacer una [**depuraci√≥n de datos**]{.hl-yellow}

---

## Recolecci√≥n

La podemos hacer a trav√©s de **encuestas, experimentos, observaciones, registros**, etc. Lo m√°s importante en esta etapa es que los datos sean representativos del fen√≥meno o poblaci√≥n que se estudia. La rama de la estad√≠stica que se dedica a estudiar esta parte del an√°lisis se conoce como [**muestreo**]{.hl-yellow}, y es fundamental para evitar sesgos en la muestra.


![](https://sketchplanations.com/_next/image?url=https%3A%2F%2Fimages.prismic.io%2Fsketchplanations%2Ff2fdb7cb-f126-4897-ad78-4fd11c743172_SP%2B723%2B-%2BSampling%2Bbias.png%3Fauto%3Dcompress%2Cformat&w=828&q=75)

---

## Conceptos b√°sicos

En estad√≠stica es fundamental entender los conceptos de [**poblaci√≥n, muestra y variable**]{.hl-yellow}, ya que son la base para cualquier an√°lisis estad√≠stico.

. . .

-   [**Poblaci√≥n**]{.hl-yellow}

La poblaci√≥n es el **conjunto completo de elementos o individuos** sobre los cuales se desea obtener informaci√≥n. En la mayor√≠a de casos el acceso a la **totalidad de la poblaci√≥n es inviable** por motivos econ√≥micos, legales o √©ticos, as√≠ que en la mayor√≠a de situaciones las conclusiones deberemos sacarlas haciendo uso de una **muestra**.

. . .

**Ejemplo**: la diferencia entre censo y encuesta es que el primero recopila datos de todos los individuos de una poblaci√≥n, mientras que el segundo trata de estimarlos o inferirlos a partir de una muestra representativa de la misma.

---

## Conceptos b√°sicos

[**Muestra**]{.hl-yellow}: subconjunto de la poblaci√≥n que se selecciona para su an√°lisis con el fin de hacer inferencias o generalizaciones sobre la poblaci√≥n completa. La muestra debe ser **representativa de la poblaci√≥n**.

-   **Muestreo aleatorio simple**: cada miembro de la poblaci√≥n tiene la misma probabilidad de ser seleccionado.

-   **Muestreo estratificado**: la poblaci√≥n se divide en subgrupos (estratos) y se toma una muestra de cada uno.

-   **Muestreo (no aleatorio) sistem√°tico**: se selecciona cada n-√©simo miembro de la poblaci√≥n.

-   **Muestreo (no aleatorio) por cuotas**: se seleccionan aquellos individuos que cumplan ciertas condiciones.

-   **Muestreo por conveniencia**: se elige a los miembros que son m√°s f√°ciles de acceder, aunque este m√©todo puede introducir sesgos.

---

## Sesgos en el muestreo

![](img/sampling-bias.jpg)

. . .

[**Sesgo de selecci√≥n**]{.hl-yellow}: aparece cuando no se tiene en cuenta la forma en la que se han recogido los datos.

---


## Sesgos en el muestreo


![](img/dewey.jpg)

El ejemplo m√°s famoso es el caso [**¬´Dewey defeats Truman¬ª (Dewer derrota a Truman)**]{.hl-yellow}, el titular con el que abri√≥ el Chicago Tribune en 1948, el mismo d√≠a en el que Truman gan√≥ al rep√∫blicano Dewer en las elecciones de 1948: sin esperar a los resultados, se basaron en una encuesta telef√≥nica (sin contar con el sesgo que, en aquella √©poca, solo la clase alta ten√≠a tel√©fono).

---



## Sesgos en el muestreo

![](img/superviviente.jpg)

¬øD√≥nde reforzar√≠as los aviones?

---

## Sesgos en el muestreo

![](img/superviviente.jpg)



El [**sesgo del superviviente**]{.hl-yellow} (un tipo de sesgo de selecci√≥n) aparece cuando se toma una muestra de un fen√≥meno ignorando si los individuos elegidos tienen las mismas opciones respecto al mismo.


---


## Conceptos b√°sicos

[**Variable**]{.hl-yellow}: **cualquier caracter√≠stica o atributo** que puede tomar diferentes valores entre los individuos de la poblaci√≥n o muestra. Las variables pueden ser de varios tipos seg√∫n su naturaleza:

-   [**Cualitativas (o categ√≥ricas)**]{.hl-purple}: describen cualidades o categor√≠as. Ejemplos:

    -   Nominales: no tienen un orden intr√≠nseco (e.g., g√©nero, estado civil, religi√≥n, etc).
    -   Ordinales: tienen un orden intr√≠nseco (e.g., niveles de satisfacci√≥n, grado acad√©mico, sano-leve-grave, tramo etario, tramo de ingresos, etc).

---

## Conceptos b√°sicos

[**Variable**]{.hl-yellow}: **cualquier caracter√≠stica o atributo** que puede tomar diferentes valores entre los individuos de la poblaci√≥n o muestra. Las variables pueden ser de varios tipos seg√∫n su naturaleza:

-   [**Cuantitativas**]{.hl-purple}: describen cantidades y pueden ser medidas num√©ricamente. Ejemplos:

    -   Discretas finitas: toman valores finitos (e.g., n√∫mero de hijos, n√∫mero de visitas al m√©dico, escala de dolor).
    -   Discretas infinitas: toman valores infinitos (o que se podr√≠an considerar como tal) pero podemos enumerarlas y sabemos siempre el siguiente elemento (e.g., n√∫mero de pelos de nuestra cabellera, n√∫mero de personas que pueden entrar en una tienda en un periodo dado).
    -   Continuas: pueden tomar cualquier valor dentro de un rango (e.g., altura, peso, tiempo de espera).

---

## Conceptos b√°sicos

[**Modalidades**]{.hl-yellow}: uno de los **posibles valores** que toma una **variable dentro de una muestra**. El **conjunto de modalidades posibles** que podr√≠a haber tomado (en tu poblaci√≥n) se suele conocer tambi√©n como soporte. Algunos ejemplos en funci√≥n del tipo de variables son:

-  **Cualitativa nominal (color de ojos)**: negro, azul y marr√≥n (3 modalidades en esa muestra de un espectro de colores m√°s amplio que podr√≠amos tener como soporte).

- **Cualitativa ordinal (estado del paciente)**: sano, leve y grave (3 modalidades en esa muestra de un conjunto de opciones - por ejemplo, sano, leve, grave, UCI, fallecido - que podr√≠amos tener).


---

## Repaso: continua vs discreta

![](img/vitro-fuego-discretas.jpg)



---

## Repaso: medidas de centralizaci√≥n

* [**Media**]{.hl-yellow}: dada una muestra $\boldsymbol{x} =\left(x_1, \ldots, x_n \right)$, la media muestral $\overline{x}$ se define como la **suma de todos los valores dividida por el tama√±o muestral**

$$\overline{x} = \frac{1}{n} \sum_{i=1}^{n} x_i$$

. . .

[**Geom√©tricamente**]{.hl-purple}: es el **valor ¬´m√°s cercano¬ª de todos los datos a la vez** (minimiza las distancias al cuadrado)

---

## Media muestral


[**VENTAJAS**]{.hl-green}

* F√°cil de calcular y entender
* F√°cil y eficiente de programar
* Siempre existe (para cuantitativas)

. . .

[**DESVENTAJAS**]{.hl-red}

* No es un valor de los datos (la media de {1, 2, 3, 4} es 2.5)
* **Poco robusta** (valores at√≠picos le afectan mucho)
* Solo se puede definir para variables cuantitativas


---

## Repaso: medidas de centralizaci√≥n

* [**Mediana**]{.hl-yellow}: dada una muestra $\boldsymbol{x} =\left(x_1, \ldots, x_n \right)$, la mediana muestral se define como el **valor que es mayor o igual que al menos el 50%**, y menor igual que al menos el 50% de los datos

$$Me_{x} = \arg \min_{x_i} \left\lbrace F_i > 0.5 \right\rbrace, \quad Me_x = e_{i-1} + \frac{0.5 - F_{i-1}}{F_i - F_{i-1} }a_i$$

La mediana es el [**valor de en medio**]{.hl-purple} si ordenamos los datos (y si se pueden ordenar...)

---

## Mediana muestral


[**VENTAJAS**]{.hl-green}

* Suele ser un valor de la muestra
* Un poco m√°s robusta que la media


. . .

[**DESVENTAJAS**]{.hl-red}

* Muy ineficiente (requiere un algoritmo de ordenaci√≥n)
* Solo definida para  cuantitativas o cualitativas ordinales

---


## Repaso: medidas de centralizaci√≥n

* [**Moda**]{.hl-yellow}: dada una muestra $\boldsymbol{x} =\left(x_1, \ldots, x_n \right)$, la moda muestral se define como el **valor o valores m√°s repetidos** (en caso de que existan).

$$Mo_x = \arg \max_{x_i} f_i, \quad Mo_x = e_{i-1} + \frac{d_i - d_{i-1}}{\left(d_i - d_{i-1} \right) + \left(d_i - d_{i+1} \right)}a_i$$


. . .

[**Gr√°ficamente**]{.hl-purple}: representa el ¬´pico¬ª de un diagrama de barras o un histograma

---

## Moda muestral


[**VENTAJAS**]{.hl-green}

* Es un valor de la muestra
* Muy robusta
* **Se puede calcular para cualquier** cuanti o cuali



. . .

[**DESVENTAJAS**]{.hl-red}

* No siempre existe (amodal) y pueden existir varias (bimodal, trimodal, etc)
* Poco usada en inferencia


---

## Repaso: medidas de centralizaci√≥n

![](img/ine-salarios-oculto.jpg)

**¬øCu√°l es la mediana, la media y la moda?**

---

## Repaso: medidas de centralizaci√≥n

![](img/ine-salarios.jpg)

---

## Repaso: medidas de dispersi√≥n

![](img/iker-jimenez.jpg)

¬øQu√© tiene que ver la imagen con la dispersi√≥n?


---

## Repaso: medidas de dispersi√≥n

![](img/extremos.jpg)

El cambio clim√°tico no solo es porque aumente la [**temperatura media (centralizaci√≥n)**]{.hl-yellow} sino por la aparici√≥n cada vez m√°s frecuente de fen√≥menos extremos 


Aumento de la [**variabilidad**]{.hl-yellow} ‚Üí aumento de la [**DISPERSI√ìN**]{.hl-yellow}

---

## Repaso: medidas de dispersi√≥n

[**¬øC√≥mo medir lo que se alejan los datos de la media?**]{.hl-yellow}

. . .

![](img/primera-idea-varianza.jpg)

Una **primera idea** podr√≠a ser [**medir la distancia de cada dato al centro**]{.hl-yellow}, es decir, restar cada dato de la media, y despu√©s realizar su promedio.

---

![](img/wait-for-it.jpg)

---

## Repaso: medidas de dispersi√≥n

Imagina que tenemos la siguiente muestra $X = \left\lbrace -5, -3, -1, 0, 1, 3, 5 \right\rbrace$.

**¬øCu√°nto vale la media?**

. . .

La media vale 0 y la distancia a ella es...la propia muestra $\left\lbrace -5, -3, -1, 0, 1, 3, 5 \right\rbrace$. **¬øCu√°l es el promedio de dichas distancias?**

. . .

Pues...de nuevo vale 0.

. . .

Si la dispersi√≥n es 0...[**¬øno hay dispersi√≥n?**]{.hl-red} ¬øNo deber√≠a de dar 0 solo cuando los datos sean constantes?

---

## Repaso: medidas de dispersi√≥n

Para **evitar que se cancelen** los signos lo que haremos ser√° calcular el [**promedio PERO de las distancias al cuadrado**]{.hl-yellow}, la conocida como [**varianza**]{.hl-yellow}

$$s_{x}^{2} = \frac{1}{n} \sum_{i=1}^{n} \left(x_i - \overline{x} \right)^2 = \overline{x^2} - \overline{x}^2 $$

. . .


::: callout-warning
# Cuidado

Tomar el valor absoluto (para evitar que se cancelen los signos) suele ser una mala idea en matem√°ticas (no es derivable como funci√≥n).
:::

---

## Repaso: medidas de dispersi√≥n


[**Problema**]{.hl-red}: si los datos est√°n en metros, la varianza estar√° en...metros cuadrados


. . .

:::: columns
::: {.column width="50%"}

¬øTiene sentido medir la dispersi√≥n de nuestra estatura en baldosas?

:::

::: {.column width="50%"}

![](img/albert-rivera.jpg)
:::

::::

---

## Repaso: medidas de dispersi√≥n

Para tener una [**medida de dispersi√≥n en las unidades de los datos**]{.hl-yellow} calcularemos la [**desviaci√≥n t√≠pica**]{.hl-yellow}, como la ra√≠z cuadrada de la varianza

$$s_{x} = \sqrt{s_{x}^{2}} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} \left(x_i - \overline{x} \right)^2} = \sqrt{\overline{x^2} - \overline{x}^2}$$


---

## Repaso: medidas de dispersi√≥n

Todav√≠a tenemos un peque√±o problema.

Imagina que queremos **comparar la dispersi√≥n de dos conjuntos** de datos, estaturas de personas y di√°metros de n√∫cleos de c√©lulas. Y Supongamos que las medias son 170 cm y 5 micr√≥metros, y la desviaci√≥n t√≠pica de 1 cm y 1.5 micr√≥metros.

[**¬øQu√© conjunto de datos es m√°s disperso?**]{.hl-yellow}

. . .

Para tener una  **medida de dispersi√≥n adimensional** definiremos el [**coeficiente de variaci√≥n**]{.hl-yellow} 

$$CV_{x} = \frac{s_{x}}{\left| \overline{x} \right|}$$

---

## Repaso: medidas de localizaci√≥n

Las [**medidas de posici√≥n o localizaci√≥n**]{.hl-yellow} nos localizan los datos, siendo valores que **nos dividen un conjunto ordenado** en subconjuntos del mismo tama√±o (ejemplo: mediana es percentil 50).

* **Percentil**: valores $P_{\alpha}$ del conjunto ordenado que dejan por debajo, al menos, el $\alpha$% de datos y $\alpha$% por encima.       
* **Decil**: valores $D_{\alpha}$ que dividen los datos en 10 partes iguales.

* **Cuartil**: valores $C_{\alpha}$ o $q_{\alpha}$ que dividen los datos en 4 partes iguales.

---

## Repaso: covarianza y correlaci√≥n

[**¬øQu√© es en realidad la varianza?**]{.hl-yellow}

. . .

La [**varianza es el promedio de las desviaciones al cuadrado**]{.hl-yellow} (respecto a la media), apareciendo dos veces dicha desviaci√≥n: puede ser entendida como una [**medida que cuantifica la relaci√≥n de una variable CONSIGO MISMA**]{.hl-yellow}

. . .

¬øY si qui√©semos medir la [**RELACI√ìN/ASOCIACI√ìN de una variable X respecto a otra variable Y (en lugar de consigo misma)**]{.hl-yellow}?


---

## Repaso: covarianza y correlaci√≥n

$$s_{x}^{2} = \frac{1}{n} \sum_{i=1}^{n} \left(x_i - \overline{x} \right)^2 = \overline{x^2} - \overline{x}^2 \quad \text{(varianza)}$$


La idea detr√°s de la [**covarianza**]{.hl-yellow} es justo esa: sustituir una de esas desviaciones de la X por la desviaci√≥n de la Y.


$$s_{xy} = \frac{1}{n} \sum_{i=1}^{n} \left(x_i - \overline{x} \right)\left(y_i - \overline{y} \right) = \overline{x*y} - \overline{x}*\overline{y}$$

---

## Repaso: covarianza y correlaci√≥n

Es importante entender algunas [**propiedades de la covarianza**]{.hl-yellow}

. . .

* [**Signo**]{.hl-purple}: la covarianza puede ser tanto positiva como negativa como 0: al eliminar el cuadrado de la varianza, ya no es necesario que sea positiva


. . .

* [**¬øQu√© cuantifica?**]{.hl-purple} La covarianza mide la [**asociaci√≥n LINEAL**]{.hl-red} (en torno a una recta) entre dos variables [**CONTINUAS**]{.hl-red}

. . .

* [**¬øQu√© dice su signo?**]{.hl-purple} El signo de la covarianza nos indicar√° la [**direcci√≥n de la dependencia lineal**]{.hl-yellow}: si es positiva, la relaci√≥n ser√° creciente (cuando X crece, Y crece); si es negativa, la relaci√≥n ser√° decreciente (cuando X crece, Y decrece)


---

## Repaso: covarianza y correlaci√≥n

Al igual que pasaba con la varianza, la [**covarianza depende de las unidades y magnitudes**]{.hl-yellow} de los datos, as√≠ que lo que haremos ser√° [**estandarizar la covarianza**]{.hl-yellow}. Definiremos la [**coeficiente correlaci√≥n lineal (de Pearson)**]{.hl-yellow} como la covarianza dividida entre el producto de las desviaciones t√≠picas (adimensional)


$$r_{xy} = \rho_{xy} = \frac{s_{xy}}{s_x s_y}$$

. . .

Tiene el [**mismo signo que la covarianza**]{.hl-yellow} (el denominador es siempre positivo) y sus [**valores siempre est√°n entre -1 y 1**]{.hl-yellow}

* m√°s cerca de -1 o 1 ‚Üí relaci√≥n lineal m√°s fuerte
* m√°s cerca de 0 ‚Üí ausencia de relaci√≥n **LINEAL**

---

## Repaso: covarianza y correlaci√≥n

![](img/correlaciones.jpg)


---

## üê£ Caso pr√°ctico I: anscombe {#caso-practico-1-1}

En el paquete `{datasets}` se encuentra el dataset conocido como [**cuarteto de Anscombe**]{.hl-yellow}, un dataset que cuenta con 4 conjuntos de datos.

```{r}
anscombe_tb <- as_tibble(datasets::anscombe)
anscombe_tb
```

&nbsp;

Intenta responder a las preguntas planteadas en el [**workbook**](https://javieralvarezliebana.quarto.pub/aprendizaje-supervisado/#caso-pr%C3%A1ctico-i-anscombe)


# Clase 2: asociaci√≥n entre variables {#clase-2}

[**Causalidad vs dependencia. Asociaci√≥n continua vs continua, cualitativa vs cualitativa (28 de enero de 2025)**]{style="color:#444442;"}


---


## Estad√≠stica bivariante

Todo lo que hemos hecho con una variable podemos hacerlo tambi√©n de manera [**bivariante**]{.hl-yellow} considerando dos variables.

. . .

Uno de los principales objetivos de la estad√≠stica bivariante es [**determinar si existe relaci√≥n o dependencia entre dos variables**]{.hl-yellow}, es decir, cuando un cambio en el valor de una de ellas se asocia a un cambio en el de la otra (una [**dependencia estad√≠stica no implica un efecto causal**]{.hl-red}).

. . .

La situaci√≥n contraria, es decir, la ausencia de relaci√≥n, se denomina [**independencia**]{.hl-yellow}.


---

## Tipos de an√°lisis posibles

Una primera aproximaci√≥n al estudio de dos variables ser√° [**clasificar el tipo de an√°lisis**]{.hl-yellow}

- [**Cuali vs cuali**]{.hl-yellow}:
  - **Resumen**: tablas de contigencia (frecuencia cruzada).
  - **Inferencia**: prueba $\chi^2$ de independencia o test de Fisher.
  - **Gr√°ficos**: barras apiladas, gofres, gr√°ficos de ¬´flujo¬ª.

---

## Tipos de an√°lisis posibles

Una primera aproximaci√≥n al estudio de dos variables ser√° [**clasificar el tipo de an√°lisis**]{.hl-yellow}


- [**Cuani vs cuanti**]{.hl-yellow}:
  - **Resumen**: covarianza y correlaci√≥n.
  - **Inferencia**: test de correlaci√≥n (relaci√≥n lineal) y test de Kolmogorov-Smirnov (¬øambas distribuciones son iguales?). Test de igualdad de medias o igualdad de varianzas
  - **Gr√°ficos**: diagrama de dispersi√≥n, correlogramas, heatmaps.

---

## Tipos de an√°lisis posibles

Una primera aproximaci√≥n al estudio de dos variables ser√° [**clasificar el tipo de an√°lisis**]{.hl-yellow}


- [**Cuanti vs cuali**]{.hl-yellow}:
  - **Resumen**: medidas de centralizaci√≥n/dispersi√≥n/posici√≥n de la cuanti desagregado por los grupos de la cuali.
  - **Inferencia**: ANOVA (una v√≠a, dos v√≠as, ...). Test de igualdad de medias o igualdad de varianzas (desagregada por grupos)
  - **Gr√°ficos**: boxplots, gr√°ficos de viol√≠n (desagregados por grupos)


---

## Repaso: inferencia

¬øPero que era eso de la [**inferencia estad√≠stica**]{.hl-yellow}? Es un conjunto de m√©todos y t√©cnicas que permite [**inferir conclusiones sobre una poblaci√≥n a partir de una muestra**]{.hl-yellow} de datos.

. . .

Su prop√≥sito es utilizar la informaci√≥n muestral para estimar caracter√≠sticas de la poblaci√≥n, probar hip√≥tesis y realizar predicciones, basado en el c√°lculo de [**estad√≠sticos**]{.hl-yellow}

-   [**Par√°metro**]{.hl-yellow}: medida que describe una caracter√≠stica de la **poblaci√≥n** (ejemplo: la media poblacional $\mu$ de la estatura de las mujeres en Espa√±a).

-   [**Estad√≠stico**]{.hl-yellow}: medida que describe una caracter√≠stica de la **muestra** (ejemplo: la media muestral $\overline{x}$ de un conjunto de 100 mujeres).

---

## Repaso: inferencia

Haciendo uso de **estad√≠sticos que aproximen una correcta estimaci√≥n de los par√°metros**, los [**contraste de hip√≥tesis**]{.hl-yellow} son procedimientos estad√≠sticos para [**tomar decisiones sobre la validez de una afirmaci√≥n acerca de una poblaci√≥n**]{.hl-yellow} en funci√≥n de los datos muestrales.

. . .

La idea es muy parecido a un **juicio**: con las pruebas (muestra) el jurado (estad√≠stico) deben decidir sobre tu culpabilidad real (poblaci√≥n), pudiendo ser declarado **culpable** o **no culpable**.

. . .

Este proceso implica formula

-   [**Hip√≥tesis nula** $H_0$]{.hl-yellow}: es una afirmaci√≥n generalmente representa una **posici√≥n de no efecto o no diferencia** (ejemplo: entras siendo no culpable a un juicio)

-   [**Hip√≥tesis alternativa** $H_0$]{.hl-yellow}: es una afirmaci√≥n que [**se acepta si se rechaza la hip√≥tesis nula**]{.hl-yellow}. Representa un efecto o diferencia (ejemplo: culpable)

---

## Repaso: inferencia

-   [**Hip√≥tesis nula** $H_0$]{.hl-yellow}: es una afirmaci√≥n generalmente representa una **posici√≥n de no efecto o no diferencia** (ejemplo: entras siendo no culpable a un juicio)

-   [**Hip√≥tesis alternativa** $H_1$]{.hl-yellow}: es una afirmaci√≥n que [**se acepta si se rechaza la hip√≥tesis nula**]{.hl-yellow}. Representa un efecto o diferencia (ejemplo: culpable)

La idea es similar a la del juicio: solo vamos a [**rechazar $H_0$ (es decir, aceptar $H_1$) si hay MUCHAS EVIDENCIAS en la muestra**]{.hl-yellow} (solo se condena culpable a una persona si hay muchas evidencias que demuestran su culpabilidad, pero el acusado no tiene que demostrar su inocencia).

. . .

Llamaremos [**nivel de significancia** $\alpha$]{.hl-yellow} a la probabilidad de [**rechazar la hip√≥tesis nula cuando es verdadera**]{.hl-red} (condenar a un inocente, conocido como **error tipo I**. Normalmente $\alpha = 0.05$ aunque se pueden usar otros valores como 0.01 o 0.10 (a decidir ANTES de realizar el contraste.)



---

## p valor

El conocido como [**p-valor**]{.hl-yellow} es uno de los conceptos m√°s importantes en estad√≠stica pero tambi√©n peor usados. Puedes ver toda una revisi√≥n de qu√© significa y qu√© no en <https://pmc.ncbi.nlm.nih.gov/articles/PMC4877414/>

. . .

Podemos definir el [**p-valor**]{.hl-yellow} como un valor continuo que nos mide la [**compatibilidad de los datos observados con el modelo e hip√≥tesis asumidas**]{.hl-yellow}: 1 indica compatibilidad perfecta y 0 incompatibilidad completa.

* [**No repesenta la probabilidad de que la hip√≥tesis nula sea cierta**]{.hl-red}: el propio p-valor se calcula ASUMIENDO que lo es.

* [**No representa la probabilidad de que, por azar, se produzca nada**]{.hl-red}

---

## Asociaci√≥n cuali vs cuali

Una vez visto conceptos b√°sicos de inferencia vamos a empezar por un [**an√°lisis bivariante de dos variables cualitativas**]{.hl-yellow}

. . .

El primer paso siempre ser√° intentar resumir la informaci√≥n mediante el uso de [**tablas de contigencia**]{.hl-yellow}, en este caso bidimensionales.

. . .

¬øC√≥mo lo har√≠as con **tidyverse**? ¬øY con **R base**?

---

## Tablas de contigencia

Vamos a tomar la base de datos `SatisfaccionPacientes.csv` que captura datos de una encuesta de satisfacci√≥n de pacientes en un hospital

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
datos
```

---

## Tablas de contigencia

Para calcular una [**tabla bidimensional de frecuencias**]{.hl-yellow} en tidyverse basta con **indicar dos variables en `count()`**

```{r}
datos |>
  count(genero, estado_civil)
```

---

## Tablas de contigencia

Lo habitual es mostrar esta tabla como una [**tabla con m filas y n columnas**]{.hl-yellow}, siendo $m$ el n√∫mero de modalidades distintas de la primera variable (en este caso $m=2$, femenino y masculino) y $n$ el n√∫mero de modalidades distintas de la segunda variable (en este caso $n = 4$). 

¬øC√≥mo hacer que la variable `estado_civil` pivote para pasar de estar en vertical a estar ¬´en horizontal¬ª? (echa un repaso a la parte de tidy data)

. . .

```{r}
datos |>
  count(genero, estado_civil) |> 
  pivot_wider(names_from = estado_civil, values_from = n)
```

---

## Tablas de contigencia


Esto se puede hacer **mucho m√°s sencillo de nuevo en `R base`** con `table()`


```{r}
table(datos$genero, datos$estado_civil)
```

---

## Tablas de contigencia


F√≠jate que ahora podemos [**normalizar las frecuencias de 3 formas**]{.hl-yellow}: respecto al total de los datos, por filas (`margin = 1`) o por columnas (`margin = 2`).

```{r}
prop.table(table(datos$genero, datos$estado_civil))
prop.table(table(datos$genero, datos$estado_civil), margin = 1)
prop.table(table(datos$genero, datos$estado_civil), margin = 2)

```

---

## Tablas de contigencia

Haciendo uso de las tablas anteriores intenta responder a las siguientes preguntas:

a) ¬øQu√© cantidad de pacientes mujeres est√°n solteras?

b) ¬øQu√© porcentaje, de entre los pacientes hombres, est√°n viudos?

c) ¬øQu√© porcentaje, de entre los que est√°n divorciados, son mujeres?

d) ¬øQu√© porcentaje (del total de pacientes) son hombres solteros?


```{r}
#| code-fold: true
# a) 22 mujeres
# b) 8.51%
# c) 57.89%
# d) 20%
```


---

## Tablas de contigencia

Puedes incluso visualizar dichas cantidades con `geom_tile()` indic√°ndole que el relleno dependa del conteo `n`

```{r}
datos |>
  count(genero, estado_civil) |>
  ggplot() +
  geom_tile(aes(x = genero, y = estado_civil, fill = n)) +
  theme_minimal()
```

---

## üíª Tu turno {#tu-turno-2-1}

[**Intenta realizar los siguientes ejercicios sin mirar las soluciones**]{style="color:#444442;"}

::: panel-tabset
### [**Ejercicio 1**]{.hl-yellow}

Para repasar lo aprendido vamos a poner todo en pr√°ctica con el dataset `SatisfaccionPacientes.csv`. 

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
```


üìù Aplica el c√≥digo que sea necesario para responder a estas preguntas. ¬øCu√°l es el tama√±o muestral? ¬øCu√°ntas variables tenemos? ¬øCu√°ntas modalidades tenemos en la variable `estado_civil` (y cuantas observaciones en cada una)?

```{r}
#| code-fold: true
#| eval: false
# Tama√±o muestral / n√∫mero de observaciones
n <- nrow(datos)

# N√∫mero de variables
p <- ncol(datos)

# ¬øQu√© modalidades tenemos?
datos |>  count(estado_civil)
```


### [**Ejercicio 2**]{.hl-yellow}

üìù Determina el tipo de variable (cuantitativa vs. cualitativa).

```{r}
#| code-fold: true
#| eval: false
# Variables cuantitativas: tiempo, grado satisfacci√≥n, n√∫mero de visitas
# Variables cualitativas: g√©nero, estado civil, estado salud
glimpse(datos)
```

### [**Ejercicio 3**]{.hl-yellow}

üìù  Obten tablas de frecuencias (absoluta y relativa) en el caso de las cualitativas NOMINALES. Con ella intenta responder a las preguntas: a) ¬øcu√°ntas mujeres hay? b) ¬øqu√© % de individuos est√°n casados?

```{r}
#| code-fold: true
#| eval: false
# no podemos calcular acumulados ya que genero es nominal
datos |>  count(genero) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs))
# Hay 53 mujeres

datos |> count(estado_civil) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs))
# Hay 26% personas casadas
```


### [**Ejercicio 4**]{.hl-yellow}

üìù Convierte de manera adecuada la variable `genero` y `estado_civil` a cualitativa nominal

```{r}
#| code-fold: true
datos <-
  datos |>
  mutate(estado_civil = factor(estado_civil),
         genero = factor(genero))
```

### [**Ejercicio 5**]{.hl-yellow}

üìù Calcula la media, mediana, rango intercuart√≠lico y desviaci√≥n t√≠pica de edad y tiempo de espera.

```{r}
#| code-fold: true
resumen <-
  datos |>
  summarise(media_edad = mean(edad), sd_edad = sd(edad), mediana_edad = median(edad),
           IQR_edad = quantile(edad, probs = 0.75) - quantile(edad, probs = 0.25),
           # tiempo espera
           media_tiempo_espera = mean(tiempo_espera), sd_tiempo_espera = sd(tiempo_espera),
           mediana_tiempo_espera = median(tiempo_espera),
           IQR_tiempo_espera = quantile(tiempo_espera, probs = 0.75) - quantile(tiempo_espera, probs = 0.25))
```

### [**Ejercicio 6**]{.hl-yellow}

üìù Repite el anterior ejercicio pero obteniendo las m√©tricas desagregadas por sexo.

```{r}
#| code-fold: true
resumen <-
  datos |>
  summarise(media_edad = mean(edad), sd_edad = sd(edad), mediana_edad = median(edad),
           IQR_edad = quantile(edad, probs = 0.75) - quantile(edad, probs = 0.25),
           # tiempo espera
           media_tiempo_espera = mean(tiempo_espera), sd_tiempo_espera = sd(tiempo_espera),
           mediana_tiempo_espera = median(tiempo_espera),
           IQR_tiempo_espera = quantile(tiempo_espera, probs = 0.75) - quantile(tiempo_espera, probs = 0.25),
          .by = genero)
```

### [**Ejercicio 7**]{.hl-yellow}

üìù Realiza un gr√°fico de viol√≠n para la variable `tiempo_espera` para cada g√©nero

```{r}
#| code-fold: true
#| eval: false
ggplot(datos) +
  geom_violin(aes(x = genero, y = tiempo_espera, fill = genero, color = genero),
              alpha = 0.7) +
  ggthemes::scale_color_colorblind() +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()
```

:::

---

## üê£ Caso pr√°ctico I: encuesta de satisfacci√≥n {#caso-practico-2-1}

Vamos a seguir poniendo en pr√°ctica lo aprendido el dataset `SatisfaccionPacientes.csv`

&nbsp;

Intenta responder a las preguntas planteadas en el [**workbook**](https://javieralvarezliebana.quarto.pub/aprendizaje-supervisado/#caso-pr%C3%A1ctico-i-encuesta-de-satisfacci%C3%B3n)


---

## Asociaci√≥n cuali vs cuali

Esas tablas de frecuencia ser√°n las que usen los [**diferentes contrastes de asociaci√≥n cuali vs cuali**]{.hl-yellow} para decidir si hay o no dependencia.

&nbsp;

El contraste m√°s conocido es la conocida como [**prueba de $\chi^2$ (chi-cuadrado)**]{.hl-yellow}: dada una tabla de contigencia entre dos cualitativas, el contraste [**compara dicha tabla con la que deber√≠amos obtener bajo la hip√≥tesis nula de independencia**]{.hl-yellow}

Vamos a hacerlo con nuestras variables `genero` y `estado_civil`

---

## Prueba chi-cuadrado

$$H_0:~\text{genero y estado civil son independientes}$$

$$H_1:~\text{genero y estado civil son dependientes}$$

```{r}
table(datos$genero, datos$estado_civil)
```

. . .

[**Si la hip√≥tesis nula fuese cierta**]{.hl-yellow}, ¬øqu√© esperar√≠amos?

---

## Prueba chi-cuadrado

1. Elegimos uno de los factores y calculamos su **proporci√≥n en la tabla general** (53% vs 47% en este caso)

```{r}
prop.table(table(datos$genero))
```

. . .

2. Calculamos la **tabla de contigencia**  de ambas variables obteniendo lo que denotaremos como [**frecuencias observadas $O_{ij}$**]{.hl-yellow}

```{r}
table(datos$genero, datos$estado_civil)
```

---

## Prueba chi-cuadrado


3. **Si ambas variables fuesen independientes**, en cada columna tendr√≠amos que tener **porcentajes parecidos a cuando lo hacemos sin desagregar** (53% mujeres y 47% hombres). Es decir, del total de casados (26) deber√≠amos tener $8.48$ mujeres y $7.52$ hombres; del total de divorciados (19) deber√≠amos tener $10.07$ mujeres y $8.93$ hombres; y as√≠ sucesivamente. Estas frecuencias las denotaremos como [**frecuencias esperadas $E_{ij}$**]{.hl-yellow}

$$E_{ij} = \frac{\text{suma fila i * suma fila j}}{\text{total}}$$


---

## Prueba chi-cuadrado


4. [**Resumimos lo que se desv√≠a una de otra**]{.hl-yellow} mediante el [**estad√≠stico chi-cuadrado**]{.hl-yellow}:

$$\begin{eqnarray}\chi^2 &=& \sum_{i,j} \frac{\left(O_{ij} - E_{ij} \right)^2}{E_{ij}} = \frac{(13.78 - 11)^2}{13.78} + \frac{(12.22 - 15)^2}{12.22} \nonumber \\
&+& \frac{(10.07 - 11)^2}{10.07} + \ldots + \frac{(6.11 - 4)^2}{6.11} = 2.75731\end{eqnarray}$$

. . .


5. Calculamos [**c√≥mo de extremo es el valor del estad√≠stico si la hip√≥tesis nula fuese cierta**]{.hl-yellow}, proporcion√°ndonos un **p-valor**.

---

## Prueba chi-cuadrado

Este proceso podemos hacerlo directamente aplicando `chisq.test()`, indic√°ndole las variables (o su tabla de frecuencias)

```{r}
contraste <- chisq.test(datos$genero, datos$estado_civil)
```

* `...$statistic`: tenemos guardado el valor del estad√≠stico

```{r}
contraste$statistic
```

* `...$observed`: tenemos guardada la tabla de frecuencias observada

```{r}
contraste$observed
```

---

## Prueba chi-cuadrado


* `...$expected`: tenemos guardada la tabla de frecuencias esperada

```{r}
contraste$expected
```

* `...$p.value`: tenemos guardado el p-valor.

```{r}
contraste$p.value
```

---

## Prueba chi-cuadrado


¬øC√≥mo [**interpretar el contraste**]{.hl-yellow}?

```{r}
contraste
```

Como $p.value = 0.4306 > \alpha = 0.05$, no podemos rechazar la hip√≥tesis nula: [**no hay evidencias suficientes en la muestra para concluir que haya dependencia**]{.hl-yellow}.

---

## Prueba de Fisher

Otra alternativa es el [**test exacto de Fisher**]{.hl-yellow}, una prueba estad√≠stica utilizada para [**determinar si hay una asociaci√≥n significativa entre dos variables cualitativas**]{.hl-yellow} especialmente √∫til cuando las frecuencias esperadas son bajas y tenemos dos grupos en cada cualitativa (la tabla de frecuencias es $2 \times 2$).

&nbsp;

Como **curiosidad** dicha prueba naci√≥ cuando Fisher trataba de comprobar si una compa√±era, Muriel Birstol, era capaz de detectar en un t√© con leche si se hab√≠a a√±adido primero el t√© o la leche en su taza (y del experiemnto del que naci√≥ la regla del $\alpha = 5%$).

. . .

Para aplicarlo nos basta con usar `fisher.test()`.

```{r}
fisher.test(datos$genero, datos$estado_civil)
```

---

## Prueba de Fisher

Como hemos dicho es especialmente √∫til cuando tenemos solo 2 modalidades en cada cualitativa ya que nos proporciona [**m√©tricas de asociaci√≥n**]{.hl-yellow}

Veamos un ejemplo con la tabla `placebo_medicamento.csv`

```{r}
datos_placebo <- read_csv(file = "./datos/placebo_medicamento.csv")
datos_placebo
```

---

## Prueba de Fisher


```{r}
fisher.test(datos_placebo$observado, datos_placebo$grupo_tratamiento)
```

Si te fijas ahora nos devuelve adem√°s un [**contraste de lo que se conoce como odds ratio (OR: raz√≥n de probabilidades)**]{.hl-yellow}

`alternative hypothesis: true odds ratio is not equal to 1`


---

## M√©tricas de asociaci√≥n

```{r}
table(datos_placebo$observado, datos_placebo$grupo_tratamiento)
```

La interpretaci√≥n de [**Odds ratio (OR)**]{.hl-yellow} es cuantificar la [**asociaci√≥n entre dos variables respecto a una asociaci√≥n esp√∫rea**]{.hl-yellow} ¬øCu√°nto [**mejoran los que tomaron medicamento respecto a una posible mejora basal**]{.hl-yellow} (aleatoria) del placebo?

* [**Ratio de mejora en tratados**]{.hl-purple}: $13/3 = 4.33333$
* [**Ratio de mejora en placebo**]{.hl-purple}: $6/11 = 0.54545$

$$OR = \frac{13/3}{6/11} = \frac{13*11}{6*3} = 7.94$$

Los pacientes sometidos a tratamiento mejoran 7.9 veces m√°s si el placebo mejorase por azar.

---

## M√©tricas de asociaci√≥n

```{r}
table(datos_placebo$observado, datos_placebo$grupo_tratamiento)
```

Otra de las m√©tricas habituales es la conocida como [**raz√≥n de prevalencias (Risk Ratio, RR)**]{.hl-yellow} que nos proporciona un [**ratio entre la probabilidad de prevalencia**]{.hl-yellow} de un evento en dos grupos.


* [**Prevalencia de mejora en tratados**]{.hl-purple}: $13/(3+13) = 0.8125$
* [**Prevalencia de mejora en placebo**]{.hl-purple}: $6/(11+6) = 0.35294$

$$RR = \frac{13/(3+13)}{6/(11+6)} = \frac{13*11}{6*3} = 2.30208$$
Los pacientes sometidos a tratamiento tienen m√°s del doble de ¬´riesgo¬ª de mejorar que los pacientes con placebo.

---

## M√©tricas de asociaci√≥n

Ambas m√©tricas podemos estimarlas tambi√©n con el paquete `{epitools}`

```{r}
library(epitools)
OR <- oddsratio(datos_placebo$observado, datos_placebo$grupo_tratamiento)
OR$measure
```

* Si $OR = 1$ no hay asociaci√≥n entre las variables.
* Si $OR > 1$ hay una asociaci√≥n positiva, es decir, la exposici√≥n est√° asociada con un mayor riesgo.
* Si $OR < 1$ hay una asociaci√≥n negativa, es decir, la exposici√≥n est√° asociada con un menor riesgo.


---

## M√©tricas de asociaci√≥n


```{r}
RR <- riskratio(datos_placebo$observado, datos_placebo$grupo_tratamiento)
RR$measure
```


* Si $RR = 1$ no hay diferencias en el riesgo entre los grupos.
* Si $RR > 1$ el grupo expuesto (en este caso medicado) tiene mayor riesgo (en este caso de mejorar)
* Si $RR < 1$ el grupo expuesto tiene menor riesgo.

---

## Gr√°ficos de barras

Volvamos al ejemplo de encuesta de satisfacci√≥n: vamos a intentar relacionar las dos variables cualitativas `genero` y `estado_civil` para **complementar el an√°lisis num√©rico realizado** (am√©n del `geom_tile()` que hemos hecho para visualizar la tabla de frecuencias)

. . .

Sabemos realizar un diagrama de barras de cada una por separado, [**¬øc√≥mo incluir la informaci√≥n de ambas con `geom_bar()`**]{.hl-yellow}

. . .

Piensa c√≥mo hacerlo recordando que `geom_bar()` solo admite una coordenada `x = ...` o `y = ...`. ¬øC√≥mo incluir la info de otra variable que no sea en `x` o `y`?

---

## Gr√°ficos de barras

```{r}
#| code-fold: true
ggplot(datos) +
  geom_bar(aes(x = estado_civil, fill = genero), alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  labs(x = "Estado civil", y = "Frec. absolutas",
       fill = "G√©nero") +
  theme_minimal()
```

---

## Gr√°ficos de barras

La funci√≥n `geom_bar()` nos permite jugar un poco con el tipo de barras, que por defecto las muestra `stacked` (apiladas). Dicho ajuste podemos **cambiarlo con el argumento `position`**: si `position = "dodge"` las muestra de [**manera agrupada una detr√°s de otra**]{.hl-yellow}.

```{r}
#| code-fold: true
ggplot(datos) +
  geom_bar(aes(x = estado_civil, fill = genero),
           position = "dodge", alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  labs(x = "Estado civil", y = "Frec. absolutas",
       fill = "G√©nero") +
  theme_minimal()
```

---

## Gr√°ficos de barras

La mejor opci√≥n para visualizar si hay asociaci√≥n es que **cada barra de estado civil representa el total y nos muestre el % de cada sexo** en cada una: si fuesen independientes, el reparto por sexo en cada barra deber√≠a ser similar. Lo haremos con `position = "fill"`

```{r}
#| code-fold: true
ggplot(datos) +
  geom_bar(aes(x = estado_civil, fill = genero),
           position = "fill", alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  labs(x = "Estado civil", y = "Frec. relativas",
       fill = "G√©nero") +
  theme_minimal()
```


---

## Gr√°ficos de barras

```{r}
#| code-fold: true
ggplot(datos) +
  geom_bar(aes(y = estado_civil, fill = genero),
           position = "fill", alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  labs(x = "Estado civil", y = "Frec. relativas",
       fill = "G√©nero") +
  theme_minimal()
```


---

## üíª Tu turno {#tu-turno-2-2}

[**Intenta realizar los siguientes ejercicios sin mirar las soluciones**]{style="color:#444442;"}

::: panel-tabset
### [**Ejercicio 1**]{.hl-yellow}

üìù Carga el fichero `placebo_medicamento_completo.csv` donde tenemos guardado los niveles de colesterol antes y despu√©s de un tratamiento: a 76 personas se les dio un medicamento para bajarlo y a 24 personas placebo.

```{r}
#| code-fold: true
datos <- read_csv(file = "./datos/placebo_medicamento_completo.csv")
```


### [**Ejercicio 2**]{.hl-yellow}

üìù A√±ade una nueva variable dicot√≥mica a los datos que nos guarde `mejora` si el paciente mejor√≥ tras el tratamiento y `no mejora` en caso negativo

```{r}
#| code-fold: true
datos <-
  datos |> 
  mutate("mejora" = if_else(colesterol_post <= colesterol_pre, "mejora",
                            "no mejora"))
```

### [**Ejercicio 3**]{.hl-yellow}

üìù Visualiza ambas variables (`mejora` y `tratamiento`) a la vez con un diagrama de barras de manera que podamos observar indicios de una posible independencia o dependencia entre ambas. Hazlo antes a papel y boli si lo necesitas

```{r}
#| code-fold: true
#| eval: false

# as√≠ pintar√≠amos en cada barra de tratamiento los mejora o no mejora
ggplot(datos) +
  geom_bar(aes(x = tratamiento, fill = mejora), alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()

# pero dado que tienes m√°s tratados que del grupo control
# no permite comparar bien as√≠ que igualamos las barras
# para que cada barra sea el 100% de su categor√≠a
ggplot(datos) +
  geom_bar(aes(x = tratamiento, fill = mejora), alpha = 0.6,
           position = "fill") +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()

# Parece evidente visualmente que hay una diferencia entre mejora y no mejora
# en cada barra
```

### [**Ejercicio 4**]{.hl-yellow}

üìù Calcula la tabla de frecuencias absoluta y relativa que consideres necesarias para responder a las siguientes preguntas:

a) ¬øCu√°ntas personas de las tratadas con medicamento no mejoraron?

b) ¬øQu√© de personas del total del estudio acabaron mejorando habiendo tomando placebo?

c) ¬øQu√© % de personas tom√≥ medicamentos entre los que no mejoraron?

d) ¬øQu√© % de personas de los que tomaron medicamento mejoraron?

```{r}
#| code-fold: true
#| eval: false
table(datos$tratamiento, datos$mejora)
prop.table(table(datos$tratamiento, datos$mejora))
prop.table(table(datos$tratamiento, datos$mejora), margin = 1)
prop.table(table(datos$tratamiento, datos$mejora), margin = 2)
# 9 personas de las tratadas con medicamento no mejoraron
# 9% del total de personas mejoraron y tomaron placebo
# 37% de los que no mejoraron hab√≠an tomado la medicaci√≥n
# 88.1% de los que tomaron medicamento mejoraron
```

### [**Ejercicio 5**]{.hl-yellow}

üìù Para confirmar y cuantificar las evidencias que ya tenemos, vamos a realizar un contraste de hip√≥tesis. Realiza la prueba de chi-cuadrado e interpreta el resultado con $\alpha = 0.05$.

```{r}
#| code-fold: true
#| eval: false
chisq.test(datos$tratamiento, datos$mejora)
# Dado que p-value = 1.654e-06 << alpha --> debemos rechazar la hip√≥tesis nula -->
# hay evidencias suficientes para afirmar que hay relaci√≥n de dependencia
```

### [**Ejercicio 6**]{.hl-yellow}


> Realiza la prueba de chi-cuadrado y Fisher e incluye los p-valores en una tabla resumen haciendo uso de tidyverse. Exporta a un `.csv` dicha tabla resumen

```{r}
#| code-fold: true
resumen_pvalores <-
  datos |> 
  summarise("sig_chisq" = chisq.test(datos$tratamiento, datos$mejora)$p.value,
            "sig_fisher" = fisher.test(datos$tratamiento, datos$mejora)$p.value)
write_csv(resumen_pvalores, file = "./datos/resumen_pvalores.csv")
```

### [**Ejercicio 7**]{.hl-yellow}

üìù Realiza la prueba de Fisher y mira la salida completa. Interpreta la salida, no solo del contraste sino de los odd ratio.

```{r}
#| code-fold: true
fisher.test(datos$tratamiento, datos$mejora)

# OR estimado es de 11.95 --> al ser mayor que 1 implica que
# hay una asociaci√≥n positiva entre las variables
# hay 12 veces m√°s opciones de que te baje el colesterol si tomas el
# medicamento respecto a una posible mejora aleatoria (porque s√≠).
```

:::

---


## üê£ Caso pr√°ctico II: bronquitis y tabaco {#caso-practico-2-2}

Vamos a cargar el archivo de datos `fumadores.csv` donde tenemos datos de 96 pacientes sobre s√≠ o fuman y quienes han desarrollado o no bronquitis.

```{r}
datos <- read_csv(file = "./datos/fumadores.csv")
datos
```

&nbsp;

Intenta responder a las preguntas planteadas en el [**workbook**](https://javieralvarezliebana.quarto.pub/aprendizaje-supervisado/#caso-pr%C3%A1ctico-ii-bronquitis-y-tabaco)


---


## üê£ Caso pr√°ctico III: salud mental {#caso-practico-2-3}

Esta la base de datos `datos_salud_mental.csv` tenemos informaci√≥n recopilada de 100 pacientes que acuden a un centro de salud mental. Se quiere realizar un estudio para ver el **impacto que tienen distintas caracter√≠sticas sobre la ansiedad y depresi√≥n** en estos 100 pacientes. Los datos incluyen una variedad de variables relacionadas con la salud mental, as√≠ como caracter√≠sticas demogr√°ficas y de estilo de vida.

```{r}
datos <-
  read_csv(file = "./datos/datos_salud_mental.csv") |> 
  janitor::clean_names()
```

&nbsp;

Intenta responder a las preguntas planteadas en el [**workbook**](https://javieralvarezliebana.quarto.pub/aprendizaje-supervisado/#caso-pr%C3%A1ctico-iii-salud-mental)


---

## Asociaci√≥n cuanti vs cuanti


Como dec√≠amos, la idea detr√°s de la [**covarianza**]{.hl-yellow} es una "varianza" entre dos variales (la varianza es una covarianza de una variable consigo misma), midiendo el **promedio de lo que se desv√≠a cada una respecto a su media**

$$s_{xy} = \frac{1}{n} \sum_{i=1}^{n} \left(x_i - \overline{x} \right)\left(y_i - \overline{y} \right) = \overline{x*y} - \overline{x}*\overline{y}$$

. . .

Para calcularla en `R` basta con usar la funci√≥n `cov()`

```{r}
starwars |> 
  drop_na(mass, height) |> 
  summarise(cov(mass, height))
```

---

## Correlaci√≥n lineal

Vamos a practicar una vez m√°s como [**hacerlo a mano con el siguiente ejercicio**]{.hl-yellow}.

---

## Correlaci√≥n lineal

En la tabla inferior se han recopilado (del 2013 al 2022) la **temperatura media en el mes de abril en Madrid (variable X, en ¬∫C)** y el **n√∫mero de d√≠as (variable Y) en el que el nivel de ozono super√≥ las 0.20 ppm (partes por mill√≥n)**

* ¬øCu√°l fue media de d√≠as en los que se super√≥ umbral de ozono de 0.20 ppm?
* ¬øCu√°l fue media de d√≠as en los que se super√≥ umbral de ozono en los a√±os que la temperatura media en marzo super√≥ los 17.4¬∫C?
* ¬øCu√°l es su covarianza?

![](img/tabla-ej-covarianza-sin-agrupar.png)

---


## Correlaci√≥n lineal

Repite el ejercicio con pocas l√≠neas de c√≥digo `R`

* ¬øCu√°l fue la media de d√≠as en los que se super√≥ el umbral de ozono de 0.20 ppm?
* ¬øCu√°l fue la media de d√≠as en los que se super√≥ el umbral de ozono en los a√±os que la temperatura media en marzo super√≥ los 17.4¬∫C?
* ¬øCu√°l es su covarianza?

![](img/tabla-ej-covarianza-sin-agrupar.png)


---


## Correlaci√≥n lineal
Realiza lo que consideres tanto a mano como en `R`

* ¬øExiste alguna **relaci√≥n de dependencia entre las variables**? ¬øDe qu√© tipo? ¬øC√≥mo de fuerte o d√©bil es dicha relaci√≥n? ¬øEn qu√© direcci√≥n es dicha relaci√≥n?


$$s_{xy} = \frac{1}{n} \sum_{i=1}^{n} \left(x_i - \overline{x} \right)\left(y_i - \overline{y} \right) = \overline{x*y} - \overline{x}*\overline{y}$$

$$r_{xy} = \rho_{xy} = \frac{s_{xy}}{s_x s_y}$$

---

## Correlaci√≥n lineal

No s√© si te has fijado qu√© sucede cuando intentamos [**calcular la covarianza/correlaci√≥n de varias variables**]{.hl-yellow}, por ejemplo vamos a calcular la (cuasi)covarianza de todas las variables num√©ricas de starwars.

. . .

```{r}
starwars |> 
  select(where(is.numeric)) |> 
  drop_na() |>
  cov()
```

. . .

Podemos usar la funci√≥n `cov()` sin m√°s, fuera de un resumen, obteniendo lo que se conoce como [**matriz de (cuasi)covarianzas**]{.hl-yellow} y que tendr√° un papel fundamental en estad√≠stica ya que contiene la informaci√≥n (= varianza) del dataset.

---

## Matriz de covarianzas


```{r}
starwars |> 
  select(where(is.numeric)) |> 
  drop_na() |>
  cov()
```

Adem√°s de ser [**sim√©trica**]{.hl-yellow}...¬øqu√© tenemos en la [**diagonal**]{.hl-yellow}?

. . .

La [**matriz de (cuasi)covarianzas**]{.hl-yellow} se denota como $\Sigma$ y sus elementos se define como $\Sigma_{ii} = s_{x_i}^{2}$ para la diagonal y $\Sigma_{ij} = \Sigma_{ji} = s_{x_i x_j}$ fuera de ella.

. . .

::: callout-important
## Importante

Recuerda que los softwares estad√≠sticos nos devuelven siempre la [**cuasi covarianza**]{.hl-purple}, dividido entre $n-1$ y no entre $n$. La cuasivarianza y la cuasicovarianza son los [**mejores estimadores muestrales (insesgados)**]{.hl-yellow} de los respectivos par√°metros poblaciones

:::

---

## Matriz de correlaciones

De la misma manera con `cor()` podemos [**calcular la matriz de correlaciones**]{.hl-yellow} (en este caso sin el `cuasi` ya que se cancelan denominadores)

. . .

```{r}
starwars |> 
  select(where(is.numeric)) |> 
  drop_na() |>
  cor()
```

. . .

La [**matriz de correlaciones**]{.hl-yellow} se denota como $R$ y sus elementos se define como $r_{ii} = 1$ para la diagonal y $r_{ij} = r_{x_ix_j}$ fuera de ella, y nos proporciona la dependencia lineal entre variables ya de manera **estandarizada**.

---

## Matriz de correlaciones

[**¬øSe te ocurre alguna manera de calcular la matriz de correlaciones a partir de la de covarianzas?**]{.hl-yellow}



---

## Correlaci√≥n vs dependencia


Podemos tener [**variables incorreladas**]{.hl-red}, con correlaci√≥n nula, pero que [**exista dependencia entre ellas**]{.hl-green}: la covarianza/correlaci√≥n [**SOLO CAPTURA relaciones lineales**]{.hl-yellow}, nada m√°s.

. . .

Veamos un ejemplo sencillo con $X = \left\lbrace -1, 0, 1 \right\rbrace$ y $Y = X^2 =  \left\lbrace 1, 0, 1 \right\rbrace$. 

* La media de ambas es nula
* La media del producto es la media de $XY = \left\lbrace -1, 0, 1 \right\rbrace$, que es de nuevo nula
* As√≠ la covarianza $\overline{x*y} - \overline{x}*\overline{y}$ es nula a pesar de tener la mayor dependencia posible (dependencia funcional)

---

## Correlaci√≥n vs dependencia

![](img/covarianza-no-lineal.png)

En relaciones no lineales como la de la imagen, la **correlaci√≥n estar√° cercana a cero** (ya que no hay relaci√≥n lineal) pero existe una [**dependencia**]{.hl-yellow}. Diremos que [**dos variables son dependientes entre s√≠**]{.hl-yellow} cuando existe un **patr√≥n num√©rico que las relaciona**

. . .

* [**Independencia implica incorrelaci√≥n**]{.hl-green}
* [**Incorrelaci√≥n NO implica independencia**]{.hl-red}

---

## Correlaci√≥n vs dependencia

![](img/escenarios-covarianza.png)

---


## Test de correlaciones

¬øPero c√≥mo saber que la correlaci√≥n observada es suficientemente peque√±a para considerarse incorreladas?

. . .

Con un [**contraste de correlaciones**]{.hl-yellow} haciendo uso de `cor.test()`


```{r}
cor.test(starwars$mass, starwars$height)
```


---

## Otras correlaciones

La [**correlaci√≥n de Pearson**]{.hl-yellow} asume que las [**variables est√°n distribuidas normalmente**]{.hl-green}, en caso de existir asociaci√≥n tienen una relaci√≥n lineal y no tienen valores at√≠picos.

. . .

Por ello existen dos alternativas: [**correlaci√≥n de Spearman**]{.hl-yellow} y [**correlaci√≥n de Kendall**]{.hl-yellow} 

---

## Correlaci√≥n de Spearman

El [**coeficiente de correlaci√≥n de Spearman**]{hl-yellow} cuantifica de manera no param√©trica la interdependencia entre dos variables aleatorias (tanto continuas como discretas). Cuantifica el [**grado de asociaci√≥n mon√≥tona entre dos variables ordinales o continuas**]{.hl-yellow} 

$$\rho =1-\frac{6\sum D^{2}}{n (n^{2}-1)}$$

donde $D$ es la diferencia entre los correspondientes estad√≠sticos de orden de $x - y$.

```{r}
starwars |> 
  select(where(is.numeric)) |> 
  drop_na() |> 
  cor(method = "spearman")
```


---

## Tau de Kendall


El [**coeficiente de correlaci√≥n de rango de Kendall**]{.hl-yellow} ($\tau$ de Kendall) cuantifica la [**asociaci√≥n ordinal de variables cualitativas**]{.hl-yellow} de manera no param√©trica. 

. . .

Dados $\left(x_1, y_1\right), \ldots, \left(x_n, y_n\right)$ un conjunto de observaciones, se dice  que $\left(x_{i},y_{i}\right)$ y $\left(x_{j},y_{j}\right)$ (con $i < j$) son un [**par concordante**]{.hl-yellow} si el orden de clasificaci√≥n coincide ($x_i < x_j,~y_i < y_j$ o bien $x_j < x_i,~y_j < y_i$) 

$$\tau =\frac{\text{n pares concordantes} - \text{n pares discordantes}}{n \choose 2}$$


---

## üíª Tu turno {#tu-turno-2-3}

[**Intenta realizar los siguientes ejercicios sin mirar las soluciones**]{style="color:#444442;"}

::: panel-tabset
### [**Ejercicio 1**]{.hl-yellow}

Vamos a tomar de nuevo nuestros datos de satisfacci√≥n de pacientes

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
datos
```

üìù Obt√©n la matriz de correlaciones haciendo uso de `cor()`. Luego haz uso de `correlate()` del paquete `{corrr}`

```{r}
#| code-fold: true
#| eval: false
datos |> 
  select(where(is.numeric)) |> 
  cor()

datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate()
```



### [**Ejercicio 2**]{.hl-yellow}

üìù Analiza y argumenta, en funci√≥n de los resultados anteriores, la asociaci√≥n entre `edad` y `grado_satisfaccion`, y entre `tiempo_espera` y `grado_satisfaccion`

```{r}
#| code-fold: true
# Vemos que por ejemplo `edad` no correla con `grado_satisfaccion` ($-0.0339$) pero `tiempo_espera` tiene una correlaci√≥n negativa ($-0.586$) con `grado_satisfaccion`.
```

### [**Ejercicio 3**]{.hl-yellow}

üìù Con el paquete `{corrplot}` visualiza la matriz de correlaciones

```{r}
#| code-fold: true
datos |> 
  select(where(is.numeric)) |> 
  cor() |> 
  corrplot::corrplot(method = "square")
```

### [**Ejercicio 4**]{.hl-yellow}

üìù Investiga el paquete `{GGally}` y a funci√≥n `ggpairs()` para visualizar las correlaciones de todas las variables (salvo `id`)

```{r}
#| code-fold: true
library(GGally)
ggpairs(datos |> select(-id)) +
  theme_minimal()

# cuali vs cuali: pictogramas (con rect√°ngulos)
# cuanti vs cuanti: scatter plot
# cuanti vs cuali: boxplot desagregados
# variable vs s√≠ misma: densidad
```

### [**Ejercicio 5**]{.hl-yellow}

üìù ¬øC√≥mo saber que la correlaci√≥n observada entre `edad` y `grado_satisfaccion` ($-0.0339$) es suficientemente peque√±a para considerarse incorreladas? ¬øC√≥mo saber si la correlaci√≥n entre `tiempo_espera` y `grado_satisfaccion` ($-0.586$) es suficientemente grande para considerar que es **significativa**?


```{r}
#| code-fold: true
#| eval: false
cor.test(datos$edad, datos$grado_satisfaccion)
cor.test(datos$tiempo_espera, datos$grado_satisfaccion)

# En uno el p-valor es bastante alto (**no rechazamos la hip√≥tesis nula de incorrelaci√≥n**) y en otro el p-valor es pr√°cticamente 0 (rechazamos la hip√≥tesis nula ->  **hay evidencias de correlaci√≥n significativa**).
```


:::



# Clase 3: an√°lisis de la varianza {#clase-3}

[**Asociaci√≥n cuali vs cuanti: an√°lisis de la varianza  (30 de enero de 2025)**]{style="color:#444442;"}

---

## ...

# Clase 4: an√°lisis de la varianza {#clase-4}

[**Asociaci√≥n cuali vs cuanti: an√°lisis de la varianza (4 de febrero de 2025)**]{style="color:#444442;"}

---

## ...





