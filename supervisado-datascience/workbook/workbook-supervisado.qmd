---
title: "Aprendizaje supervisado: modelos lineales"
subtitle: "Workbooks de la asignatura Aprendizaje Supervisado I"
author: "Javier Álvarez Liébana"
format:
  html:
    theme: [default, style.scss]
    toc: true
    toc-title: Índice
    toc-depth: 5
    toc-location: left
    number-sections: true
embed-resources: true
execute: 
  echo: true
---

```{r}
#| echo: false
setwd(dir = getwd())
```

* [**Diapositivas**]{.hl-yellow}: las diapositivas usadas en el aula a lo largo del curso, estructuradas por clases, estarán disponibles y actualizadas en **<https://javieralvarezliebana.es/docencia/supervisado-datascience/diapos>** 

* [**Datos**]{.hl-yellow}: [**acceso a Drive**](https://drive.google.com/drive/folders/1sim9xjM2qRcWrsMHrv_qRlkwDbGKOWN9?usp=sharing) y [**Github**](https://github.com/dadosdelaplace/docencia/tree/main/supervisado-datascience/workbook/datos)

## Clase 1

### 🐣 Caso práctico I: anscombe


En el paquete `{datasets}` se encuentra el dataset conocido como [**cuarteto de Anscombe**]{.hl-yellow}, un dataset que cuenta con 4 conjuntos de datos, cada uno de ellos cuenta con 11 observaciones de una variable x y otra y.

```{r}
#| message: false
#| warning: false
library(tidyverse)
anscombe_tb <- as_tibble(datasets::anscombe)
anscombe_tb
```


#### Pregunta 1


> Convierte a tidy data. Debes acabar con un dataset de 44 filas (11 valores para cada dataset) y 3 columnas (dataset, x e y)

```{r}
#| code-fold: true
anscombe_x <- 
  anscombe_tb |>
  pivot_longer(cols = x1:x4, names_to = "dataset", values_to = "x",
               names_prefix = "x") |>
  select(-contains("y"))

anscombe_y <- 
  anscombe_tb |>
  pivot_longer(cols = y1:y4, names_to = "dataset", values_to = "y",
               names_prefix = "y") |>
  select(-contains("x"))

anscombe_tidy <-
  anscombe_x |>
  mutate("y" = anscombe_y$y)
anscombe_tidy
```

#### Pregunta 2


> Calcula la media, varianza, desv. típica de x e y en cada dataset por separado

```{r}
#| code-fold: true
#| eval: false
anscombe_tidy |> 
  summarise(mean_x = mean(x), mean_y = mean(y),
            var_x = var(x), var_y = var(y),
            sd_x = sd(x), sd_y = sd(y),
            .by = dataset)
```

#### Pregunta 3


> Calcula la covarianza y correlación entre x e y en cada dataset

```{r}
#| code-fold: true
#| eval: false
anscombe_tidy |> 
  summarise(cov = cov(x, y), cor = cor(x, y),
            .by = dataset)
```


#### Pregunta 4


> Si te fijas todos los datasets tienen los mismos momentos muestrales ... ¿serán el mismo dataset desordenado? Visualiza los 4 datasets en el mismo gráfico mediante un diagrama de dispersión con su ajuste de regresión

```{r}
#| code-fold: true
ggplot(anscombe_tidy, aes(x = x, y = y, color = dataset)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE) +
  ggthemes::scale_color_colorblind() +
  facet_wrap(~dataset) +
  theme_minimal()
```

 Por suerte o por desgracia **no todo son matemáticas**: antes de pensar que modelo es mejor para nuestros datos, es importantísimo realizar un **análisis exploratorio** de los mismos (incluyendo visualización)


#### Pregunta 5


> Podemos visualizarlo de manera aún más extrema con el dataset `datasaurus_dozen` del paquete `{datasauRus}` (ver más en <https://www.research.autodesk.com/publications/same-stats-different-graphs/>). Calcula de nuevo, para cada dataset, media, varianza, desv. típica, covarianza y correlación

```{r}
#| code-fold: true
#| eval: false
library(datasauRus)
datasaurus_dozen |>
  summarise(mean_x = mean(x), mean_y = mean(y),
            var_x = var(x), var_y = var(y),
            sd_x = sd(x), sd_y = sd(y),
            cov = cov(x, y), cor = cor(x, y), .by = dataset)
```

#### Pregunta 6

> Elimina el dataset `"wide_lines"` y visualiza los 12 datasets restantes mediante un diagrama de dispersión (con su ajuste de regresión)

```{r}
#| code-fold: true
library(datasauRus)
ggplot(datasaurus_dozen |> filter(dataset != "wide_lines"),
       aes(x = x, y = y, color = dataset)) +
  geom_point(size = 2.5, alpha = 0.75) +
  geom_smooth(method = "lm", se = FALSE)  +
  facet_wrap(~dataset, ncol = 3) +
  theme_minimal()
```


## Clase 2

### 💻 Ejercicios resueltos: tablas de frecuencia


#### Ejercicio 1

Para repasar lo aprendido vamos a poner todo en práctica con el dataset `SatisfaccionPacientes.csv`. 

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
```


📝 Aplica el código que sea necesario para responder a estas preguntas. ¿Cuál es el tamaño muestral? ¿Cuántas variables tenemos? ¿Cuántas modalidades tenemos en la variable `estado_civil` (y cuantas observaciones en cada una)?

```{r}
# Tamaño muestral / número de observaciones
n <- nrow(datos)

# Número de variables
p <- ncol(datos)

# ¿Qué modalidades tenemos?
datos |>  count(estado_civil)
```


#### Ejercicio 2

📝 Determina el tipo de variable (cuantitativa vs. cualitativa).

```{r}
# Variables cuantitativas: tiempo, grado satisfacción, número de visitas
# Variables cualitativas: género, estado civil, estado salud
glimpse(datos)
```

#### Ejercicio 3

📝  Obten tablas de frecuencias (absoluta y relativa) en el caso de las cualitativas NOMINALES. Con ella intenta responder a las preguntas: a) ¿cuántas mujeres hay? b) ¿qué % de individuos están casados?

```{r}
# no podemos calcular acumulados ya que genero es nominal
datos |>  count(genero) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs))
# Hay 53 mujeres

datos |> count(estado_civil) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs))
# Hay 26% personas casadas
```


#### Ejercicio 4

📝 Convierte de manera adecuada la variable `genero` y `estado_civil` a cualitativa nominal

```{r}
datos <-
  datos |>
  mutate(estado_civil = factor(estado_civil),
         genero = factor(genero))
datos
```

#### Ejercicio 5

📝 Calcula la media, mediana, rango intercuartílico y desviación típica de edad y tiempo de espera.

```{r}
resumen <-
  datos |>
  summarise(media_edad = mean(edad), sd_edad = sd(edad), mediana_edad = median(edad),
           IQR_edad = quantile(edad, probs = 0.75) - quantile(edad, probs = 0.25),
           # tiempo espera
           media_tiempo_espera = mean(tiempo_espera), sd_tiempo_espera = sd(tiempo_espera),
           mediana_tiempo_espera = median(tiempo_espera),
           IQR_tiempo_espera = quantile(tiempo_espera, probs = 0.75) - quantile(tiempo_espera, probs = 0.25))
resumen
```

#### Ejercicio 6

📝 Repite el anterior ejercicio pero obteniendo las métricas desagregadas por sexo.

```{r}
resumen <-
  datos |>
  summarise(media_edad = mean(edad), sd_edad = sd(edad), mediana_edad = median(edad),
           IQR_edad = quantile(edad, probs = 0.75) - quantile(edad, probs = 0.25),
           # tiempo espera
           media_tiempo_espera = mean(tiempo_espera), sd_tiempo_espera = sd(tiempo_espera),
           mediana_tiempo_espera = median(tiempo_espera),
           IQR_tiempo_espera = quantile(tiempo_espera, probs = 0.75) - quantile(tiempo_espera, probs = 0.25),
          .by = genero)
resumen
```

#### Ejercicio 7

📝 Realiza un gráfico de violín para la variable `tiempo_espera` para cada género

```{r}
ggplot(datos) +
  geom_violin(aes(x = genero, y = tiempo_espera, fill = genero, color = genero),
              alpha = 0.7) +
  ggthemes::scale_color_colorblind() +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()
```

### 💻 Ejercicios resueltos: cuali vs cuali

#### Ejercicio 1

📝 Carga el fichero `placebo_medicamento_completo.csv` donde tenemos guardado los niveles de colesterol antes y después de un tratamiento: a 76 personas se les dio un medicamento para bajarlo y a 24 personas placebo.

```{r}
datos <- read_csv(file = "./datos/placebo_medicamento_completo.csv")
datos
```


#### Ejercicio 2

📝 Añade una nueva variable dicotómica a los datos que nos guarde `mejora` si el paciente mejoró tras el tratamiento y `no mejora` en caso negativo

```{r}
datos <-
  datos |> 
  mutate("mejora" = if_else(colesterol_post <= colesterol_pre, "mejora",
                            "no mejora"))
datos
```

#### Ejercicio 3

📝 Visualiza ambas variables (`mejora` y `tratamiento`) a la vez con un diagrama de barras de manera que podamos observar indicios de una posible independencia o dependencia entre ambas. Hazlo antes a papel y boli si lo necesitas

```{r}
# así pintaríamos en cada barra de tratamiento los mejora o no mejora
ggplot(datos) +
  geom_bar(aes(x = tratamiento, fill = mejora), alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()

# pero dado que tienes más tratados que del grupo control
# no permite comparar bien así que igualamos las barras
# para que cada barra sea el 100% de su categoría
ggplot(datos) +
  geom_bar(aes(x = tratamiento, fill = mejora), alpha = 0.6,
           position = "fill") +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()

# Parece evidente visualmente que hay una diferencia entre mejora y no mejora
# en cada barra
```

#### Ejercicio 4

📝 Calcula la tabla de frecuencias absoluta y relativa que consideres necesarias para responder a las siguientes preguntas:

a) ¿Cuántas personas de las tratadas con medicamento no mejoraron?

b) ¿Qué de personas del total del estudio acabaron mejorando habiendo tomando placebo?

c) ¿Qué % de personas tomó medicamentos entre los que no mejoraron?

d) ¿Qué % de personas de los que tomaron medicamento mejoraron?

```{r}
table(datos$tratamiento, datos$mejora)
prop.table(table(datos$tratamiento, datos$mejora))
prop.table(table(datos$tratamiento, datos$mejora), margin = 1)
prop.table(table(datos$tratamiento, datos$mejora), margin = 2)
# 9 personas de las tratadas con medicamento no mejoraron
# 9% del total de personas mejoraron y tomaron placebo
# 37% de los que no mejoraron habían tomado la medicación
# 88.1% de los que tomaron medicamento mejoraron
```

#### Ejercicio 5

📝 Para confirmar y cuantificar las evidencias que ya tenemos, vamos a realizar un contraste de hipótesis. Realiza la prueba de chi-cuadrado e interpreta el resultado con $\alpha = 0.05$.

```{r}
chisq.test(datos$tratamiento, datos$mejora)
# Dado que p-value = 1.654e-06 << alpha --> debemos rechazar la hipótesis nula -->
# hay evidencias suficientes para afirmar que hay relación de dependencia
```

#### Ejercicio 6


> Realiza la prueba de chi-cuadrado y Fisher e incluye los p-valores en una tabla resumen haciendo uso de tidyverse. Exporta a un `.csv` dicha tabla resumen

```{r}
resumen_pvalores <-
  datos |> 
  summarise("sig_chisq" = chisq.test(datos$tratamiento, datos$mejora)$p.value,
            "sig_fisher" = fisher.test(datos$tratamiento, datos$mejora)$p.value)
resumen_pvalores

write_csv(resumen_pvalores, file = "./datos/resumen_pvalores.csv")
```

#### Ejercicio 7

📝 Realiza la prueba de Fisher y mira la salida completa. Interpreta la salida, no solo del contraste sino de los odd ratio.

```{r}
fisher.test(datos$tratamiento, datos$mejora)

# OR estimado es de 11.95 --> al ser mayor que 1 implica que
# hay una asociación positiva entre las variables
# hay 12 veces más opciones de que te baje el colesterol si tomas el
# medicamento respecto a una posible mejora aleatoria (porque sí).
```

### 💻 Ejercicios resueltos: cuanti vs cuanti

#### Ejercicio 1

Vamos a tomar de nuevo nuestros datos de satisfacción de pacientes

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
datos
```

📝 Obtén la matriz de correlaciones de Pearson haciendo uso de `cor()`. Luego haz uso de `correlate()` del paquete `{corrr}`

```{r}
datos |> 
  select(where(is.numeric)) |> 
  cor()

datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate()
```

#### Ejercicio 2

📝 Obtén la matriz de correlaciones con kendall y spearman


```{r}
datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate(method = "spearman")

datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate(method = "kendall")
```

#### Ejercicio 3

📝 Analiza y argumenta, en función de los resultados anteriores, la asociación entre `edad` y `grado_satisfaccion`, y entre `tiempo_espera` y `grado_satisfaccion`

```{r}
# Vemos que por ejemplo `edad` no correla con `grado_satisfaccion` ($-0.0339$ según Pearson) pero `tiempo_espera` tiene una correlación negativa ($-0.586$ según Pearson) con `grado_satisfaccion`.
```

#### Ejercicio 4

📝 Con el paquete `{corrplot}` visualiza la matriz de correlaciones

```{r}
datos |> 
  select(where(is.numeric)) |> 
  cor() |> 
  corrplot::corrplot(method = "square")
```

#### Ejercicio 5

📝 Investiga el paquete `{GGally}` y a función `ggpairs()` para visualizar las correlaciones de todas las variables (salvo `id`)

```{r}
library(GGally)
ggpairs(datos |> select(-id)) +
  theme_minimal()

# cuali vs cuali: pictogramas (con rectángulos)
# cuanti vs cuanti: scatter plot
# cuanti vs cuali: boxplot desagregados
# variable vs sí misma: densidad
```

#### Ejercicio 6

📝 ¿Cómo saber que la correlación observada entre `edad` y `grado_satisfaccion` ($-0.0339$) es suficientemente pequeña para considerarse incorreladas? ¿Cómo saber si la correlación entre `tiempo_espera` y `grado_satisfaccion` ($-0.586$) es suficientemente grande para considerar que es **significativa**?


```{r}
cor.test(datos$edad, datos$grado_satisfaccion)
cor.test(datos$tiempo_espera, datos$grado_satisfaccion)

# En uno el p-valor es bastante alto (**no rechazamos la hipótesis nula de incorrelación**) y en otro el p-valor es prácticamente 0 (rechazamos la hipótesis nula ->  **hay evidencias de correlación significativa**).

# Ninguna de las 3 es normal así que lo apropiado sería
# contrastar la correlación de rango
performance::check_normality(datos$edad)
performance::check_normality(datos$grado_satisfaccion)
performance::check_normality(datos$tiempo_espera)
```



### 🐣 Caso práctico I: encuesta de satisfacción

Vamos a seguir poniendo en práctica lo aprendido el dataset `SatisfaccionPacientes.csv`

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names() |>
  mutate(estado_civil = factor(estado_civil),
         genero = factor(genero))
datos
```

#### Pregunta 1

> Convierte de manera adecuada la variable `estado_salud` a cualitativa ORDINAL

```{r}
#| code-fold: true
datos <-
  datos |>
  mutate(estado_salud =
           factor(estado_salud, levels = c("Malo", "Regular", "Bueno", "Excelente"),
                  ordered = TRUE))
```

#### Pregunta 2

> Haz uso de `table()` para calcular la tabla de frecuencias de `genero` y `estado_civil`

```{r}
#| code-fold: true
#| eval: false
table(datos$genero)
table(datos$estado_civil)
```

####  Pregunta 3

>  Calcula la tabla de frecuencias de las ORDINALES y piensa si ahora puedes añadir algo más a la tabla de frecuencias). Tras ello usa el código más sencillo para responder a: ¿cuántas personas tienen un estado de salud regular (o peor)?

```{r}
#| code-fold: true
#| eval: false
freq_estado_salud <-
  datos |> 
  count(estado_salud) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs),
         frecuencia_acum_abs = cumsum(frecuencia_abs),
         frecuencia_acum_rel = cumsum(frecuencia_rel))
# Se ve dentro de la tabla. Hay 44+15 = 59 personas con un estado de salud malo o regular. 
# Con código
datos |>
  count(estado_salud <= "Regular")
```

####  Pregunta 4

>  Si te fijas una de las modalidades es totalmente anecdótica (solo 1 Excelente). Sería conveniente recategorizar la categoría Excelente: siempre que detecte Excelente, lo debe recategorizar a Bueno (criterio general: las categorías deben contener al menos un 5% de los individuos de toda la muestra).

```{r}
#| code-fold: true
datos <- 
  datos |> 
  mutate(estado_salud  = if_else(estado_salud  == "Excelente", "Bueno", estado_salud),
         # ojo: hay que redefinir los niveles de la cualitativa
         # ya que ha dejado de ser factor (veremos un día el paquete forcats para esto)
         estado_salud =
           factor(estado_salud, levels = c("Malo", "Regular", "Bueno"),
                  ordered = TRUE))
```

####  Pregunta 5

>  Calcula la media, mediana, rango intercuartílico y desviación típica de grado de satisfacción desagregado por sexo.

```{r}
#| code-fold: true
resumen <-
  datos |>
  summarise(media_grado_satisfaccion = mean(grado_satisfaccion),
           sd_grado_satisfaccion = sd(grado_satisfaccion),
           mediana_grado_satisfaccion = median(grado_satisfaccion),
           IQR_grado_satisfaccion =
             quantile(grado_satisfaccion, probs = 0.75) -
             quantile(grado_satisfaccion, probs = 0.25),
           .by = genero)
```

####  Pregunta 6

> Exporta los resultados anteriores (`resumen`) en un archivo `resumen.csv`. En lugar de un `read_csv()` vamos a usar `write_csv(tabla, file = "ruta")`

```{r}
#| code-fold: true
# importado como csv
write_csv(resumen, file = "./resumen.csv")
```

#### Pregunta 7

> Crear un diagrama de barras para la variable género. ¿Cómo podríamos decirle que cada barra (es decir, para cada modalidad de género) sea de un color (de relleno)?


```{r}
#| code-fold: true
ggplot(datos) +
  # dentro de aes() para que dependa de la tabla
  geom_bar(aes(x = genero, fill = genero))
```


#### Pregunta 8

> Crear desde cero un diagrama de barras, con ajustes personalizados para la variable estado de salud

```{r}
#| code-fold: true
# Estado de salud (ahora el orden importa)
ggplot(datos) +
  geom_bar(aes(x = estado_salud, fill = estado_salud), alpha = 0.75) +
  ggthemes::scale_fill_colorblind() +
  labs(title = "Diagrama de barras de la variable estado salud", 
       x = "Categoría",  y = "Frecuencia absoluta",
       fill = "Categoría") +
  theme_minimal() 
```


Fíjate que si **no tuviésemos la variable como cuali ordinal, las barras van por orden alfabético**, no por jerarquía real

```{r}
ggplot(datos) +
  geom_bar(aes(x = as.character(estado_salud), fill = as.character(estado_salud)),
           alpha = 0.75) +
  ggthemes::scale_fill_colorblind() +
  labs(title = "Diagrama de barras de la variable estado salud", 
       x = "Categoría",  y = "Frecuencia absoluta",
       fill = "Categoría") +
  theme_minimal() 
```

#### Pregunta 9

> Crea el histograma inferior para las variable edad y tiempo de espera.

```{r}
#| code-fold: true
ggplot(datos) +
  geom_histogram(aes(x = edad), bins = 30, fill = "darkorange", alpha = 0.75) + 
  labs(title = "Histograma de edad", subtitle = "Bins = 30",
       x = "Valores", y = "Frecuencia absoluta") +
  theme_minimal()

ggplot(datos) +
  # Define el ancho de las barras y colores
  geom_histogram(aes(x = tiempo_espera), bins = 30, fill = "orchid", alpha = 0.75) + 
  labs(title = "Histograma de tiempo de espera", subtitle = "Bins = 30",
       x = "Valores", y = "Frecuencia absoluta") +
  theme_minimal()
```

#### Pregunta 10

> Crea el gráfico de densidad inferior para las variable edad y tiempo de espera.

```{r}
#| code-fold: true
ggplot(datos) +
  geom_density(aes(x = edad), color = "darkorange", 
               fill = "darkorange", alpha = 0.75) + 
  labs(title = "Gráfico de densidad de edad",
       x = "Valores", y = "Frecuencia relativa") +
  theme_minimal()

ggplot(datos) +
  geom_density(aes(x = tiempo_espera), color = "orchid", 
               fill = "orchid", alpha = 0.75) + 
  labs(title = "Gráfico de densidad de tiempo de espera",
       x = "Valores", y = "Frecuencia relativa") +
  theme_minimal()
```



#### Pregunta 11

> Realiza un boxplot para edad y un boxplot para numero de visitas PERO por género (dos variables, piensa cómo)

```{r}
#| code-fold: true
ggplot(datos) +
  geom_boxplot(aes(y = edad), fill = "lightblue", alpha = 0.75) +  
  labs(title = "Boxplot de edad",  y = "Edad") +
  theme_minimal()

ggplot(datos) +
  geom_boxplot(aes(x = genero, y = tiempo_espera, fill = genero),
               alpha = 0.75) +
  labs(title = "Boxplot de tiempo de espera por género", 
       x = "Género", y = "Tiempo de Espera") +
  theme_minimal()
```


> Haciendo uso del gráfico anterior:

a)  ¿La variable edad tiene outliers? ¿Qué edad tienen esos pacientes?

b)  ¿Quién ha esperado más los hombres o las mujeres?


### 🐣 Caso práctico II: bronquitis y tabaco


Vamos a cargar el archivo de datos `fumadores.csv` donde tenemos datos de 96 pacientes sobre sí o fuman y quienes han desarrollado o no bronquitis.

```{r}
datos <- read_csv(file = "./datos/fumadores.csv")
datos
```


#### Pregunta 1

> Realiza la tabla de contigencia de manera absoluta y relativa y responde a las siguientes preguntas

a) ¿Cuántas personas fumaoras tienen bronquitis?

b) ¿Qué % de los fumadores está sano?

c) ¿Qué % del total son a la vez no fumadores y enfermos de bronquitis?

d) ¿Qué % de los enfermos son fumadores?

```{r}
#| code-fold: true
#| eval: false
table(datos$fumador, datos$estado)
prop.table(table(datos$fumador, datos$estado))
prop.table(table(datos$fumador, datos$estado), margin = 1)
prop.table(table(datos$fumador, datos$estado), margin = 2)
# a) 32 personas
# b) 38.46%
# c) 16%
# d) 61.53%
```

#### Pregunta 2

> Visualiza ambas variables (`fumador` y `estado`) a la vez de manera adecuada que nos permita comparar

```{r}
#| code-fold: true
#| eval: false

ggplot(datos) +
  geom_bar(aes(x = fumador, fill = estado), alpha = 0.6, position = "fill") +
  labs(x = "fumador", y = "Frec relativa", fill = "Estado") +
  theme_minimal()
```

#### Pregunta 3

> ¿Existen evidencias en la muestra de una asociación entre ambas variables?

```{r}
#| code-fold: true
#| eval: false
datos |> 
  summarise("sig_chisq" = chisq.test(datos$fumador, datos$estado)$p.value,
            "sig_fisher" = fisher.test(datos$fumador, datos$estado)$p.value)
# p-valor < alpha --> hay evidencias para rechazar la hip nula
# hay evidencias (no muy fuertes, quizás aumentar tamaño muestral?) de
# que las variables son dependientes y existe una asociación
```


#### Pregunta 4

> Si hubiera asociación, cuantifica la fuerza de dicha asociación (y el sentido) y calcula el riesgo relativo de los fumadores a contraer bronquitis (respecto a no fumadores)

```{r}
#| code-fold: true
#| eval: false
fisher.test(datos$fumador, datos$estado)
# OR estimado = 0.3611 ==> piensa que tenemos no fumar primero y luego fumar ==>
# 1/0.3611 = 2.769316 > 1 ==> hay una asociación positiva entre fumar y tener 
# bronquitis 
# La bronquitis en pacientes que fuman es 2.77 veces más frecuente
# que en los pacientes que no fuman

# RR ratio
a <- 32  # Expuestos con evento
b <- 16  # Expuestos sin evento
c <- 20  # No expuestos con evento
d <- 28  # No expuestos sin evento

RR <- (a / (a + b)) / (c / (c + d))
# El grupo que fuma tiene un riesgo 1.6 veces mayor de que desarrollar bronquitis en comparación con el grupo que no fuma.
```



### 🐣 Caso práctico III: salud mental

Esta la base de datos `datos_salud_mental.csv` tenemos información recopilada de 100 pacientes que acuden a un centro de salud mental. Se quiere realizar un estudio para ver el **impacto que tienen distintas características sobre la ansiedad y depresión** en estos 100 pacientes. Los datos incluyen una variedad de variables relacionadas con la salud mental, así como características demográficas y de estilo de vida.

```{r}
datos <-
  read_csv(file = "./datos/datos_salud_mental.csv") |> 
  janitor::clean_names()
datos
```


Las variables son:

* `id`: identificador único del paciente.
* `edad`: edad del paciente en años.
* `Genero`: género del paciente.
* `ansiedad`: nivel de ansiedad del paciente en una escala del 1 al 10.
* `depresión`: nivel de depresión del paciente en una escala del 1 al 10.
* `sesiones_terapia`: número de sesiones de terapia asistidas en el último año.
* `actividad_fisica`: número de días a la semana que el paciente realiza actividad física.
* `horas_sueno`: número de horas promedio de sueño por noche.
* `uso_drogas_recreativas`: indicador de si el paciente ha usado drogas recreativas en el último año.
* `tipo_drogas`: tipo de drogas que ha consumido el paciente.


#### Pregunta 1

> ¿De qué tipo es cada variable? Convierte las que consideres a cualis nominales y a cualis ordinales, y si hay alguna variable que deba ser lógica

```{r}
#| code-fold: true
# id: en realidad esto tendría ser un factor (un texto) ya que no cuenta nada
# Cuantitativas: edad, horas_sueno
# Cualitativas nominales: genero, tipo_drogas
# Cuanitativas discretas: sesiones_terapia y actividad_fisica
# Cuantitativas discretas pero que deberíamos tratarlas como cualis ordinales
# ya que son escalas: ansiedad, depresión
# Binarias (cualis ordinales muy concretas): uso_drogas_recreativas
datos <-
  datos |> 
  mutate("id" = as.character(id),
         "genero" = factor(genero), "tipo_drogas" = factor(tipo_drogas),
         "ansiedad" = factor(ansiedad, levels = as.character(1:10), ordered = TRUE),
         "depresion" = factor(depresion, levels = as.character(1:10), ordered = TRUE),
         "uso_drogas_recreativas" = (uso_drogas_recreativas == "Si"))
```


#### Pregunta 2

> Calcula la tabla de frecuencias absolutas y relativas de género.

```{r}
#| code-fold: true
tabla_freq_abs <- table(datos$genero)
tabla_freq_rel <- prop.table(tabla_freq_abs)
```


#### Pregunta 3

> Calcula la media de las 4 variables cuantitativas que tenemos desagregado por género. Exporta dicho resumen en un `.csv`

```{r}
#| code-fold: true
resumen <- 
  datos |> 
  drop_na(where(is.numeric)) |> 
  summarise(across(where(is.numeric), mean), .by = genero)
write_csv(resumen, file = "./datos/resumen.csv")
```

#### Pregunta 4

> Calcula la tabla de contigencia de las variables ansiedad vs genero. Calcula otra para ansiedad vs depresion. Usa `useNA = "always"` como argumento para incluir los `NA`

```{r}
#| code-fold: true
tabla_freq_genero_ansiedad <- table(datos$genero, datos$ansiedad, useNA = "always")
tabla_freq_depresion_ansiedad <- table(datos$depresion, datos$ansiedad, useNA = "always")
```


#### Pregunta 5

> Realiza un gráfico adecuado para la variable `edad`. Piensa como adaptarlo para tenerlo desagregado por `genero`.

```{r}
#| code-fold: true
#| eval: false
# Densidades
ggplot(datos) +
  geom_density(aes(x = edad), fill = "#459191", alpha = 0.4) +
  labs(x = "Edad (años)", y = "Densidad (frec relativa)") +
  theme_minimal()

library(ggridges)
ggplot(datos) +
  geom_density_ridges(aes(x = edad, y = genero, fill = genero), alpha = 0.4) +
  ggthemes::scale_fill_colorblind() +
  labs(x = "Edad (años)", y = "Sexo", fill = "Género") +
  theme_minimal()

# Histograma (mala idea con pocos datos)
ggplot(datos) +
  geom_histogram(aes(x = edad), bins = 15, fill = "#459191", alpha = 0.4) +
  labs(x = "Edad (años)", y = "Frec absoluta") +
  theme_minimal()
ggplot(datos) +
    geom_histogram(aes(x = edad, fill = genero), bins = 15, alpha = 0.25) +
    labs(x = "Edad (años)", y = "Frec absoluta") +
    theme_minimal()

# Boxplot
ggplot(datos) +
  geom_boxplot(aes(y = edad), fill = "#459191", alpha = 0.4,
               outlier.size = 3, outlier.alpha = 0.9,
               outlier.color = "#991293", outlier.shape = 18) +
  labs(y = "Edad") +
  theme_minimal()

ggplot(datos, aes(x = genero, y = edad, fill = genero, color = genero)) +
  geom_boxplot(alpha = 0.4, outlier.size = 3, outlier.alpha = 0.9,
               outlier.color = "#991293", outlier.shape = 18) +
  ggthemes::scale_color_colorblind() +
  ggthemes::scale_fill_colorblind() +
  guides(color = "none") +
  labs(x = "Género", y = "Edad", fill = "Género") +
  theme_minimal()
```

#### Pregunta 6

> Realiza un gráfico adecuado para visualizar a la vez depresión y ansiedad.

```{r}
#| code-fold: true
#| eval: false

# fíjate que aunque sean números, dado que son variables discretas
# de una escala, no permite una correcta visualización un diagrama
# de dispersión ya que hay muchos puntos iguales que se solapan
ggplot(datos) + 
  geom_point(aes(x = depresion, y = ansiedad)) +
  theme_minimal()

# una opción: se ve un patrón (tipo "recta ascedente")
ggplot(datos |> count(depresion, ansiedad)) + 
  geom_point(aes(x = depresion, y = ansiedad, color = n, size = n)) +
  scale_color_viridis_c() +
  guides(size = "none") +
  theme_minimal()
```


#### Pregunta 7

>  ¿Existe asociación entre genero y uso de drogas? ¿Y entre depresión y ansiedad? Cuantifica la respuesta todo lo que puedas.

```{r}
#| code-fold: true
resumen_p_valores_1 <-
  datos |> 
  summarise("sig_chisq" = chisq.test(datos$genero, datos$uso_drogas_recreativas)$p.value,
            "sig_fisher" = fisher.test(datos$genero, datos$uso_drogas_recreativas)$p.value)
# p-valores >> alpha --> no evidencias para rechazar la independencia -->
# no hay evidencias para afirmar la dependencia

# con tantas categorías Fisher no funciona
chisq.test(datos$depresion, datos$ansiedad)
# p-valores << alpha --> sí hay evidencias para rechazar la independencia -->
# sí hay evidencias para afirmar la dependencia
```


## Clases 3 y 4

### 💻 Ejercicios resueltos: ANOVA

#### Ejercicio 1


Vamos a usar el fichero `cushing_syndrome.csv` que contiene datos del síndrome de Cushing, un trastorno hormonal asociado con un alto nivel de cortisol. Para cada individuo de la muestra tenemos recopiladas las tasas de excreción urinaria de dos metabolitos de esteroides (tetrahidrocortisona y pregnanetriol). La variable `type` recopila el tipo de síndrome: adenoma (a), hiperplasia bilateral (b), carcinoma (c) y desconocido (u)


📝  Carga el fichero `cushing_syndrome.csv`

```{r}
datos <-
  read_csv(file = "./datos/cushing_syndrome.csv") |> 
  janitor::clean_names()
datos
```

#### Ejercicio 2

📝 Calcula la media global de `tetrahydrocortisone`. Calcula la media para cada uno de los tipos de síndrome así como su tamaño muestral

```{r}
datos |> 
  summarise("mean_global" = mean(tetrahydrocortisone))

datos |> 
  summarise("mean_groups" = mean(tetrahydrocortisone),
            "n" = n(), .by = type)
```

#### Ejercicio 3

📝 Calcula la varianza global de `tetrahydrocortisone`. Calcula la varianza para cada uno de los tipos de síndrome así como la varianza ponderada (cada varianza de grupo multiplicada por su proporción muestral)

```{r}
datos |> 
  summarise("var_global" = var(tetrahydrocortisone))

datos |> 
  summarise("var_groups" = var(tetrahydrocortisone),
            "n" = n(), .by = type) |> 
  mutate("var_weighted" = sum(var_groups*n)/sum(n))
```


#### Ejercicio 4

📝 Visualiza con boxplot `tetrahydrocortisone` para cada grupo

```{r}
ggplot(datos) +
  geom_boxplot(aes(x = type, y = tetrahydrocortisone,
                   fill = type, color = type), alpha = 0.6) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()
```

#### Ejercicio 5

📝 Visualiza los puntos de `tetrahydrocortisone` junto con sus medias distinguiendo para cada uno de los grupos

```{r}
ggplot(datos |>
         rowid_to_column(var = "id") |>
         mutate("mean" = mean(tetrahydrocortisone), .by = type)) +
  geom_point(aes(x = id, y = tetrahydrocortisone, color = type),
             size = 3, alpha = 0.6) +
  geom_line(aes(x = id, y = mean, color = type), linewidth = 2) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  theme_minimal()
```

#### Ejercicio 6

📝 Plantea la formulación del ANOVA `tetrahydrocortisone` vs `type`. Ejecuta el código que consideres y saca conclusiones: ¿hay diferencias significativas de dicha hormona entre los síndromes con $\alpha = 0.05$ y $\alpha = 0.01$?

```{r}
aov(data = datos, formula = tetrahydrocortisone ~ type) |>
  summary()
# p-valor: 0.01 > 0.05 ==> no rechazamos H_0 ==>
# no dif sig a ese nivel de sig. ==> no se continuaría

# p-valor: 0.0412 < 0.05 ==> rechazamos H_0 ==>
# hay diferencias sig. entre síndromes ==> ¿entre cuáles?
```

#### Ejercicio 7

📝 En los casos en los que se haya obtenido una dif significativa, ¿cuáles son diferentes entre sí? Haz pruebas post-hoc usando Bonferroni y Tukey (realizando comprobaciones previas que consideres). ¿Cuál sería más adecuado?

```{r}
pairwise.t.test(datos$tetrahydrocortisone, datos$type, p.adjust.method = "bonferroni", pool.sd = FALSE) 
# solo diferencia significativas a vs b (0.01 p-valor ajustado)

# ¿varianzas iguales?
car::leveneTest(datos$tetrahydrocortisone ~ datos$type)
aov(data = datos, formula = tetrahydrocortisone ~ type) |>
  TukeyHSD()
# solo dif significativa c vs a 
# dif medias = 16.753, IC bajo de 0.65, IC alto de 32.85
# p-valor ajustado 0.039

# en este caso mejor bonferroni porque a) no hay tamaños iguales y b) no son normales
```


#### Ejercicio 8

📝 Por último vamos a considerar que el tipo `"a"` es nuestro grupo de referencia/control. ¿Cómo comparar todas vs control en lugar de todas vs todas (asumimos que son independientes)?

```{r}
# ¿varianzas iguales?
car::leveneTest(datos$tetrahydrocortisone ~ datos$type)

# ¿Normalidad? ==> no parece
olsrr::ols_test_normality(datos$tetrahydrocortisone)

# Dunnet test
DescTools::DunnettTest(x = datos$tetrahydrocortisone, g = datos$type)
# nos devuelve que el único sig diferente al control es c (como antes)
# resultados "con pinzas" ya que no cumple la normalidad de momento
```



### 🐣 Caso práctico I: participación vs candidatos

El fichero `blackturnout.csv` contiene los datos de participación electoral en las elecciones para congresistas en Estados Unidos de los años 2006, 2008 y 2010, para cada uno de los estados. 
* variable `turnout`: porcentaje de participación en las últimas elecciones presenciales de la población negra (proporción respecto a la población negra en edad de poder votar)

* variable `cvap`: proporción de habitantes de población negra del distrito (proporción respecto a los habitantes en edad de votar)

* variable `candidate`: 1 si el candidato pertenece a la población negra; 0 en caso contrario.


```{r}
datos <-
  read_csv(file = "./datos/blackturnout.csv") |>
  janitor::clean_names()
datos
```

#### Pregunta 1

> ¿Cuántos distritos electorales había en cada estado para cada uno de los años (el número se reajusta en cada elección en función de la población)?

```{r}
#| eval: false
#| code-fold: true
datos |>
   summarise(n_distinct(district), .by = c(state, year))
```


#### Pregunta 2

> ¿Cuántos estados tenían un candidato negro en cada una de las elecciones? ¿Qué cantidad de candidatos negros hay en cada estado para cada una de las elecciones?

```{r}
#| eval: false
#| code-fold: true
# n estados con candidato negro
datos |>
  summarise("n_candidates" = sum(candidate), .by = c(year, state)) |> 
  summarise("n_states" = sum(n_candidates > 0), .by = year)

# cantidad de candidatos negros hay en cada estado para elección
datos |>
  summarise("n_candidates" = sum(candidate), .by = c(year, state)) 
```

#### Pregunta 3

> ¿Qué gráfico podemos usar para visualizar una posible relación (lineal) entre `turnout` (participación) y `cvap` (proporción de población negra en el distrito) distinguiendo por año? ¿Qué opinas sobre una posible asociación?

```{r}
#| eval: false
#| code-fold: true
ggplot(datos,
       aes(x = turnout, y = cvap,
           color = factor(year, levels = c("2006", "2008", "2010"),
                          ordered = TRUE))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggthemes::scale_color_colorblind() +
  labs(x = "Participación", y = "Proporción población",
       color = "Año") +
  theme_minimal()
# sitios con mayor proporción de población negra --> mayor participación entre ella (¿más comunidad?)
# 2008 participación significativamente más alta que otros años (año obama en las presidenciales)
# correlación positiva pero débil
```


#### Pregunta 4

> Cuantifica de manera numérica la posible relación lineal entre ambas variables. Comenta todo lo que consideres. ¿Existen evidencias suficientes para rechazar que no exista dicha relación lineal?

```{r}
#| eval: false
#| code-fold: true
# cuanti vs cuanti: correlación
datos |> 
  select(turnout, cvap) |> 
  cor()
# correlación muestral = 0.1686327

cor.test(datos$turnout, datos$cvap)
# p-value = 2.405e-09 ==> rechazamos incorrelación
# ==> correlación débil pero significativamente distinta de 0
```

#### Pregunta 5

> Asumiendo `year` como variable cualitativa (nos daría igual tener `2008` o `año1`), ¿hay un cambio en la cantidad de candidatos negros a lo largo de los años? ¿Existe alguna diferencia entre años? Debes cuantificarlo de 3 maneras: i) visualmente; ii) de manera descriptiva (correlación, tabla de frecuencias o lo que tú consideres adecuado); iii) de manera inferencial.

```{r}
#| eval: false
#| code-fold: true
# cuali vs cuali: tablas de contigencia + chi-cuadrado

# visualmente
datos <-
  datos |>
  mutate("year" = factor(year, levels = c("2006", "2008", "2010"),
                         ordered = TRUE),
         "black_candidate" = candidate == 1)
ggplot(datos) +
  geom_bar(aes(x = year, fill = black_candidate, color = black_candidate),
           alpha = 0.6, position = "fill") +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  labs(x = "Año", y = "Proporción candidatos") +
  theme_minimal()
# no se aprecian a priori diferencias entre los años

# tablas de contigencia
table(datos$year, datos$black_candidate)
prop.table(table(datos$year, datos$black_candidate))
prop.table(table(datos$year, datos$black_candidate), margin = 1)
prop.table(table(datos$year, datos$black_candidate), margin = 2)
# aprox todos los años igual: 87-88% vs 12-13%

# chi cuadrado
chisq.test(datos$year, datos$black_candidate)
# p-value = 0.6816 ==> no rechazamos independencia
# ==> no hay evidencias suficientes para inferir asociación
# ==> no hay evidencias suficientes para decir que proporción de candidatos negros sea distinta durante los años
```


#### Pregunta 6

> Repite el ejercicio anterior pero sustituyendo año por `state`. ¿Existen diferencias por estados?


```{r}
#| eval: false
#| code-fold: true
# cuali vs cuali: tablas de contigencia + chi-cuadrado

# visualmente
datos <-
  datos |>
  mutate("state" = factor(state))
ggplot(datos) +
  geom_bar(aes(x = state, fill = black_candidate, color = black_candidate),
           alpha = 0.6, position = "fill") +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  labs(x = "Estado", y = "Proporción candidatos") +
  theme_minimal()
# sí se aprecian diferentes evidentes a lo largo de los estados

# tablas de contigencia: si hay muchos grupos, nada útiles
table(datos$state, datos$black_candidate)
prop.table(table(datos$state, datos$black_candidate))
prop.table(table(datos$state, datos$black_candidate), margin = 1)
prop.table(table(datos$state, datos$black_candidate), margin = 2)
# hay estados con 0% de candidatos negros y otros 
# como Georgia (GA) de más del 30%

# chi cuadrado
chisq.test(datos$state, datos$black_candidate)
#  p-value = 2.953e-05 ==> rechazamos independencia
# ==> hay evidencias suficientes para inferir asociación
# ==> hay evidencias suficientes para decir que proporción de candidatos negros sea distinta en los diferentes estados
```


#### Pregunta 7

> ¿Influye en la participación electoral de la población negra que exista un candidato negro en su distrito? Cuantifica y concluye haciendo uso de todas las herramientas disponibles y detallando cada una de las conclusiones obtenidas (de manera razonada)

```{r}
#| eval: false
#| code-fold: true
# cuani vs cuali: boxplot/violin/densidad por grupos + anova

# visualmente
ggplot(datos) +
  geom_boxplot(aes(x = candidate, y = turnout,
                   fill = candidate, color = candidate),
               alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  labs(x = "Candidato negro", y = "Participación (negra)") +
  theme_minimal()
# en promedio (mediana) hay más participación negra
# cuando hay candidatos negros (aunque los valores más altos)
# son justo de distritos sin candidato negro.
# ¿Influye entonces?

# descriptivamente
datos |> 
  summarise("mean_turnout" = mean(turnout), .by = candidate)
# ¿suficiente grande la diferencia para considerarlas suficiente?

# anova (obviamos de momento las condiciones)
aov(data = datos, turnout ~ candidate) |> 
  summary()
# SSE = 0.5
# SSR = 36.13

# var explicada = 0.4950 (insesgado)
# var residual = 0.0293 (insesgado)

# ¿Cómo de grande es la var explicada vs no explicada?
# F = 0.4950 / 0.0293 = 16.92 (aprox)

# ¿Es suficientemente mayor que 1?

# p-valor = 0 (aprox) ==> F >>>> 1 ==>
# variabilidad de las medias en cada grupo es significativamente grande
# (respecto a la variabilidad inherente de turnout)
# ==> hay diferencias significativas entre las medias
```



### 🐣 Caso práctico II: atractivo vs alcohol

Los datos los tenemos cargados directamente en `beer_goggles_effect.csv` 

```{r}
datos <-
  read_csv(file = "./datos/beer_goggles_effect.csv") 
datos
```

En la tabla tenemos guardado el género de 48 estudiantes, 24 mujeres y 24 hombres, divididos en 3 grupos de alcohol, que han encontrado una pareja que les atrae en un bar. También tenemos la cantidad de alcohol ingerida y el **atractivo medido en base a una puntuación del 0 al 100**, otorgada por unos "jueces" externos, de la pareja encontrada por cada participante.



> Convierte a factor ordinal y/o nominal lo que consideres

```{r}
#| code-fold: true
datos <-
  datos |> 
  mutate("gender" = factor(gender),
         "alcohol" =
           factor(alcohol, levels = c("None", "2 Pints", "4 Pints"),
                  ordered = TRUE))
```


#### Pregunta 1

> Visualiza la distribución de la variable cuantitativa `attractiveness`. Tras hacer los gráficos que consideres, ¿es una variable normal?

```{r}
#| eval: false
#| code-fold: true

# densidad
ggplot(datos) +
  geom_density(aes(x = attractiveness)) +
  theme_minimal()

# q-q plot (vs normality)
ggplot(datos) +
  stat_qq(aes(sample = attractiveness)) +
  stat_qq_line(aes(sample = attractiveness)) +
  theme_minimal()

# ¿es normal?
shapiro.test(datos$attractiveness)
```

#### Pregunta 2

> Repite el ejercicio anterior pero separando cada uno de los grupos de `alcohol`

```{r}
#| eval: false
#| code-fold: true

# densidades
ggplot(datos) +
  geom_density(aes(x = attractiveness, fill = alcohol,
                   color = alcohol), alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  facet_wrap(~alcohol, scales = "free_y") +
  theme_minimal()

ggplot(datos) +
  ggridges::geom_density_ridges(aes(x = attractiveness, y = alcohol,
                                    fill = alcohol, color = alcohol),
                                alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()

# q-q plot (vs normality)
ggplot(datos,
       aes(sample = attractiveness, fill = alcohol, color = alcohol)) +
  stat_qq(alpha = 0.5) +
  stat_qq_line() +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  facet_wrap(~alcohol, scales = "free_y") +
  theme_minimal()

# ¿es normal?
# son normales en cada subgrupo también
datos |> 
  summarise("p_value" = shapiro.test(attractiveness)$p.value,
            .by = alcohol)
```

#### Pregunta 3

> ¿Influye el grado de alcoholismo en lo atractivo que vemos a la gente? Responde a la pregunta como consideres. Responde de manera i) descriptiva; ii) visual y iii) inferencialmente

```{r}
#| eval: false
#| code-fold: true

# cuanti (atractiveness) vs cuali (alcohol) ==>  ANOVA
# queremos testar
# H_0: media de atractivo ("objetivo" según jueces) igual en cada grupo de alcohol
# H_1: alguna distinta

# ¿Cuáles son las medias?
datos |> 
  summarise("mean_attractiveness" = mean(attractiveness), .by = alcohol)
# son diferentes (siempre lo van a ser por puro azar) pero...
# ¿suficientemente diferentes?

# visualmente
ggplot(datos) +
  geom_violin(aes(x = alcohol, y = attractiveness,
                  fill = alcohol, color = alcohol), alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()

ggplot(datos) +
  geom_boxplot(aes(x = alcohol, y = attractiveness,
                  fill = alcohol, color = alcohol), alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()
# parece que optan por personas ligeramente más atractivas con 2 pintas
# pero decrece estrepitosamente con 4
# además se pierde la simetría de la variable según van borrachos
# ¿suficientes diferencias?

ggplot(datos |>
         arrange(alcohol) |> 
         rowid_to_column(var = "id") |> 
         mutate("mean_attractiveness" = mean(attractiveness),
                .by = alcohol)) +
  geom_point(aes(x = id, y = attractiveness, color = alcohol),
             alpha = 0.5, size = 3) +
  geom_line(aes(x = id, y = mean_attractiveness, color = alcohol),
            linewidth = 2.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  theme_minimal()

# inferencialmente: anova
aov(data = datos, attractiveness ~ alcohol) |> 
  summary()
# SSE = 1054
# SSR = 3575

# var explicada = 526.9 
# var no explicada = 79.4

# F = var explicada / var no explicada = 6.633

# pvalue = 0.00299 ==> la variabilidad de las medias (varianza explicada)
# es significativamente mayor que la no explicada ==> 
# rechazamos la igualdad de medias ==> hay diferencias significativas ==>
# alcohol influye en el atractivo que percibimos (somos menos exigentes) =>
# hay asociación
```


#### Pregunta 4

> En caso de que se hayan observado diferencias significativas, ¿qué grupos son realmente diferentes entre sí? Usa el mejor método post-hoc usando Bonferroni. ¿Cuál sería más adecuado? que consideres suponiendo que los 3 grupos los tratamos por igual

```{r}
#| eval: false
#| code-fold: true

# ¿varianzas iguales?
car::leveneTest(datos$attractiveness ~ datos$alcohol)
# no se rechaza igualdad de varianzas

# la normalidad ya la hemos comprobado
# mismo tamaño de grupos
datos |> 
  count(alcohol)

# podemos aplicar tukey (paramétrico)
# que controla mucho mejor el error de tipo II (mayor poder estadístico que Bonferroni)
aov(data = datos, formula = attractiveness ~ alcohol) |>
  TukeyHSD()
# sin alcohol vs 2 pintas ==> no significativo
# sin alcohol vs 4 pintas ==> diferencia significativas
# 2 pintas vs 4 pintas ==> diferencia significativas
```

#### Pregunta 5

> Repite la pregunta anterior pero considerando (como deberías) que el grupo de los abstemios es el grupo control.

```{r}
#| eval: false
#| code-fold: true

# tenemos que cumple todas las hipótesis ya comprobadas
DescTools::DunnettTest(x = datos$attractiveness, g = datos$alcohol,
                       control = "None")
# sin alcohol vs 2 pintas ==> no significativo
# sin alcohol vs 4 pintas ==> diferencias significativas
# podríamos decir que las diferencias son realmente significativas a partir de
# la segunda pinta
```

## Clase 8

### 🐣 Caso práctico I: predicción de iris

Vamos a empezar la regresión con un ejemplo sencillo haciendo uso del archiconocido dataset `iris` donde tenemos para 150 plantas de 3 especies distintas guardado su longitud y anchura de sépalo, y su longitud y anchura de pétalo.

```{r}
datos <- iris |> as_tibble()
datos
```

#### Pregunta 1

> ¿Cuál de todas las variables va más por "libre" (no depende tanto de las demás) asumiendo una relación lineal?

```{r}
#| code-fold: true
#| eval: false
# forma 1
datos |> select(where(is.numeric)) |> cor()

# forma 2
datos |> select(where(is.numeric)) |> corrr::correlate()

# forma 3
datos |> select(where(is.numeric)) |> cor() |> corrplot::corrplot()

# la variable sepal.width es la que enos depende del resto (no así petal width)
```


#### Pregunta 2

> Suponiendo que queremos predecir de manera lineal la variable ` Sepal.Length` haciendo uso de tan solo una predictora, ¿con cuál te quedarías y por qué? Si fuésemos a meter todas las variables, ¿podríamos hacerlo o tendríamos información redundante que deberíamos quitar

```{r}
#| code-fold: true
#| eval: false
datos |> select(where(is.numeric)) |> corrr::correlate()
# con aquella con mayor correlación en valor absoluto
# es decir Petal.Length

# no tiene sentido meter a la vez Petal.Length y Petal.Width
# ya que tienen una correlación de 0.963 --> aportan la misma info
# deberíamos de hacer un análisis de colinealidad y retirar alguna
```



#### Pregunta 3

> Con la variable seleccionada realiza la formulación del modelo que planteas como hipótesis y ejecuta el código `lm()` adecuado. Interpreta hasta donde puedas en este momento del proceso. 

```{r}
#| echo: false
ajuste <- lm(data = datos, Sepal.Length ~ Petal.Length)
```

```{r}
#| code-fold: true
#| eval: false
# modelo:
# Sepal.Length = beta_0 + beta_1*Petal.Length + epsilon
# donde epsilon ~ N(0, sigma) tal que
# estimacion = beta_hat_0 + beta_hat_1*Petal.Length 
# tal que los beta_hat salen de una estimación por mínimos cuadrados

ajuste <- lm(data = datos, Sepal.Length ~ Petal.Length)
ajuste |> summary()

# beta_hat_0 = 4.30660  -> predicción de la longitud del
# sépalo cuando la longitud del pétalo es nula
# Petal.Length = 0.40892  -> por cada cm que se incrementa
# la longitud del sépalo, la longitud del pétalo
# crece 0.40892 cm

# 0.4071 es la estimación insesgada de la 
# desv. típica de la varianza residual -> cuantifica
# un promedio de los errores.

# Y HASTA AQUÍ
```

#### Pregunta 4

> ¿Qué no puedes interpretar todavía y por qué?


```{r}
#| code-fold: true
# No podemos interpretar de momento nada más ya que
# R2: no sabemos interpretarlo a estas alturas del curso todavía
# p-valores: necesitamos que se cumplan las hipótesis
# para poder hacer inferencia
```

#### Pregunta 5

> Usa el código que consideres para calcular la media de los errores al cuadrado (MSE). Visualiza la distribución de los residuos

```{r}
#| code-fold: true
#| eval: false
MSE <- mean(ajuste$residuals^2)

ggplot(tibble("residuos" = ajuste$residuals)) +
  geom_density(aes(x = residuos)) +
  theme_minimal()

ggplot(tibble("residuos" = ajuste$residuals)) +
  stat_qq(aes(sample = residuos)) +
  stat_qq_line(aes(sample = residuos)) +
  theme_minimal()
```

#### Pregunta 6

> Construye una tabla con 3 columnas: (x, y, y_hat), siendo y_hat el valor predicho. Tras ello visualiza y vs y_hat para tener una calibración visual del acierto de nuestro modelo

```{r}
#| code-fold: true
tabla_predicciones <-
  tibble("x" = datos$Petal.Length,
         "y" = datos$Sepal.Length,
         "y_hat" = ajuste$fitted.values)

ggplot(tabla_predicciones) +
  geom_point(aes(x = y, y = y_hat)) +
  geom_line(aes(x = y, y = y), color = "#913131",
            linewidth = 1.4) +
  theme_minimal()
```

#### Pregunta 7

> ¿Cómo crees que será de buena la predicción del modelo para una longitud de pétalo de 12cm?

```{r}
#| code-fold: true
# da igual el R2, la varianza residual o los errores:
# el modelo no es fiable si x está fuera del rango
# de valores con los que has entrenado el modelo
```

## Clase 10

### 🐣 Caso práctico III: colesterol


Vamos a intentar predecir los niveles de colesterol de 100 pacientes en función de otras variables predictoras

```{r}
datos <- read_csv(file = "./datos/colesterol.csv")
datos
```

#### Pregunta 1

> Nuestra variable objetivo es colesterol. Depura la variable eliminando datos ausentes e imputando cómo consideres los posibles valores atípicos en dicha variable

```{r}
#| code-fold: true
#| eval: false

# eliminamos ausentes
datos <-
  datos |> 
  drop_na(colesterol)

# chequeamos outliers
ggplot(datos) +
  geom_boxplot(aes(y = colesterol)) +
  theme_minimal()
ggplot(datos) +
  geom_density(aes(x = colesterol)) +
  theme_minimal()
ggplot(datos) +
  stat_qq(aes(sample = colesterol)) +
  stat_qq_line(aes(sample = colesterol)) +
  theme_minimal()
olsrr::ols_test_normality(datos$colesterol)

# parece tenemos outliers
# y la variable parece normal
# ==> vamos a detectar los outliers según la media
# outlier: si se aleja 2.5 desviaciones típicas de la media
datos <-
  datos |> 
  mutate("outlier" =
           abs(outliers::scores(colesterol, type = "z")) > 2.5) 
datos |> filter(outlier)

# imputamos
datos <-
  datos |> 
  mutate("colesterol" = if_else(outlier, NA, colesterol),
         "colesterol" =
           if_else(is.na(colesterol),
                   mean(colesterol, na.rm = TRUE), colesterol))
# chequeamos que la distribución no ha variado sustancialmente
ggplot(datos) +
  geom_density(aes(x = colesterol)) +
  theme_minimal()
```


#### Pregunta 2

> ¿Existe relación entre los niveles de colesterol y el sexo del paciente? Ejecuta el código que consideres para responder

```{r}
#| code-fold: true
#| eval: false

# numéricamente
datos |>
  drop_na(sexo) |> 
  summarise(mean(colesterol), .by = sexo)

# visualmente
ggplot(datos |> drop_na(sexo)) +
  geom_boxplot(aes(x = sexo, y = colesterol, fill = sexo,
                   color = sexo), alpha = 0.5) +
  MetBrewer::scale_color_met_d("Renoir") +
  MetBrewer::scale_fill_met_d("Renoir") +
  theme_minimal()
# se parecian diferencias pequeñas: ¿suficientes para decir que no?

# inferencialmente
aov(data = datos, colesterol ~ sexo) |> 
  summary()
# estimación insesgada de la varianza explicada:  5.06 
# estimación insesgada de la var no explicada: 166.64
# cociente entre ambas: F-value = 0.03
# resultado: p-valor >> 0.05 ==> no podemos rechazar H0
# no hay ev suficientes para decir que las medias sean disitntas
# no hay relación entre el sexo y los niveles de colesteorl
```



#### Pregunta 3

> Vamos a querer ahora predecir la variable colesterol mediante un modelo lineal univariante. ¿Qué variable sería la mejor predictora? ¿Por qué?

```{r}
#| code-fold: true
#| eval: false
datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate() |> 
  filter(term == "colesterol")
# la variable más correlada (en valor absoluto) es edad

# ambas variables son normales, podemos usar pearson
olsrr::ols_test_normality(datos |> drop_na(edad) |> pull(edad))

datos |> 
  select(where(is.numeric)) |> 
  cor(use = "complete.obs") |> 
  corrplot::corrplot()

ggplot(datos, aes(x = edad, y = colesterol)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()

# Es la más correlada pero suficientemente distinto de 0?
cor.test(datos$colesterol, datos$edad) # ==> sí
```


#### Pregunta 4

> Formula el modelo. Comprueba que no hay missings ni outliers tampoco en edad (si los hubiese, impútalos por lo que consideres). Tras ello aplica lm(). Interpreta todo lo que sepas y puedas HASTA ESTE PUNTO del análisis.

```{r}
#| code-fold: true
#| eval: false

# sí tengo ausentes
datos |>
  count(is.na(edad))

# al ser normal la variable, se lo imputo por la media
datos <- 
  datos |> 
  mutate("edad" = if_else(is.na(edad), mean(edad, na.rm = TRUE),
                          edad))

# ¿hay outliers? (detectados e imputados respecto a la media)
datos <-
  datos |> 
  mutate("outliers_edad" = abs(outliers::scores(edad, type = "z")) > 2.5) |> 
  mutate("edad" = if_else(outliers_edad, mean(edad), edad))

# modelo:
#  colesterol = beta_0 + beta_1 * edad
ajuste_lineal <-
  lm(data = datos, colesterol ~ edad)
ajuste_lineal |> summary()

# interpretación
# colesterol_hat = 97.3456 +  0.6795 * edad
# - si edad = 0 (es decir, lo basal de un ser humano),
#  el colesterol promedio predicho es de 97.3456
# - por cada año que envejecemos, el modelo predice EN PROMEDIO
#  que al colesterol aumenta en +0.6795

# Residual standard error: 10.66 --> estimación insesgada de
# la desviación típica poblacional de los residuos

# Y FIN DE MOMENTO: no podemos interpretar más
```


#### Pregunta 5

> ¿Cumple el modelo las condiciones inferenciales necesarias? ¿Para que necesitamos que se cumplan?

```{r}
#| code-fold: true
#| eval: false

# 4. incorrelación
# visual (deberías no ver patrón)
ggplot(tibble("res" = ajuste_lineal$residuals[-1],
              "res_lag" =
                ajuste_lineal$residuals[-length(ajuste_lineal$residuals)])) +
  geom_point(aes(x = res, y = res_lag)) +
  theme_minimal()

# inferencial
performance::check_autocorrelation(ajuste_lineal)

# 3. normalidad
# visual
ggplot(tibble("res" = ajuste_lineal$residuals)) +
  stat_qq(aes(sample = res)) +
  stat_qq_line(aes(sample = res)) +
  theme_minimal()
ggplot(tibble("res" = ajuste_lineal$residuals)) +
  geom_density(aes(x = res)) +
  theme_minimal()

# inferencial
performance::check_normality(ajuste_lineal)


# 2. heterocedasticidad
# visual (debería ver todo dentro deuna banda sin que aumente varianza)
ggplot(tibble("x" = datos$edad,
              "res" = ajuste_lineal$residuals)) +
  geom_line(aes(x = x, y = res)) +
  theme_minimal()

# inferencial
performance::check_heteroscedasticity(ajuste_lineal)

# 1. linealidad
# visual (debería ver todo sin patrón=
ggplot(tibble("y_hat" = ajuste_lineal$fitted.values,
              "res" = ajuste_lineal$residuals)) +
  geom_point(aes(x = y_hat, y = res)) +
  theme_minimal()

# inferencial
# lineal
lm(data = tibble("y_hat" = ajuste_lineal$fitted.values,
                 "res" = ajuste_lineal$residuals),
   res ~ y_hat) |> summary()
# cuadrático
lm(data = tibble("y_hat" = ajuste_lineal$fitted.values,
                 "res" = ajuste_lineal$residuals),
   res ~ y_hat + I(y_hat^2)) |> summary()

# cúbico
lm(data = tibble("y_hat" = ajuste_lineal$fitted.values,
                 "res" = ajuste_lineal$residuals),
   res ~ y_hat + I(y_hat^2) + I(y_hat^3)) |> summary()

# todo a la vez
performance::check_model(ajuste_lineal)
```


#### Pregunta 6

> Si fuese posible interpreta el resto de la salida inferencial del modelo. Detalla todo lo que consideras.

```{r}
#| code-fold: true
#| eval: false

# ahora sí
ajuste_lineal <-
  lm(data = datos, colesterol ~ edad)
ajuste_lineal |> summary()

# beta_0 ~ N(97.3456, sigma = 6.0564)
# beta_1 ~ N(0.6795 , sigma = 0.1065)
# p-valores < 0.05 ==> ambos parámetros son significativos no hay que quitarlos
# R2 de momento en clsae 10 no sabemos (pero si lo haces y ya sabes interpreta)
```


#### Pregunta 7

> Piensa el código necesario para obtener las 2 siguientes gráficas e interprétalas.

```{r}
#| echo: false
ajuste_lineal <- lm(data = datos, colesterol ~ edad)
```

```{r}
#| code-fold: true
beta_0_sim <-
  rnorm(n = 1000, mean = ajuste_lineal$coefficients[1], sd = 6.0564)
beta_1_sim <-
  rnorm(n = 1000, mean = ajuste_lineal$coefficients[2], sd = 0.1065)
betas_sim <- 
  tibble(beta_0_sim, beta_1_sim) |> 
  pivot_longer(cols = everything(), names_to = "param", values_to = "values")

ggplot(betas_sim) +
  geom_density(aes(x = values, fill = param, color = param),
               alpha = 0.5) +
  MetBrewer::scale_color_met_d("Renoir") +
  MetBrewer::scale_fill_met_d("Renoir") +
  facet_wrap(~param, scales = "free") +
  theme_minimal() +
  labs(title = "Betas simulados")

predic_simul <-
  datos |> 
  reframe("id_simul" = rep(1:1000, each = length(edad)),
          "x" = rep(edad, 1000),
          "y_hat" = beta_0_sim + beta_1_sim*x)
ggplot(predic_simul) +
  geom_density(aes(x = y_hat, group = id_simul),
               color = "grey20", alpha = 0.2, linewidth = 0.1) +
  geom_density(data =
                 tibble("y_hat" = ajuste_lineal$fitted.values),
               aes(x = y_hat), color = "red", linewidth = 1.5) +
  theme_minimal() +
  labs(title = "Simulación predicciones",
       subtitle = "1000 simulaciones")
```

## Clase 11

### 🐣 Caso práctico I: simulación


#### Pregunta 1

> Simula unos datos ($n = 500$) bajo la hipótesis (junta $y$ y $x$ en la misma tabla) de que

$$Y = -1 + 3*X + \varepsilon, \quad  X \sim N(-3, \sigma = 1.2), \quad \varepsilon \sim N(0, \sigma = 3)$$

```{r}
#| code-fold: true
eps <- rnorm(n = 500, mean = 0, sd = 3)
x <- rnorm(n = 500, mean = -3, sd = 1.2)
y <- -1 + 3*x + eps
datos <- tibble(y, x)
```

#### Pregunta 2

> Ajusta un modelo de regresión lineal univariante e interpreta todo lo que consideres (asume que la diagnosis se cumple ya que lo hemos simulado para que así sea) 

```{r}
#| code-fold: true
ajuste_inicial <- lm(data = datos, y ~ x)
ajuste_inicial |> summary()
```

#### Pregunta 3

>  Diseña un bucle de 490 iteraciones de manera que, en cada iteración, incorpores a la tabla una nueva predictora $X_i \sim N(0, 1)$. Fíjate que las [**predictoras nuevas no tienen ningún tipo de relación con $y$**]{.hl-red} (son "basura" para el modelo). En cada iteración haz un ajuste de $y$ vs todas y guarda su $R2$

```{r}
#| code-fold: true
R2 <- c()
for (i in 1:490) {
  
  datos[, i + 2] <-  rnorm(n = 500, mean = 0, sd = 1)
  R2[i] <- (lm(data = datos, y ~ .) |> summary())$r.squared
  
}
```

#### Pregunta 4

>  Crea una tabla con dos columnas: iteración y R2. Tras ello visualiza la evolución del R2 en función del número de la iteración (=número de predictoras basura). Interpreta lo que observes

```{r}
#| code-fold: true
tabla_R2 <- tibble("iter" = 1:490, "R2" = R2)
ggplot(tabla_R2) +
  geom_line(aes(x = iter, y = R2), linewidth = 1.5) +
  theme_minimal() +
  labs(x = "Número de predictoras basura")
# Moraleja: a mayor nº de predictoras, más se infla R^2
# ¡aunque sean basura!
```

#### Pregunta 5

> Simula una colección de datos ($n = 500$) bajo la hipótesis de que $Y = -1 + 3*X_1 + \varepsilon$ con $X \sim N(-3, \sigma = 1.2)$ y

* `datos_1`: $\varepsilon \sim N(0, \sigma = 0.5)$, `datos_2`: $\varepsilon \sim N(0, \sigma = 1)$

* `datos_3`: $\varepsilon \sim N(0, \sigma = 2)$, `datos_4`: $\varepsilon \sim N(0, \sigma = 4)$

* `datos_5`: $\varepsilon \sim N(0, \sigma = 8)$, `datos_6`: $\varepsilon \sim N(0, \sigma = 12)$

```{r}
#| code-fold: true
x <- rnorm(n = 500, mean = -3, sd = 1.2)
y <- -1 + 3*x

datos_1 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 0.5), x)
datos_2 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 1), x)
datos_3 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 2), x)
datos_4 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 4), x)
datos_5 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 8), x)
datos_6 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 12), x)
```

#### Pregunta 6

> Realiza los 6 ajustes, uno para cada dataset, siempre $y$ vs $x$. **IMPORTANTE**: fíjate que la parte a explicar, la modelizable, la parte no aleatoria, ¡es siempre la misma! Así que el modelo debería ser parecido siempre. Usa `compare_performance()` para compararlos.

```{r}
#| code-fold: true
#| eval: false
ajuste_1 <- lm(data = datos_1, formula = y ~ x)
ajuste_2 <- lm(data = datos_2, formula = y ~ x)
ajuste_3 <- lm(data = datos_3, formula = y ~ x)
ajuste_4 <- lm(data = datos_4, formula = y ~ x)
ajuste_5 <- lm(data = datos_5, formula = y ~ x)
ajuste_6 <- lm(data = datos_6, formula = y ~ x)

performance::compare_performance(ajuste_1, ajuste_2, ajuste_3, ajuste_4, ajuste_5, ajuste_6)
# ¡La supuesta calidad del ajuste desciende drásticamente,
# siendo igual de bueno! La parte que se puede predecir está
# perfectamente ajustada pero tenemos más ruido en los
# datos (ruido = no modelizable)
```



#### Pregunta 7

> Y si tenemos un modelo con un alto $R^2$, ¿no hace falta que cumpla las hipótesis?. Basándote en  $X \sim N(-3, \sigma = 1.5)$ y $\varepsilon \sim N(0, \sigma = 1)$  con $n = 500$, simula un modelo entre $X$ e $Y$ que incumpla la hipótesis de linealidad.

```{r}
#| code-fold: true
eps <- rnorm(n = 500, mean = 0, sd = 1)
x <- rnorm(n = 500, mean = -3, sd = 1.5)
y <- -1.5 + 2*x - 3*x^2 # por ejemplo
datos <- tibble(x, y)
```

#### Pregunta 8

>  Realiza el ajuste lineal y visualiza residuos vs valores predichos.

```{r}
#| code-fold: true
ajuste <- lm(data = datos, y ~ x)

tabla_residuos <- tibble("eps_hat" = ajuste$residuals, "y_hat" = ajuste$fitted.values)
ggplot(tabla_residuos) +
  geom_point(aes(x = y_hat, y = eps_hat)) +
  theme_minimal()
# deberías observar en los residuos el patrón que en
# los datos no modelizaste o no tuviste en cuenta

```


#### Pregunta 9

> Simula los datos bajo la siguiente hipótesis ($x_i = 0.01 + 0.01*(i-1)$) 

$$y_i = 1 - 2x_i(1 + 0.25 \sin(4 \pi x_i)) + \varepsilon_i, \quad \varepsilon_i \sim N(0, \sigma_i = 0.25 * x_{i}^2 )$$


Junta todo en un dataset de 3 columnas: y, x y $\sigma_i$. ¿Qué hipótesis se incumplen?

```{r}
#| code-fold: true
x <- seq(0.01, 2, l = 500)
eps <- rnorm(n = 500, mean = 0, sd = 0.2 * x^2)
y <- 1 - 2 * x * (1 + 0.25*sin(4 * pi * x)) + eps
datos <- tibble("y" = y, "x" = x, "sigma" =  0.2 * x^2)
```

#### Pregunta 10

> Realiza el ajuste de $y ~ x$ y observa el $R^2$

```{r}
#| code-fold: true
ajuste_lineal <- lm(data = datos, formula = y ~ x)
ajuste_lineal |> summary()
```

#### Pregunta 11

> Fíjate que tenemos un $R^2$ bastante alto pero... ¿tiene sentido su interpretación? Pinta en un diagrama de puntos + recta de regresión los datos $x$ vs $y$.

```{r}
#| code-fold: true
ggplot(datos, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal()
# Aunque el R^2 es bastante alto, el modelo no tiene sentido,
# dando estimaciones cada vez más erradas
```





