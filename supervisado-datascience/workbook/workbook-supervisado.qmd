---
title: "Aprendizaje supervisado: modelos lineales"
subtitle: "Workbooks de la asignatura Aprendizaje Supervisado I"
author: "Javier 츼lvarez Li칠bana"
format:
  html:
    theme: [default, style.scss]
    toc: true
    toc-title: 칈ndice
    toc-depth: 5
    toc-location: left
    number-sections: true
embed-resources: true
execute: 
  echo: true
---

```{r}
#| echo: false
setwd(dir = getwd())
```

* [**Diapositivas**]{.hl-yellow}: las diapositivas usadas en el aula a lo largo del curso, estructuradas por clases, estar치n disponibles y actualizadas en **<https://javieralvarezliebana.es/docencia/supervisado-datascience/diapos>** 

* [**Datos**]{.hl-yellow}: [**acceso a Drive**](https://drive.google.com/drive/folders/1sim9xjM2qRcWrsMHrv_qRlkwDbGKOWN9?usp=sharing) y [**Github**](https://github.com/dadosdelaplace/docencia/tree/main/supervisado-datascience/workbook/datos)

## Clase 1

### 游냒 Caso pr치ctico I: anscombe


En el paquete `{datasets}` se encuentra el dataset conocido como [**cuarteto de Anscombe**]{.hl-yellow}, un dataset que cuenta con 4 conjuntos de datos, cada uno de ellos cuenta con 11 observaciones de una variable x y otra y.

```{r}
#| message: false
#| warning: false
library(tidyverse)
anscombe_tb <- as_tibble(datasets::anscombe)
anscombe_tb
```


#### Pregunta 1


> Convierte a tidy data. Debes acabar con un dataset de 44 filas (11 valores para cada dataset) y 3 columnas (dataset, x e y)

```{r}
#| code-fold: true
anscombe_x <- 
  anscombe_tb |>
  pivot_longer(cols = x1:x4, names_to = "dataset", values_to = "x",
               names_prefix = "x") |>
  select(-contains("y"))

anscombe_y <- 
  anscombe_tb |>
  pivot_longer(cols = y1:y4, names_to = "dataset", values_to = "y",
               names_prefix = "y") |>
  select(-contains("x"))

anscombe_tidy <-
  anscombe_x |>
  mutate("y" = anscombe_y$y)
anscombe_tidy
```

#### Pregunta 2


> Calcula la media, varianza, desv. t칤pica de x e y en cada dataset por separado

```{r}
#| code-fold: true
#| eval: false
anscombe_tidy |> 
  summarise(mean_x = mean(x), mean_y = mean(y),
            var_x = var(x), var_y = var(y),
            sd_x = sd(x), sd_y = sd(y),
            .by = dataset)
```

#### Pregunta 3


> Calcula la covarianza y correlaci칩n entre x e y en cada dataset

```{r}
#| code-fold: true
#| eval: false
anscombe_tidy |> 
  summarise(cov = cov(x, y), cor = cor(x, y),
            .by = dataset)
```


#### Pregunta 4


> Si te fijas todos los datasets tienen los mismos momentos muestrales ... 쯥er치n el mismo dataset desordenado? Visualiza los 4 datasets en el mismo gr치fico mediante un diagrama de dispersi칩n con su ajuste de regresi칩n

```{r}
#| code-fold: true
ggplot(anscombe_tidy, aes(x = x, y = y, color = dataset)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE) +
  ggthemes::scale_color_colorblind() +
  facet_wrap(~dataset) +
  theme_minimal()
```

 Por suerte o por desgracia **no todo son matem치ticas**: antes de pensar que modelo es mejor para nuestros datos, es important칤simo realizar un **an치lisis exploratorio** de los mismos (incluyendo visualizaci칩n)


#### Pregunta 5


> Podemos visualizarlo de manera a칰n m치s extrema con el dataset `datasaurus_dozen` del paquete `{datasauRus}` (ver m치s en <https://www.research.autodesk.com/publications/same-stats-different-graphs/>). Calcula de nuevo, para cada dataset, media, varianza, desv. t칤pica, covarianza y correlaci칩n

```{r}
#| code-fold: true
#| eval: false
library(datasauRus)
datasaurus_dozen |>
  summarise(mean_x = mean(x), mean_y = mean(y),
            var_x = var(x), var_y = var(y),
            sd_x = sd(x), sd_y = sd(y),
            cov = cov(x, y), cor = cor(x, y), .by = dataset)
```

#### Pregunta 6

> Elimina el dataset `"wide_lines"` y visualiza los 12 datasets restantes mediante un diagrama de dispersi칩n (con su ajuste de regresi칩n)

```{r}
#| code-fold: true
library(datasauRus)
ggplot(datasaurus_dozen |> filter(dataset != "wide_lines"),
       aes(x = x, y = y, color = dataset)) +
  geom_point(size = 2.5, alpha = 0.75) +
  geom_smooth(method = "lm", se = FALSE)  +
  facet_wrap(~dataset, ncol = 3) +
  theme_minimal()
```


## Clase 2

### 游눹 Ejercicios resueltos: tablas de frecuencia


#### Ejercicio 1

Para repasar lo aprendido vamos a poner todo en pr치ctica con el dataset `SatisfaccionPacientes.csv`. 

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
```


游닇 Aplica el c칩digo que sea necesario para responder a estas preguntas. 쮺u치l es el tama침o muestral? 쮺u치ntas variables tenemos? 쮺u치ntas modalidades tenemos en la variable `estado_civil` (y cuantas observaciones en cada una)?

```{r}
# Tama침o muestral / n칰mero de observaciones
n <- nrow(datos)

# N칰mero de variables
p <- ncol(datos)

# 쯈u칠 modalidades tenemos?
datos |>  count(estado_civil)
```


#### Ejercicio 2

游닇 Determina el tipo de variable (cuantitativa vs. cualitativa).

```{r}
# Variables cuantitativas: tiempo, grado satisfacci칩n, n칰mero de visitas
# Variables cualitativas: g칠nero, estado civil, estado salud
glimpse(datos)
```

#### Ejercicio 3

游닇  Obten tablas de frecuencias (absoluta y relativa) en el caso de las cualitativas NOMINALES. Con ella intenta responder a las preguntas: a) 쯖u치ntas mujeres hay? b) 쯤u칠 % de individuos est치n casados?

```{r}
# no podemos calcular acumulados ya que genero es nominal
datos |>  count(genero) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs))
# Hay 53 mujeres

datos |> count(estado_civil) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs))
# Hay 26% personas casadas
```


#### Ejercicio 4

游닇 Convierte de manera adecuada la variable `genero` y `estado_civil` a cualitativa nominal

```{r}
datos <-
  datos |>
  mutate(estado_civil = factor(estado_civil),
         genero = factor(genero))
datos
```

#### Ejercicio 5

游닇 Calcula la media, mediana, rango intercuart칤lico y desviaci칩n t칤pica de edad y tiempo de espera.

```{r}
resumen <-
  datos |>
  summarise(media_edad = mean(edad), sd_edad = sd(edad), mediana_edad = median(edad),
           IQR_edad = quantile(edad, probs = 0.75) - quantile(edad, probs = 0.25),
           # tiempo espera
           media_tiempo_espera = mean(tiempo_espera), sd_tiempo_espera = sd(tiempo_espera),
           mediana_tiempo_espera = median(tiempo_espera),
           IQR_tiempo_espera = quantile(tiempo_espera, probs = 0.75) - quantile(tiempo_espera, probs = 0.25))
resumen
```

#### Ejercicio 6

游닇 Repite el anterior ejercicio pero obteniendo las m칠tricas desagregadas por sexo.

```{r}
resumen <-
  datos |>
  summarise(media_edad = mean(edad), sd_edad = sd(edad), mediana_edad = median(edad),
           IQR_edad = quantile(edad, probs = 0.75) - quantile(edad, probs = 0.25),
           # tiempo espera
           media_tiempo_espera = mean(tiempo_espera), sd_tiempo_espera = sd(tiempo_espera),
           mediana_tiempo_espera = median(tiempo_espera),
           IQR_tiempo_espera = quantile(tiempo_espera, probs = 0.75) - quantile(tiempo_espera, probs = 0.25),
          .by = genero)
resumen
```

#### Ejercicio 7

游닇 Realiza un gr치fico de viol칤n para la variable `tiempo_espera` para cada g칠nero

```{r}
ggplot(datos) +
  geom_violin(aes(x = genero, y = tiempo_espera, fill = genero, color = genero),
              alpha = 0.7) +
  ggthemes::scale_color_colorblind() +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()
```

### 游눹 Ejercicios resueltos: cuali vs cuali

#### Ejercicio 1

游닇 Carga el fichero `placebo_medicamento_completo.csv` donde tenemos guardado los niveles de colesterol antes y despu칠s de un tratamiento: a 76 personas se les dio un medicamento para bajarlo y a 24 personas placebo.

```{r}
datos <- read_csv(file = "./datos/placebo_medicamento_completo.csv")
datos
```


#### Ejercicio 2

游닇 A침ade una nueva variable dicot칩mica a los datos que nos guarde `mejora` si el paciente mejor칩 tras el tratamiento y `no mejora` en caso negativo

```{r}
datos <-
  datos |> 
  mutate("mejora" = if_else(colesterol_post <= colesterol_pre, "mejora",
                            "no mejora"))
datos
```

#### Ejercicio 3

游닇 Visualiza ambas variables (`mejora` y `tratamiento`) a la vez con un diagrama de barras de manera que podamos observar indicios de una posible independencia o dependencia entre ambas. Hazlo antes a papel y boli si lo necesitas

```{r}
# as칤 pintar칤amos en cada barra de tratamiento los mejora o no mejora
ggplot(datos) +
  geom_bar(aes(x = tratamiento, fill = mejora), alpha = 0.6) +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()

# pero dado que tienes m치s tratados que del grupo control
# no permite comparar bien as칤 que igualamos las barras
# para que cada barra sea el 100% de su categor칤a
ggplot(datos) +
  geom_bar(aes(x = tratamiento, fill = mejora), alpha = 0.6,
           position = "fill") +
  ggthemes::scale_fill_colorblind() +
  theme_minimal()

# Parece evidente visualmente que hay una diferencia entre mejora y no mejora
# en cada barra
```

#### Ejercicio 4

游닇 Calcula la tabla de frecuencias absoluta y relativa que consideres necesarias para responder a las siguientes preguntas:

a) 쮺u치ntas personas de las tratadas con medicamento no mejoraron?

b) 쯈u칠 de personas del total del estudio acabaron mejorando habiendo tomando placebo?

c) 쯈u칠 % de personas tom칩 medicamentos entre los que no mejoraron?

d) 쯈u칠 % de personas de los que tomaron medicamento mejoraron?

```{r}
table(datos$tratamiento, datos$mejora)
prop.table(table(datos$tratamiento, datos$mejora))
prop.table(table(datos$tratamiento, datos$mejora), margin = 1)
prop.table(table(datos$tratamiento, datos$mejora), margin = 2)
# 9 personas de las tratadas con medicamento no mejoraron
# 9% del total de personas mejoraron y tomaron placebo
# 37% de los que no mejoraron hab칤an tomado la medicaci칩n
# 88.1% de los que tomaron medicamento mejoraron
```

#### Ejercicio 5

游닇 Para confirmar y cuantificar las evidencias que ya tenemos, vamos a realizar un contraste de hip칩tesis. Realiza la prueba de chi-cuadrado e interpreta el resultado con $\alpha = 0.05$.

```{r}
chisq.test(datos$tratamiento, datos$mejora)
# Dado que p-value = 1.654e-06 << alpha --> debemos rechazar la hip칩tesis nula -->
# hay evidencias suficientes para afirmar que hay relaci칩n de dependencia
```

#### Ejercicio 6


> Realiza la prueba de chi-cuadrado y Fisher e incluye los p-valores en una tabla resumen haciendo uso de tidyverse. Exporta a un `.csv` dicha tabla resumen

```{r}
resumen_pvalores <-
  datos |> 
  summarise("sig_chisq" = chisq.test(datos$tratamiento, datos$mejora)$p.value,
            "sig_fisher" = fisher.test(datos$tratamiento, datos$mejora)$p.value)
resumen_pvalores

write_csv(resumen_pvalores, file = "./datos/resumen_pvalores.csv")
```

#### Ejercicio 7

游닇 Realiza la prueba de Fisher y mira la salida completa. Interpreta la salida, no solo del contraste sino de los odd ratio.

```{r}
fisher.test(datos$tratamiento, datos$mejora)

# OR estimado es de 11.95 --> al ser mayor que 1 implica que
# hay una asociaci칩n positiva entre las variables
# hay 12 veces m치s opciones de que te baje el colesterol si tomas el
# medicamento respecto a una posible mejora aleatoria (porque s칤).
```

### 游눹 Ejercicios resueltos: cuanti vs cuanti

#### Ejercicio 1

Vamos a tomar de nuevo nuestros datos de satisfacci칩n de pacientes

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names()
datos
```

游닇 Obt칠n la matriz de correlaciones de Pearson haciendo uso de `cor()`. Luego haz uso de `correlate()` del paquete `{corrr}`

```{r}
datos |> 
  select(where(is.numeric)) |> 
  cor()

datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate()
```

#### Ejercicio 2

游닇 Obt칠n la matriz de correlaciones con kendall y spearman


```{r}
datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate(method = "spearman")

datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate(method = "kendall")
```

#### Ejercicio 3

游닇 Analiza y argumenta, en funci칩n de los resultados anteriores, la asociaci칩n entre `edad` y `grado_satisfaccion`, y entre `tiempo_espera` y `grado_satisfaccion`

```{r}
# Vemos que por ejemplo `edad` no correla con `grado_satisfaccion` ($-0.0339$ seg칰n Pearson) pero `tiempo_espera` tiene una correlaci칩n negativa ($-0.586$ seg칰n Pearson) con `grado_satisfaccion`.
```

#### Ejercicio 4

游닇 Con el paquete `{corrplot}` visualiza la matriz de correlaciones

```{r}
datos |> 
  select(where(is.numeric)) |> 
  cor() |> 
  corrplot::corrplot(method = "square")
```

#### Ejercicio 5

游닇 Investiga el paquete `{GGally}` y a funci칩n `ggpairs()` para visualizar las correlaciones de todas las variables (salvo `id`)

```{r}
library(GGally)
ggpairs(datos |> select(-id)) +
  theme_minimal()

# cuali vs cuali: pictogramas (con rect치ngulos)
# cuanti vs cuanti: scatter plot
# cuanti vs cuali: boxplot desagregados
# variable vs s칤 misma: densidad
```

#### Ejercicio 6

游닇 쮺칩mo saber que la correlaci칩n observada entre `edad` y `grado_satisfaccion` ($-0.0339$) es suficientemente peque침a para considerarse incorreladas? 쮺칩mo saber si la correlaci칩n entre `tiempo_espera` y `grado_satisfaccion` ($-0.586$) es suficientemente grande para considerar que es **significativa**?


```{r}
cor.test(datos$edad, datos$grado_satisfaccion)
cor.test(datos$tiempo_espera, datos$grado_satisfaccion)

# En uno el p-valor es bastante alto (**no rechazamos la hip칩tesis nula de incorrelaci칩n**) y en otro el p-valor es pr치cticamente 0 (rechazamos la hip칩tesis nula ->  **hay evidencias de correlaci칩n significativa**).

# Ninguna de las 3 es normal as칤 que lo apropiado ser칤a
# contrastar la correlaci칩n de rango
performance::check_normality(datos$edad)
performance::check_normality(datos$grado_satisfaccion)
performance::check_normality(datos$tiempo_espera)
```



### 游냒 Caso pr치ctico I: encuesta de satisfacci칩n

Vamos a seguir poniendo en pr치ctica lo aprendido el dataset `SatisfaccionPacientes.csv`

```{r}
library(readr)
datos <-
  read_csv(file = "./datos/SatisfaccionPacientes.csv") |> 
  janitor::clean_names() |>
  mutate(estado_civil = factor(estado_civil),
         genero = factor(genero))
datos
```

#### Pregunta 1

> Convierte de manera adecuada la variable `estado_salud` a cualitativa ORDINAL

```{r}
#| code-fold: true
datos <-
  datos |>
  mutate(estado_salud =
           factor(estado_salud, levels = c("Malo", "Regular", "Bueno", "Excelente"),
                  ordered = TRUE))
```

#### Pregunta 2

> Haz uso de `table()` para calcular la tabla de frecuencias de `genero` y `estado_civil`

```{r}
#| code-fold: true
#| eval: false
table(datos$genero)
table(datos$estado_civil)
```

####  Pregunta 3

>  Calcula la tabla de frecuencias de las ORDINALES y piensa si ahora puedes a침adir algo m치s a la tabla de frecuencias). Tras ello usa el c칩digo m치s sencillo para responder a: 쯖u치ntas personas tienen un estado de salud regular (o peor)?

```{r}
#| code-fold: true
#| eval: false
freq_estado_salud <-
  datos |> 
  count(estado_salud) |> 
  rename(frecuencia_abs = n) |> 
  mutate(frecuencia_rel = frecuencia_abs/sum(frecuencia_abs),
         frecuencia_acum_abs = cumsum(frecuencia_abs),
         frecuencia_acum_rel = cumsum(frecuencia_rel))
# Se ve dentro de la tabla. Hay 44+15 = 59 personas con un estado de salud malo o regular. 
# Con c칩digo
datos |>
  count(estado_salud <= "Regular")
```

####  Pregunta 4

>  Si te fijas una de las modalidades es totalmente anecd칩tica (solo 1 Excelente). Ser칤a conveniente recategorizar la categor칤a Excelente: siempre que detecte Excelente, lo debe recategorizar a Bueno (criterio general: las categor칤as deben contener al menos un 5% de los individuos de toda la muestra).

```{r}
#| code-fold: true
datos <- 
  datos |> 
  mutate(estado_salud  = if_else(estado_salud  == "Excelente", "Bueno", estado_salud),
         # ojo: hay que redefinir los niveles de la cualitativa
         # ya que ha dejado de ser factor (veremos un d칤a el paquete forcats para esto)
         estado_salud =
           factor(estado_salud, levels = c("Malo", "Regular", "Bueno"),
                  ordered = TRUE))
```

####  Pregunta 5

>  Calcula la media, mediana, rango intercuart칤lico y desviaci칩n t칤pica de grado de satisfacci칩n desagregado por sexo.

```{r}
#| code-fold: true
resumen <-
  datos |>
  summarise(media_grado_satisfaccion = mean(grado_satisfaccion),
           sd_grado_satisfaccion = sd(grado_satisfaccion),
           mediana_grado_satisfaccion = median(grado_satisfaccion),
           IQR_grado_satisfaccion =
             quantile(grado_satisfaccion, probs = 0.75) -
             quantile(grado_satisfaccion, probs = 0.25),
           .by = genero)
```

####  Pregunta 6

> Exporta los resultados anteriores (`resumen`) en un archivo `resumen.csv`. En lugar de un `read_csv()` vamos a usar `write_csv(tabla, file = "ruta")`

```{r}
#| code-fold: true
# importado como csv
write_csv(resumen, file = "./resumen.csv")
```

#### Pregunta 7

> Crear un diagrama de barras para la variable g칠nero. 쮺칩mo podr칤amos decirle que cada barra (es decir, para cada modalidad de g칠nero) sea de un color (de relleno)?


```{r}
#| code-fold: true
ggplot(datos) +
  # dentro de aes() para que dependa de la tabla
  geom_bar(aes(x = genero, fill = genero))
```


#### Pregunta 8

> Crear desde cero un diagrama de barras, con ajustes personalizados para la variable estado de salud

```{r}
#| code-fold: true
# Estado de salud (ahora el orden importa)
ggplot(datos) +
  geom_bar(aes(x = estado_salud, fill = estado_salud), alpha = 0.75) +
  ggthemes::scale_fill_colorblind() +
  labs(title = "Diagrama de barras de la variable estado salud", 
       x = "Categor칤a",  y = "Frecuencia absoluta",
       fill = "Categor칤a") +
  theme_minimal() 
```


F칤jate que si **no tuvi칠semos la variable como cuali ordinal, las barras van por orden alfab칠tico**, no por jerarqu칤a real

```{r}
ggplot(datos) +
  geom_bar(aes(x = as.character(estado_salud), fill = as.character(estado_salud)),
           alpha = 0.75) +
  ggthemes::scale_fill_colorblind() +
  labs(title = "Diagrama de barras de la variable estado salud", 
       x = "Categor칤a",  y = "Frecuencia absoluta",
       fill = "Categor칤a") +
  theme_minimal() 
```

#### Pregunta 9

> Crea el histograma inferior para las variable edad y tiempo de espera.

```{r}
#| code-fold: true
ggplot(datos) +
  geom_histogram(aes(x = edad), bins = 30, fill = "darkorange", alpha = 0.75) + 
  labs(title = "Histograma de edad", subtitle = "Bins = 30",
       x = "Valores", y = "Frecuencia absoluta") +
  theme_minimal()

ggplot(datos) +
  # Define el ancho de las barras y colores
  geom_histogram(aes(x = tiempo_espera), bins = 30, fill = "orchid", alpha = 0.75) + 
  labs(title = "Histograma de tiempo de espera", subtitle = "Bins = 30",
       x = "Valores", y = "Frecuencia absoluta") +
  theme_minimal()
```

#### Pregunta 10

> Crea el gr치fico de densidad inferior para las variable edad y tiempo de espera.

```{r}
#| code-fold: true
ggplot(datos) +
  geom_density(aes(x = edad), color = "darkorange", 
               fill = "darkorange", alpha = 0.75) + 
  labs(title = "Gr치fico de densidad de edad",
       x = "Valores", y = "Frecuencia relativa") +
  theme_minimal()

ggplot(datos) +
  geom_density(aes(x = tiempo_espera), color = "orchid", 
               fill = "orchid", alpha = 0.75) + 
  labs(title = "Gr치fico de densidad de tiempo de espera",
       x = "Valores", y = "Frecuencia relativa") +
  theme_minimal()
```



#### Pregunta 11

> Realiza un boxplot para edad y un boxplot para numero de visitas PERO por g칠nero (dos variables, piensa c칩mo)

```{r}
#| code-fold: true
ggplot(datos) +
  geom_boxplot(aes(y = edad), fill = "lightblue", alpha = 0.75) +  
  labs(title = "Boxplot de edad",  y = "Edad") +
  theme_minimal()

ggplot(datos) +
  geom_boxplot(aes(x = genero, y = tiempo_espera, fill = genero),
               alpha = 0.75) +
  labs(title = "Boxplot de tiempo de espera por g칠nero", 
       x = "G칠nero", y = "Tiempo de Espera") +
  theme_minimal()
```


> Haciendo uso del gr치fico anterior:

a)  쯃a variable edad tiene outliers? 쯈u칠 edad tienen esos pacientes?

b)  쯈ui칠n ha esperado m치s los hombres o las mujeres?


### 游냒 Caso pr치ctico II: bronquitis y tabaco


Vamos a cargar el archivo de datos `fumadores.csv` donde tenemos datos de 96 pacientes sobre s칤 o fuman y quienes han desarrollado o no bronquitis.

```{r}
datos <- read_csv(file = "./datos/fumadores.csv")
datos
```


#### Pregunta 1

> Realiza la tabla de contigencia de manera absoluta y relativa y responde a las siguientes preguntas

a) 쮺u치ntas personas fumaoras tienen bronquitis?

b) 쯈u칠 % de los fumadores est치 sano?

c) 쯈u칠 % del total son a la vez no fumadores y enfermos de bronquitis?

d) 쯈u칠 % de los enfermos son fumadores?

```{r}
#| code-fold: true
#| eval: false
table(datos$fumador, datos$estado)
prop.table(table(datos$fumador, datos$estado))
prop.table(table(datos$fumador, datos$estado), margin = 1)
prop.table(table(datos$fumador, datos$estado), margin = 2)
# a) 32 personas
# b) 38.46%
# c) 16%
# d) 61.53%
```

#### Pregunta 2

> Visualiza ambas variables (`fumador` y `estado`) a la vez de manera adecuada que nos permita comparar

```{r}
#| code-fold: true
#| eval: false

ggplot(datos) +
  geom_bar(aes(x = fumador, fill = estado), alpha = 0.6, position = "fill") +
  labs(x = "fumador", y = "Frec relativa", fill = "Estado") +
  theme_minimal()
```

#### Pregunta 3

> 쮼xisten evidencias en la muestra de una asociaci칩n entre ambas variables?

```{r}
#| code-fold: true
#| eval: false
datos |> 
  summarise("sig_chisq" = chisq.test(datos$fumador, datos$estado)$p.value,
            "sig_fisher" = fisher.test(datos$fumador, datos$estado)$p.value)
# p-valor < alpha --> hay evidencias para rechazar la hip nula
# hay evidencias (no muy fuertes, quiz치s aumentar tama침o muestral?) de
# que las variables son dependientes y existe una asociaci칩n
```


#### Pregunta 4

> Si hubiera asociaci칩n, cuantifica la fuerza de dicha asociaci칩n (y el sentido) y calcula el riesgo relativo de los fumadores a contraer bronquitis (respecto a no fumadores)

```{r}
#| code-fold: true
#| eval: false
fisher.test(datos$fumador, datos$estado)
# OR estimado = 0.3611 ==> piensa que tenemos no fumar primero y luego fumar ==>
# 1/0.3611 = 2.769316 > 1 ==> hay una asociaci칩n positiva entre fumar y tener 
# bronquitis 
# La bronquitis en pacientes que fuman es 2.77 veces m치s frecuente
# que en los pacientes que no fuman

# RR ratio
a <- 32  # Expuestos con evento
b <- 16  # Expuestos sin evento
c <- 20  # No expuestos con evento
d <- 28  # No expuestos sin evento

RR <- (a / (a + b)) / (c / (c + d))
# El grupo que fuma tiene un riesgo 1.6 veces mayor de que desarrollar bronquitis en comparaci칩n con el grupo que no fuma.
```



### 游냒 Caso pr치ctico III: salud mental

Esta la base de datos `datos_salud_mental.csv` tenemos informaci칩n recopilada de 100 pacientes que acuden a un centro de salud mental. Se quiere realizar un estudio para ver el **impacto que tienen distintas caracter칤sticas sobre la ansiedad y depresi칩n** en estos 100 pacientes. Los datos incluyen una variedad de variables relacionadas con la salud mental, as칤 como caracter칤sticas demogr치ficas y de estilo de vida.

```{r}
datos <-
  read_csv(file = "./datos/datos_salud_mental.csv") |> 
  janitor::clean_names()
datos
```


Las variables son:

* `id`: identificador 칰nico del paciente.
* `edad`: edad del paciente en a침os.
* `Genero`: g칠nero del paciente.
* `ansiedad`: nivel de ansiedad del paciente en una escala del 1 al 10.
* `depresi칩n`: nivel de depresi칩n del paciente en una escala del 1 al 10.
* `sesiones_terapia`: n칰mero de sesiones de terapia asistidas en el 칰ltimo a침o.
* `actividad_fisica`: n칰mero de d칤as a la semana que el paciente realiza actividad f칤sica.
* `horas_sueno`: n칰mero de horas promedio de sue침o por noche.
* `uso_drogas_recreativas`: indicador de si el paciente ha usado drogas recreativas en el 칰ltimo a침o.
* `tipo_drogas`: tipo de drogas que ha consumido el paciente.


#### Pregunta 1

> 쮻e qu칠 tipo es cada variable? Convierte las que consideres a cualis nominales y a cualis ordinales, y si hay alguna variable que deba ser l칩gica

```{r}
#| code-fold: true
# id: en realidad esto tendr칤a ser un factor (un texto) ya que no cuenta nada
# Cuantitativas: edad, horas_sueno
# Cualitativas nominales: genero, tipo_drogas
# Cuanitativas discretas: sesiones_terapia y actividad_fisica
# Cuantitativas discretas pero que deber칤amos tratarlas como cualis ordinales
# ya que son escalas: ansiedad, depresi칩n
# Binarias (cualis ordinales muy concretas): uso_drogas_recreativas
datos <-
  datos |> 
  mutate("id" = as.character(id),
         "genero" = factor(genero), "tipo_drogas" = factor(tipo_drogas),
         "ansiedad" = factor(ansiedad, levels = as.character(1:10), ordered = TRUE),
         "depresion" = factor(depresion, levels = as.character(1:10), ordered = TRUE),
         "uso_drogas_recreativas" = (uso_drogas_recreativas == "Si"))
```


#### Pregunta 2

> Calcula la tabla de frecuencias absolutas y relativas de g칠nero.

```{r}
#| code-fold: true
tabla_freq_abs <- table(datos$genero)
tabla_freq_rel <- prop.table(tabla_freq_abs)
```


#### Pregunta 3

> Calcula la media de las 4 variables cuantitativas que tenemos desagregado por g칠nero. Exporta dicho resumen en un `.csv`

```{r}
#| code-fold: true
resumen <- 
  datos |> 
  drop_na(where(is.numeric)) |> 
  summarise(across(where(is.numeric), mean), .by = genero)
write_csv(resumen, file = "./datos/resumen.csv")
```

#### Pregunta 4

> Calcula la tabla de contigencia de las variables ansiedad vs genero. Calcula otra para ansiedad vs depresion. Usa `useNA = "always"` como argumento para incluir los `NA`

```{r}
#| code-fold: true
tabla_freq_genero_ansiedad <- table(datos$genero, datos$ansiedad, useNA = "always")
tabla_freq_depresion_ansiedad <- table(datos$depresion, datos$ansiedad, useNA = "always")
```


#### Pregunta 5

> Realiza un gr치fico adecuado para la variable `edad`. Piensa como adaptarlo para tenerlo desagregado por `genero`.

```{r}
#| code-fold: true
#| eval: false
# Densidades
ggplot(datos) +
  geom_density(aes(x = edad), fill = "#459191", alpha = 0.4) +
  labs(x = "Edad (a침os)", y = "Densidad (frec relativa)") +
  theme_minimal()

library(ggridges)
ggplot(datos) +
  geom_density_ridges(aes(x = edad, y = genero, fill = genero), alpha = 0.4) +
  ggthemes::scale_fill_colorblind() +
  labs(x = "Edad (a침os)", y = "Sexo", fill = "G칠nero") +
  theme_minimal()

# Histograma (mala idea con pocos datos)
ggplot(datos) +
  geom_histogram(aes(x = edad), bins = 15, fill = "#459191", alpha = 0.4) +
  labs(x = "Edad (a침os)", y = "Frec absoluta") +
  theme_minimal()
ggplot(datos) +
    geom_histogram(aes(x = edad, fill = genero), bins = 15, alpha = 0.25) +
    labs(x = "Edad (a침os)", y = "Frec absoluta") +
    theme_minimal()

# Boxplot
ggplot(datos) +
  geom_boxplot(aes(y = edad), fill = "#459191", alpha = 0.4,
               outlier.size = 3, outlier.alpha = 0.9,
               outlier.color = "#991293", outlier.shape = 18) +
  labs(y = "Edad") +
  theme_minimal()

ggplot(datos, aes(x = genero, y = edad, fill = genero, color = genero)) +
  geom_boxplot(alpha = 0.4, outlier.size = 3, outlier.alpha = 0.9,
               outlier.color = "#991293", outlier.shape = 18) +
  ggthemes::scale_color_colorblind() +
  ggthemes::scale_fill_colorblind() +
  guides(color = "none") +
  labs(x = "G칠nero", y = "Edad", fill = "G칠nero") +
  theme_minimal()
```

#### Pregunta 6

> Realiza un gr치fico adecuado para visualizar a la vez depresi칩n y ansiedad.

```{r}
#| code-fold: true
#| eval: false

# f칤jate que aunque sean n칰meros, dado que son variables discretas
# de una escala, no permite una correcta visualizaci칩n un diagrama
# de dispersi칩n ya que hay muchos puntos iguales que se solapan
ggplot(datos) + 
  geom_point(aes(x = depresion, y = ansiedad)) +
  theme_minimal()

# una opci칩n: se ve un patr칩n (tipo "recta ascedente")
ggplot(datos |> count(depresion, ansiedad)) + 
  geom_point(aes(x = depresion, y = ansiedad, color = n, size = n)) +
  scale_color_viridis_c() +
  guides(size = "none") +
  theme_minimal()
```


#### Pregunta 7

>  쮼xiste asociaci칩n entre genero y uso de drogas? 쯏 entre depresi칩n y ansiedad? Cuantifica la respuesta todo lo que puedas.

```{r}
#| code-fold: true
resumen_p_valores_1 <-
  datos |> 
  summarise("sig_chisq" = chisq.test(datos$genero, datos$uso_drogas_recreativas)$p.value,
            "sig_fisher" = fisher.test(datos$genero, datos$uso_drogas_recreativas)$p.value)
# p-valores >> alpha --> no evidencias para rechazar la independencia -->
# no hay evidencias para afirmar la dependencia

# con tantas categor칤as Fisher no funciona
chisq.test(datos$depresion, datos$ansiedad)
# p-valores << alpha --> s칤 hay evidencias para rechazar la independencia -->
# s칤 hay evidencias para afirmar la dependencia
```


## Clases 3 y 4

### 游눹 Ejercicios resueltos: ANOVA

#### Ejercicio 1


Vamos a usar el fichero `cushing_syndrome.csv` que contiene datos del s칤ndrome de Cushing, un trastorno hormonal asociado con un alto nivel de cortisol. Para cada individuo de la muestra tenemos recopiladas las tasas de excreci칩n urinaria de dos metabolitos de esteroides (tetrahidrocortisona y pregnanetriol). La variable `type` recopila el tipo de s칤ndrome: adenoma (a), hiperplasia bilateral (b), carcinoma (c) y desconocido (u)


游닇  Carga el fichero `cushing_syndrome.csv`

```{r}
datos <-
  read_csv(file = "./datos/cushing_syndrome.csv") |> 
  janitor::clean_names()
datos
```

#### Ejercicio 2

游닇 Calcula la media global de `tetrahydrocortisone`. Calcula la media para cada uno de los tipos de s칤ndrome as칤 como su tama침o muestral

```{r}
datos |> 
  summarise("mean_global" = mean(tetrahydrocortisone))

datos |> 
  summarise("mean_groups" = mean(tetrahydrocortisone),
            "n" = n(), .by = type)
```

#### Ejercicio 3

游닇 Calcula la varianza global de `tetrahydrocortisone`. Calcula la varianza para cada uno de los tipos de s칤ndrome as칤 como la varianza ponderada (cada varianza de grupo multiplicada por su proporci칩n muestral)

```{r}
datos |> 
  summarise("var_global" = var(tetrahydrocortisone))

datos |> 
  summarise("var_groups" = var(tetrahydrocortisone),
            "n" = n(), .by = type) |> 
  mutate("var_weighted" = sum(var_groups*n)/sum(n))
```


#### Ejercicio 4

游닇 Visualiza con boxplot `tetrahydrocortisone` para cada grupo

```{r}
ggplot(datos) +
  geom_boxplot(aes(x = type, y = tetrahydrocortisone,
                   fill = type, color = type), alpha = 0.6) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()
```

#### Ejercicio 5

游닇 Visualiza los puntos de `tetrahydrocortisone` junto con sus medias distinguiendo para cada uno de los grupos

```{r}
ggplot(datos |>
         rowid_to_column(var = "id") |>
         mutate("mean" = mean(tetrahydrocortisone), .by = type)) +
  geom_point(aes(x = id, y = tetrahydrocortisone, color = type),
             size = 3, alpha = 0.6) +
  geom_line(aes(x = id, y = mean, color = type), linewidth = 2) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  theme_minimal()
```

#### Ejercicio 6

游닇 Plantea la formulaci칩n del ANOVA `tetrahydrocortisone` vs `type`. Ejecuta el c칩digo que consideres y saca conclusiones: 쯛ay diferencias significativas de dicha hormona entre los s칤ndromes con $\alpha = 0.05$ y $\alpha = 0.01$?

```{r}
aov(data = datos, formula = tetrahydrocortisone ~ type) |>
  summary()
# p-valor: 0.01 > 0.05 ==> no rechazamos H_0 ==>
# no dif sig a ese nivel de sig. ==> no se continuar칤a

# p-valor: 0.0412 < 0.05 ==> rechazamos H_0 ==>
# hay diferencias sig. entre s칤ndromes ==> 쯘ntre cu치les?
```

#### Ejercicio 7

游닇 En los casos en los que se haya obtenido una dif significativa, 쯖u치les son diferentes entre s칤? Haz pruebas post-hoc usando Bonferroni y Tukey (realizando comprobaciones previas que consideres). 쮺u치l ser칤a m치s adecuado?

```{r}
pairwise.t.test(datos$tetrahydrocortisone, datos$type, p.adjust.method = "bonferroni", pool.sd = FALSE) 
# solo diferencia significativas a vs b (0.01 p-valor ajustado)

# 쯨arianzas iguales?
car::leveneTest(datos$tetrahydrocortisone ~ datos$type)
aov(data = datos, formula = tetrahydrocortisone ~ type) |>
  TukeyHSD()
# solo dif significativa c vs a 
# dif medias = 16.753, IC bajo de 0.65, IC alto de 32.85
# p-valor ajustado 0.039

# en este caso mejor bonferroni porque a) no hay tama침os iguales y b) no son normales
```


#### Ejercicio 8

游닇 Por 칰ltimo vamos a considerar que el tipo `"a"` es nuestro grupo de referencia/control. 쮺칩mo comparar todas vs control en lugar de todas vs todas (asumimos que son independientes)?

```{r}
# 쯨arianzas iguales?
car::leveneTest(datos$tetrahydrocortisone ~ datos$type)

# 쯅ormalidad? ==> no parece
olsrr::ols_test_normality(datos$tetrahydrocortisone)

# Dunnet test
DescTools::DunnettTest(x = datos$tetrahydrocortisone, g = datos$type)
# nos devuelve que el 칰nico sig diferente al control es c (como antes)
# resultados "con pinzas" ya que no cumple la normalidad de momento
```



### 游냒 Caso pr치ctico I: participaci칩n vs candidatos

El fichero `blackturnout.csv` contiene los datos de participaci칩n electoral en las elecciones para congresistas en Estados Unidos de los a침os 2006, 2008 y 2010, para cada uno de los estados. 
* variable `turnout`: porcentaje de participaci칩n en las 칰ltimas elecciones presenciales de la poblaci칩n negra (proporci칩n respecto a la poblaci칩n negra en edad de poder votar)

* variable `cvap`: proporci칩n de habitantes de poblaci칩n negra del distrito (proporci칩n respecto a los habitantes en edad de votar)

* variable `candidate`: 1 si el candidato pertenece a la poblaci칩n negra; 0 en caso contrario.


```{r}
datos <-
  read_csv(file = "./datos/blackturnout.csv") |>
  janitor::clean_names()
datos
```

#### Pregunta 1

> 쮺u치ntos distritos electorales hab칤a en cada estado para cada uno de los a침os (el n칰mero se reajusta en cada elecci칩n en funci칩n de la poblaci칩n)?

```{r}
#| eval: false
#| code-fold: true
datos |>
   summarise(n_distinct(district), .by = c(state, year))
```


#### Pregunta 2

> 쮺u치ntos estados ten칤an un candidato negro en cada una de las elecciones? 쯈u칠 cantidad de candidatos negros hay en cada estado para cada una de las elecciones?

```{r}
#| eval: false
#| code-fold: true
# n estados con candidato negro
datos |>
  summarise("n_candidates" = sum(candidate), .by = c(year, state)) |> 
  summarise("n_states" = sum(n_candidates > 0), .by = year)

# cantidad de candidatos negros hay en cada estado para elecci칩n
datos |>
  summarise("n_candidates" = sum(candidate), .by = c(year, state)) 
```

#### Pregunta 3

> 쯈u칠 gr치fico podemos usar para visualizar una posible relaci칩n (lineal) entre `turnout` (participaci칩n) y `cvap` (proporci칩n de poblaci칩n negra en el distrito) distinguiendo por a침o? 쯈u칠 opinas sobre una posible asociaci칩n?

```{r}
#| eval: false
#| code-fold: true
ggplot(datos,
       aes(x = turnout, y = cvap,
           color = factor(year, levels = c("2006", "2008", "2010"),
                          ordered = TRUE))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggthemes::scale_color_colorblind() +
  labs(x = "Participaci칩n", y = "Proporci칩n poblaci칩n",
       color = "A침o") +
  theme_minimal()
# sitios con mayor proporci칩n de poblaci칩n negra --> mayor participaci칩n entre ella (쯠치s comunidad?)
# 2008 participaci칩n significativamente m치s alta que otros a침os (a침o obama en las presidenciales)
# correlaci칩n positiva pero d칠bil
```


#### Pregunta 4

> Cuantifica de manera num칠rica la posible relaci칩n lineal entre ambas variables. Comenta todo lo que consideres. 쮼xisten evidencias suficientes para rechazar que no exista dicha relaci칩n lineal?

```{r}
#| eval: false
#| code-fold: true
# cuanti vs cuanti: correlaci칩n
datos |> 
  select(turnout, cvap) |> 
  cor()
# correlaci칩n muestral = 0.1686327

cor.test(datos$turnout, datos$cvap)
# p-value = 2.405e-09 ==> rechazamos incorrelaci칩n
# ==> correlaci칩n d칠bil pero significativamente distinta de 0
```

#### Pregunta 5

> Asumiendo `year` como variable cualitativa (nos dar칤a igual tener `2008` o `a침o1`), 쯛ay un cambio en la cantidad de candidatos negros a lo largo de los a침os? 쮼xiste alguna diferencia entre a침os? Debes cuantificarlo de 3 maneras: i) visualmente; ii) de manera descriptiva (correlaci칩n, tabla de frecuencias o lo que t칰 consideres adecuado); iii) de manera inferencial.

```{r}
#| eval: false
#| code-fold: true
# cuali vs cuali: tablas de contigencia + chi-cuadrado

# visualmente
datos <-
  datos |>
  mutate("year" = factor(year, levels = c("2006", "2008", "2010"),
                         ordered = TRUE),
         "black_candidate" = candidate == 1)
ggplot(datos) +
  geom_bar(aes(x = year, fill = black_candidate, color = black_candidate),
           alpha = 0.6, position = "fill") +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  labs(x = "A침o", y = "Proporci칩n candidatos") +
  theme_minimal()
# no se aprecian a priori diferencias entre los a침os

# tablas de contigencia
table(datos$year, datos$black_candidate)
prop.table(table(datos$year, datos$black_candidate))
prop.table(table(datos$year, datos$black_candidate), margin = 1)
prop.table(table(datos$year, datos$black_candidate), margin = 2)
# aprox todos los a침os igual: 87-88% vs 12-13%

# chi cuadrado
chisq.test(datos$year, datos$black_candidate)
# p-value = 0.6816 ==> no rechazamos independencia
# ==> no hay evidencias suficientes para inferir asociaci칩n
# ==> no hay evidencias suficientes para decir que proporci칩n de candidatos negros sea distinta durante los a침os
```


#### Pregunta 6

> Repite el ejercicio anterior pero sustituyendo a침o por `state`. 쮼xisten diferencias por estados?


```{r}
#| eval: false
#| code-fold: true
# cuali vs cuali: tablas de contigencia + chi-cuadrado

# visualmente
datos <-
  datos |>
  mutate("state" = factor(state))
ggplot(datos) +
  geom_bar(aes(x = state, fill = black_candidate, color = black_candidate),
           alpha = 0.6, position = "fill") +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  labs(x = "Estado", y = "Proporci칩n candidatos") +
  theme_minimal()
# s칤 se aprecian diferentes evidentes a lo largo de los estados

# tablas de contigencia: si hay muchos grupos, nada 칰tiles
table(datos$state, datos$black_candidate)
prop.table(table(datos$state, datos$black_candidate))
prop.table(table(datos$state, datos$black_candidate), margin = 1)
prop.table(table(datos$state, datos$black_candidate), margin = 2)
# hay estados con 0% de candidatos negros y otros 
# como Georgia (GA) de m치s del 30%

# chi cuadrado
chisq.test(datos$state, datos$black_candidate)
#  p-value = 2.953e-05 ==> rechazamos independencia
# ==> hay evidencias suficientes para inferir asociaci칩n
# ==> hay evidencias suficientes para decir que proporci칩n de candidatos negros sea distinta en los diferentes estados
```


#### Pregunta 7

> 쯀nfluye en la participaci칩n electoral de la poblaci칩n negra que exista un candidato negro en su distrito? Cuantifica y concluye haciendo uso de todas las herramientas disponibles y detallando cada una de las conclusiones obtenidas (de manera razonada)

```{r}
#| eval: false
#| code-fold: true
# cuani vs cuali: boxplot/violin/densidad por grupos + anova

# visualmente
ggplot(datos) +
  geom_boxplot(aes(x = candidate, y = turnout,
                   fill = candidate, color = candidate),
               alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  labs(x = "Candidato negro", y = "Participaci칩n (negra)") +
  theme_minimal()
# en promedio (mediana) hay m치s participaci칩n negra
# cuando hay candidatos negros (aunque los valores m치s altos)
# son justo de distritos sin candidato negro.
# 쯀nfluye entonces?

# descriptivamente
datos |> 
  summarise("mean_turnout" = mean(turnout), .by = candidate)
# 쯥uficiente grande la diferencia para considerarlas suficiente?

# anova (obviamos de momento las condiciones)
aov(data = datos, turnout ~ candidate) |> 
  summary()
# SSE = 0.5
# SSR = 36.13

# var explicada = 0.4950 (insesgado)
# var residual = 0.0293 (insesgado)

# 쮺칩mo de grande es la var explicada vs no explicada?
# F = 0.4950 / 0.0293 = 16.92 (aprox)

# 쮼s suficientemente mayor que 1?

# p-valor = 0 (aprox) ==> F >>>> 1 ==>
# variabilidad de las medias en cada grupo es significativamente grande
# (respecto a la variabilidad inherente de turnout)
# ==> hay diferencias significativas entre las medias
```



### 游냒 Caso pr치ctico II: atractivo vs alcohol

Los datos los tenemos cargados directamente en `beer_goggles_effect.csv` 

```{r}
datos <-
  read_csv(file = "./datos/beer_goggles_effect.csv") 
datos
```

En la tabla tenemos guardado el g칠nero de 48 estudiantes, 24 mujeres y 24 hombres, divididos en 3 grupos de alcohol, que han encontrado una pareja que les atrae en un bar. Tambi칠n tenemos la cantidad de alcohol ingerida y el **atractivo medido en base a una puntuaci칩n del 0 al 100**, otorgada por unos "jueces" externos, de la pareja encontrada por cada participante.



> Convierte a factor ordinal y/o nominal lo que consideres

```{r}
#| code-fold: true
datos <-
  datos |> 
  mutate("gender" = factor(gender),
         "alcohol" =
           factor(alcohol, levels = c("None", "2 Pints", "4 Pints"),
                  ordered = TRUE))
```


#### Pregunta 1

> Visualiza la distribuci칩n de la variable cuantitativa `attractiveness`. Tras hacer los gr치ficos que consideres, 쯘s una variable normal?

```{r}
#| eval: false
#| code-fold: true

# densidad
ggplot(datos) +
  geom_density(aes(x = attractiveness)) +
  theme_minimal()

# q-q plot (vs normality)
ggplot(datos) +
  stat_qq(aes(sample = attractiveness)) +
  stat_qq_line(aes(sample = attractiveness)) +
  theme_minimal()

# 쯘s normal?
shapiro.test(datos$attractiveness)
```

#### Pregunta 2

> Repite el ejercicio anterior pero separando cada uno de los grupos de `alcohol`

```{r}
#| eval: false
#| code-fold: true

# densidades
ggplot(datos) +
  geom_density(aes(x = attractiveness, fill = alcohol,
                   color = alcohol), alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  facet_wrap(~alcohol, scales = "free_y") +
  theme_minimal()

ggplot(datos) +
  ggridges::geom_density_ridges(aes(x = attractiveness, y = alcohol,
                                    fill = alcohol, color = alcohol),
                                alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()

# q-q plot (vs normality)
ggplot(datos,
       aes(sample = attractiveness, fill = alcohol, color = alcohol)) +
  stat_qq(alpha = 0.5) +
  stat_qq_line() +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  facet_wrap(~alcohol, scales = "free_y") +
  theme_minimal()

# 쯘s normal?
# son normales en cada subgrupo tambi칠n
datos |> 
  summarise("p_value" = shapiro.test(attractiveness)$p.value,
            .by = alcohol)
```

#### Pregunta 3

> 쯀nfluye el grado de alcoholismo en lo atractivo que vemos a la gente? Responde a la pregunta como consideres. Responde de manera i) descriptiva; ii) visual y iii) inferencialmente

```{r}
#| eval: false
#| code-fold: true

# cuanti (atractiveness) vs cuali (alcohol) ==>  ANOVA
# queremos testar
# H_0: media de atractivo ("objetivo" seg칰n jueces) igual en cada grupo de alcohol
# H_1: alguna distinta

# 쮺u치les son las medias?
datos |> 
  summarise("mean_attractiveness" = mean(attractiveness), .by = alcohol)
# son diferentes (siempre lo van a ser por puro azar) pero...
# 쯥uficientemente diferentes?

# visualmente
ggplot(datos) +
  geom_violin(aes(x = alcohol, y = attractiveness,
                  fill = alcohol, color = alcohol), alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()

ggplot(datos) +
  geom_boxplot(aes(x = alcohol, y = attractiveness,
                  fill = alcohol, color = alcohol), alpha = 0.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  MetBrewer::scale_fill_met_d(palette_name = "Renoir") +
  theme_minimal()
# parece que optan por personas ligeramente m치s atractivas con 2 pintas
# pero decrece estrepitosamente con 4
# adem치s se pierde la simetr칤a de la variable seg칰n van borrachos
# 쯥uficientes diferencias?

ggplot(datos |>
         arrange(alcohol) |> 
         rowid_to_column(var = "id") |> 
         mutate("mean_attractiveness" = mean(attractiveness),
                .by = alcohol)) +
  geom_point(aes(x = id, y = attractiveness, color = alcohol),
             alpha = 0.5, size = 3) +
  geom_line(aes(x = id, y = mean_attractiveness, color = alcohol),
            linewidth = 2.5) +
  MetBrewer::scale_color_met_d(palette_name = "Renoir") +
  theme_minimal()

# inferencialmente: anova
aov(data = datos, attractiveness ~ alcohol) |> 
  summary()
# SSE = 1054
# SSR = 3575

# var explicada = 526.9 
# var no explicada = 79.4

# F = var explicada / var no explicada = 6.633

# pvalue = 0.00299 ==> la variabilidad de las medias (varianza explicada)
# es significativamente mayor que la no explicada ==> 
# rechazamos la igualdad de medias ==> hay diferencias significativas ==>
# alcohol influye en el atractivo que percibimos (somos menos exigentes) =>
# hay asociaci칩n
```


#### Pregunta 4

> En caso de que se hayan observado diferencias significativas, 쯤u칠 grupos son realmente diferentes entre s칤? Usa el mejor m칠todo post-hoc usando Bonferroni. 쮺u치l ser칤a m치s adecuado? que consideres suponiendo que los 3 grupos los tratamos por igual

```{r}
#| eval: false
#| code-fold: true

# 쯨arianzas iguales?
car::leveneTest(datos$attractiveness ~ datos$alcohol)
# no se rechaza igualdad de varianzas

# la normalidad ya la hemos comprobado
# mismo tama침o de grupos
datos |> 
  count(alcohol)

# podemos aplicar tukey (param칠trico)
# que controla mucho mejor el error de tipo II (mayor poder estad칤stico que Bonferroni)
aov(data = datos, formula = attractiveness ~ alcohol) |>
  TukeyHSD()
# sin alcohol vs 2 pintas ==> no significativo
# sin alcohol vs 4 pintas ==> diferencia significativas
# 2 pintas vs 4 pintas ==> diferencia significativas
```

#### Pregunta 5

> Repite la pregunta anterior pero considerando (como deber칤as) que el grupo de los abstemios es el grupo control.

```{r}
#| eval: false
#| code-fold: true

# tenemos que cumple todas las hip칩tesis ya comprobadas
DescTools::DunnettTest(x = datos$attractiveness, g = datos$alcohol,
                       control = "None")
# sin alcohol vs 2 pintas ==> no significativo
# sin alcohol vs 4 pintas ==> diferencias significativas
# podr칤amos decir que las diferencias son realmente significativas a partir de
# la segunda pinta
```

## Clase 8

### 游냒 Caso pr치ctico I: predicci칩n de iris

Vamos a empezar la regresi칩n con un ejemplo sencillo haciendo uso del archiconocido dataset `iris` donde tenemos para 150 plantas de 3 especies distintas guardado su longitud y anchura de s칠palo, y su longitud y anchura de p칠talo.

```{r}
datos <- iris |> as_tibble()
datos
```

#### Pregunta 1

> 쮺u치l de todas las variables va m치s por "libre" (no depende tanto de las dem치s) asumiendo una relaci칩n lineal?

```{r}
#| code-fold: true
#| eval: false
# forma 1
datos |> select(where(is.numeric)) |> cor()

# forma 2
datos |> select(where(is.numeric)) |> corrr::correlate()

# forma 3
datos |> select(where(is.numeric)) |> cor() |> corrplot::corrplot()

# la variable sepal.width es la que enos depende del resto (no as칤 petal width)
```


#### Pregunta 2

> Suponiendo que queremos predecir de manera lineal la variable ` Sepal.Length` haciendo uso de tan solo una predictora, 쯖on cu치l te quedar칤as y por qu칠? Si fu칠semos a meter todas las variables, 쯣odr칤amos hacerlo o tendr칤amos informaci칩n redundante que deber칤amos quitar

```{r}
#| code-fold: true
#| eval: false
datos |> select(where(is.numeric)) |> corrr::correlate()
# con aquella con mayor correlaci칩n en valor absoluto
# es decir Petal.Length

# no tiene sentido meter a la vez Petal.Length y Petal.Width
# ya que tienen una correlaci칩n de 0.963 --> aportan la misma info
# deber칤amos de hacer un an치lisis de colinealidad y retirar alguna
```



#### Pregunta 3

> Con la variable seleccionada realiza la formulaci칩n del modelo que planteas como hip칩tesis y ejecuta el c칩digo `lm()` adecuado. Interpreta hasta donde puedas en este momento del proceso. 

```{r}
#| echo: false
ajuste <- lm(data = datos, Sepal.Length ~ Petal.Length)
```

```{r}
#| code-fold: true
#| eval: false
# modelo:
# Sepal.Length = beta_0 + beta_1*Petal.Length + epsilon
# donde epsilon ~ N(0, sigma) tal que
# estimacion = beta_hat_0 + beta_hat_1*Petal.Length 
# tal que los beta_hat salen de una estimaci칩n por m칤nimos cuadrados

ajuste <- lm(data = datos, Sepal.Length ~ Petal.Length)
ajuste |> summary()

# beta_hat_0 = 4.30660  -> predicci칩n de la longitud del
# s칠palo cuando la longitud del p칠talo es nula
# Petal.Length = 0.40892  -> por cada cm que se incrementa
# la longitud del s칠palo, la longitud del p칠talo
# crece 0.40892 cm

# 0.4071 es la estimaci칩n insesgada de la 
# desv. t칤pica de la varianza residual -> cuantifica
# un promedio de los errores.

# Y HASTA AQU칈
```

#### Pregunta 4

> 쯈u칠 no puedes interpretar todav칤a y por qu칠?


```{r}
#| code-fold: true
# No podemos interpretar de momento nada m치s ya que
# R2: no sabemos interpretarlo a estas alturas del curso todav칤a
# p-valores: necesitamos que se cumplan las hip칩tesis
# para poder hacer inferencia
```

#### Pregunta 5

> Usa el c칩digo que consideres para calcular la media de los errores al cuadrado (MSE). Visualiza la distribuci칩n de los residuos

```{r}
#| code-fold: true
#| eval: false
MSE <- mean(ajuste$residuals^2)

ggplot(tibble("residuos" = ajuste$residuals)) +
  geom_density(aes(x = residuos)) +
  theme_minimal()

ggplot(tibble("residuos" = ajuste$residuals)) +
  stat_qq(aes(sample = residuos)) +
  stat_qq_line(aes(sample = residuos)) +
  theme_minimal()
```

#### Pregunta 6

> Construye una tabla con 3 columnas: (x, y, y_hat), siendo y_hat el valor predicho. Tras ello visualiza y vs y_hat para tener una calibraci칩n visual del acierto de nuestro modelo

```{r}
#| code-fold: true
tabla_predicciones <-
  tibble("x" = datos$Petal.Length,
         "y" = datos$Sepal.Length,
         "y_hat" = ajuste$fitted.values)

ggplot(tabla_predicciones) +
  geom_point(aes(x = y, y = y_hat)) +
  geom_line(aes(x = y, y = y), color = "#913131",
            linewidth = 1.4) +
  theme_minimal()
```

#### Pregunta 7

> 쮺칩mo crees que ser치 de buena la predicci칩n del modelo para una longitud de p칠talo de 12cm?

```{r}
#| code-fold: true
# da igual el R2, la varianza residual o los errores:
# el modelo no es fiable si x est치 fuera del rango
# de valores con los que has entrenado el modelo
```

## Clase 10

### 游냒 Caso pr치ctico III: colesterol


Vamos a intentar predecir los niveles de colesterol de 100 pacientes en funci칩n de otras variables predictoras

```{r}
datos <- read_csv(file = "./datos/colesterol.csv")
datos
```

#### Pregunta 1

> Nuestra variable objetivo es colesterol. Depura la variable eliminando datos ausentes e imputando c칩mo consideres los posibles valores at칤picos en dicha variable

```{r}
#| code-fold: true
#| eval: false

# eliminamos ausentes
datos <-
  datos |> 
  drop_na(colesterol)

# chequeamos outliers
ggplot(datos) +
  geom_boxplot(aes(y = colesterol)) +
  theme_minimal()
ggplot(datos) +
  geom_density(aes(x = colesterol)) +
  theme_minimal()
ggplot(datos) +
  stat_qq(aes(sample = colesterol)) +
  stat_qq_line(aes(sample = colesterol)) +
  theme_minimal()
olsrr::ols_test_normality(datos$colesterol)

# parece tenemos outliers
# y la variable parece normal
# ==> vamos a detectar los outliers seg칰n la media
# outlier: si se aleja 2.5 desviaciones t칤picas de la media
datos <-
  datos |> 
  mutate("outlier" =
           abs(outliers::scores(colesterol, type = "z")) > 2.5) 
datos |> filter(outlier)

# imputamos
datos <-
  datos |> 
  mutate("colesterol" = if_else(outlier, NA, colesterol),
         "colesterol" =
           if_else(is.na(colesterol),
                   mean(colesterol, na.rm = TRUE), colesterol))
# chequeamos que la distribuci칩n no ha variado sustancialmente
ggplot(datos) +
  geom_density(aes(x = colesterol)) +
  theme_minimal()
```


#### Pregunta 2

> 쮼xiste relaci칩n entre los niveles de colesterol y el sexo del paciente? Ejecuta el c칩digo que consideres para responder

```{r}
#| code-fold: true
#| eval: false

# num칠ricamente
datos |>
  drop_na(sexo) |> 
  summarise(mean(colesterol), .by = sexo)

# visualmente
ggplot(datos |> drop_na(sexo)) +
  geom_boxplot(aes(x = sexo, y = colesterol, fill = sexo,
                   color = sexo), alpha = 0.5) +
  MetBrewer::scale_color_met_d("Renoir") +
  MetBrewer::scale_fill_met_d("Renoir") +
  theme_minimal()
# se parecian diferencias peque침as: 쯥uficientes para decir que no?

# inferencialmente
aov(data = datos, colesterol ~ sexo) |> 
  summary()
# estimaci칩n insesgada de la varianza explicada:  5.06 
# estimaci칩n insesgada de la var no explicada: 166.64
# cociente entre ambas: F-value = 0.03
# resultado: p-valor >> 0.05 ==> no podemos rechazar H0
# no hay ev suficientes para decir que las medias sean disitntas
# no hay relaci칩n entre el sexo y los niveles de colesteorl
```



#### Pregunta 3

> Vamos a querer ahora predecir la variable colesterol mediante un modelo lineal univariante. 쯈u칠 variable ser칤a la mejor predictora? 쯇or qu칠?

```{r}
#| code-fold: true
#| eval: false
datos |> 
  select(where(is.numeric)) |> 
  corrr::correlate() |> 
  filter(term == "colesterol")
# la variable m치s correlada (en valor absoluto) es edad

# ambas variables son normales, podemos usar pearson
olsrr::ols_test_normality(datos |> drop_na(edad) |> pull(edad))

datos |> 
  select(where(is.numeric)) |> 
  cor(use = "complete.obs") |> 
  corrplot::corrplot()

ggplot(datos, aes(x = edad, y = colesterol)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()

# Es la m치s correlada pero suficientemente distinto de 0?
cor.test(datos$colesterol, datos$edad) # ==> s칤
```


#### Pregunta 4

> Formula el modelo. Comprueba que no hay missings ni outliers tampoco en edad (si los hubiese, imp칰talos por lo que consideres). Tras ello aplica lm(). Interpreta todo lo que sepas y puedas HASTA ESTE PUNTO del an치lisis.

```{r}
#| code-fold: true
#| eval: false

# s칤 tengo ausentes
datos |>
  count(is.na(edad))

# al ser normal la variable, se lo imputo por la media
datos <- 
  datos |> 
  mutate("edad" = if_else(is.na(edad), mean(edad, na.rm = TRUE),
                          edad))

# 쯛ay outliers? (detectados e imputados respecto a la media)
datos <-
  datos |> 
  mutate("outliers_edad" = abs(outliers::scores(edad, type = "z")) > 2.5) |> 
  mutate("edad" = if_else(outliers_edad, mean(edad), edad))

# modelo:
#  colesterol = beta_0 + beta_1 * edad
ajuste_lineal <-
  lm(data = datos, colesterol ~ edad)
ajuste_lineal |> summary()

# interpretaci칩n
# colesterol_hat = 97.3456 +  0.6795 * edad
# - si edad = 0 (es decir, lo basal de un ser humano),
#  el colesterol promedio predicho es de 97.3456
# - por cada a침o que envejecemos, el modelo predice EN PROMEDIO
#  que al colesterol aumenta en +0.6795

# Residual standard error: 10.66 --> estimaci칩n insesgada de
# la desviaci칩n t칤pica poblacional de los residuos

# Y FIN DE MOMENTO: no podemos interpretar m치s
```


#### Pregunta 5

> 쮺umple el modelo las condiciones inferenciales necesarias? 쯇ara que necesitamos que se cumplan?

```{r}
#| code-fold: true
#| eval: false

# 4. incorrelaci칩n
# visual (deber칤as no ver patr칩n)
ggplot(tibble("res" = ajuste_lineal$residuals[-1],
              "res_lag" =
                ajuste_lineal$residuals[-length(ajuste_lineal$residuals)])) +
  geom_point(aes(x = res, y = res_lag)) +
  theme_minimal()

# inferencial
performance::check_autocorrelation(ajuste_lineal)

# 3. normalidad
# visual
ggplot(tibble("res" = ajuste_lineal$residuals)) +
  stat_qq(aes(sample = res)) +
  stat_qq_line(aes(sample = res)) +
  theme_minimal()
ggplot(tibble("res" = ajuste_lineal$residuals)) +
  geom_density(aes(x = res)) +
  theme_minimal()

# inferencial
performance::check_normality(ajuste_lineal)


# 2. heterocedasticidad
# visual (deber칤a ver todo dentro deuna banda sin que aumente varianza)
ggplot(tibble("x" = datos$edad,
              "res" = ajuste_lineal$residuals)) +
  geom_line(aes(x = x, y = res)) +
  theme_minimal()

# inferencial
performance::check_heteroscedasticity(ajuste_lineal)

# 1. linealidad
# visual (deber칤a ver todo sin patr칩n=
ggplot(tibble("y_hat" = ajuste_lineal$fitted.values,
              "res" = ajuste_lineal$residuals)) +
  geom_point(aes(x = y_hat, y = res)) +
  theme_minimal()

# inferencial
# lineal
lm(data = tibble("y_hat" = ajuste_lineal$fitted.values,
                 "res" = ajuste_lineal$residuals),
   res ~ y_hat) |> summary()
# cuadr치tico
lm(data = tibble("y_hat" = ajuste_lineal$fitted.values,
                 "res" = ajuste_lineal$residuals),
   res ~ y_hat + I(y_hat^2)) |> summary()

# c칰bico
lm(data = tibble("y_hat" = ajuste_lineal$fitted.values,
                 "res" = ajuste_lineal$residuals),
   res ~ y_hat + I(y_hat^2) + I(y_hat^3)) |> summary()

# todo a la vez
performance::check_model(ajuste_lineal)
```


#### Pregunta 6

> Si fuese posible interpreta el resto de la salida inferencial del modelo. Detalla todo lo que consideras.

```{r}
#| code-fold: true
#| eval: false

# ahora s칤
ajuste_lineal <-
  lm(data = datos, colesterol ~ edad)
ajuste_lineal |> summary()

# beta_0 ~ N(97.3456, sigma = 6.0564)
# beta_1 ~ N(0.6795 , sigma = 0.1065)
# p-valores < 0.05 ==> ambos par치metros son significativos no hay que quitarlos
# R2 de momento en clsae 10 no sabemos (pero si lo haces y ya sabes interpreta)
```


#### Pregunta 7

> Piensa el c칩digo necesario para obtener las 2 siguientes gr치ficas e interpr칠talas.

```{r}
#| echo: false
ajuste_lineal <- lm(data = datos, colesterol ~ edad)
```

```{r}
#| code-fold: true
beta_0_sim <-
  rnorm(n = 1000, mean = ajuste_lineal$coefficients[1], sd = 6.0564)
beta_1_sim <-
  rnorm(n = 1000, mean = ajuste_lineal$coefficients[2], sd = 0.1065)
betas_sim <- 
  tibble(beta_0_sim, beta_1_sim) |> 
  pivot_longer(cols = everything(), names_to = "param", values_to = "values")

ggplot(betas_sim) +
  geom_density(aes(x = values, fill = param, color = param),
               alpha = 0.5) +
  MetBrewer::scale_color_met_d("Renoir") +
  MetBrewer::scale_fill_met_d("Renoir") +
  facet_wrap(~param, scales = "free") +
  theme_minimal() +
  labs(title = "Betas simulados")

predic_simul <-
  datos |> 
  reframe("id_simul" = rep(1:1000, each = length(edad)),
          "x" = rep(edad, 1000),
          "y_hat" = beta_0_sim + beta_1_sim*x)
ggplot(predic_simul) +
  geom_density(aes(x = y_hat, group = id_simul),
               color = "grey20", alpha = 0.2, linewidth = 0.1) +
  geom_density(data =
                 tibble("y_hat" = ajuste_lineal$fitted.values),
               aes(x = y_hat), color = "red", linewidth = 1.5) +
  theme_minimal() +
  labs(title = "Simulaci칩n predicciones",
       subtitle = "1000 simulaciones")
```

## Clase 11

### 游냒 Caso pr치ctico I: simulaci칩n


#### Pregunta 1

> Simula unos datos ($n = 500$) bajo la hip칩tesis (junta $y$ y $x$ en la misma tabla) de que

$$Y = -1 + 3*X + \varepsilon, \quad  X \sim N(-3, \sigma = 1.2), \quad \varepsilon \sim N(0, \sigma = 3)$$

```{r}
#| code-fold: true
eps <- rnorm(n = 500, mean = 0, sd = 3)
x <- rnorm(n = 500, mean = -3, sd = 1.2)
y <- -1 + 3*x + eps
datos <- tibble(y, x)
```

#### Pregunta 2

> Ajusta un modelo de regresi칩n lineal univariante e interpreta todo lo que consideres (asume que la diagnosis se cumple ya que lo hemos simulado para que as칤 sea) 

```{r}
#| code-fold: true
ajuste_inicial <- lm(data = datos, y ~ x)
ajuste_inicial |> summary()
```

#### Pregunta 3

>  Dise침a un bucle de 490 iteraciones de manera que, en cada iteraci칩n, incorpores a la tabla una nueva predictora $X_i \sim N(0, 1)$. F칤jate que las [**predictoras nuevas no tienen ning칰n tipo de relaci칩n con $y$**]{.hl-red} (son "basura" para el modelo). En cada iteraci칩n haz un ajuste de $y$ vs todas y guarda su $R2$

```{r}
#| code-fold: true
R2 <- c()
for (i in 1:490) {
  
  datos[, i + 2] <-  rnorm(n = 500, mean = 0, sd = 1)
  R2[i] <- (lm(data = datos, y ~ .) |> summary())$r.squared
  
}
```

#### Pregunta 4

>  Crea una tabla con dos columnas: iteraci칩n y R2. Tras ello visualiza la evoluci칩n del R2 en funci칩n del n칰mero de la iteraci칩n (=n칰mero de predictoras basura). Interpreta lo que observes

```{r}
#| code-fold: true
tabla_R2 <- tibble("iter" = 1:490, "R2" = R2)
ggplot(tabla_R2) +
  geom_line(aes(x = iter, y = R2), linewidth = 1.5) +
  theme_minimal() +
  labs(x = "N칰mero de predictoras basura")
# Moraleja: a mayor n췈 de predictoras, m치s se infla R^2
# 춰aunque sean basura!
```

#### Pregunta 5

> Simula una colecci칩n de datos ($n = 500$) bajo la hip칩tesis de que $Y = -1 + 3*X_1 + \varepsilon$ con $X \sim N(-3, \sigma = 1.2)$ y

* `datos_1`: $\varepsilon \sim N(0, \sigma = 0.5)$, `datos_2`: $\varepsilon \sim N(0, \sigma = 1)$

* `datos_3`: $\varepsilon \sim N(0, \sigma = 2)$, `datos_4`: $\varepsilon \sim N(0, \sigma = 4)$

* `datos_5`: $\varepsilon \sim N(0, \sigma = 8)$, `datos_6`: $\varepsilon \sim N(0, \sigma = 12)$

```{r}
#| code-fold: true
x <- rnorm(n = 500, mean = -3, sd = 1.2)
y <- -1 + 3*x

datos_1 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 0.5), x)
datos_2 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 1), x)
datos_3 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 2), x)
datos_4 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 4), x)
datos_5 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 8), x)
datos_6 <- tibble("y" = y + rnorm(n = 500, mean = 0, sd = 12), x)
```

#### Pregunta 6

> Realiza los 6 ajustes, uno para cada dataset, siempre $y$ vs $x$. **IMPORTANTE**: f칤jate que la parte a explicar, la modelizable, la parte no aleatoria, 춰es siempre la misma! As칤 que el modelo deber칤a ser parecido siempre. Usa `compare_performance()` para compararlos.

```{r}
#| code-fold: true
#| eval: false
ajuste_1 <- lm(data = datos_1, formula = y ~ x)
ajuste_2 <- lm(data = datos_2, formula = y ~ x)
ajuste_3 <- lm(data = datos_3, formula = y ~ x)
ajuste_4 <- lm(data = datos_4, formula = y ~ x)
ajuste_5 <- lm(data = datos_5, formula = y ~ x)
ajuste_6 <- lm(data = datos_6, formula = y ~ x)

performance::compare_performance(ajuste_1, ajuste_2, ajuste_3, ajuste_4, ajuste_5, ajuste_6)
# 춰La supuesta calidad del ajuste desciende dr치sticamente,
# siendo igual de bueno! La parte que se puede predecir est치
# perfectamente ajustada pero tenemos m치s ruido en los
# datos (ruido = no modelizable)
```



#### Pregunta 7

> Y si tenemos un modelo con un alto $R^2$, 쯡o hace falta que cumpla las hip칩tesis?. Bas치ndote en  $X \sim N(-3, \sigma = 1.5)$ y $\varepsilon \sim N(0, \sigma = 1)$  con $n = 500$, simula un modelo entre $X$ e $Y$ que incumpla la hip칩tesis de linealidad.

```{r}
#| code-fold: true
eps <- rnorm(n = 500, mean = 0, sd = 1)
x <- rnorm(n = 500, mean = -3, sd = 1.5)
y <- -1.5 + 2*x - 3*x^2 # por ejemplo
datos <- tibble(x, y)
```

#### Pregunta 8

>  Realiza el ajuste lineal y visualiza residuos vs valores predichos.

```{r}
#| code-fold: true
ajuste <- lm(data = datos, y ~ x)

tabla_residuos <- tibble("eps_hat" = ajuste$residuals, "y_hat" = ajuste$fitted.values)
ggplot(tabla_residuos) +
  geom_point(aes(x = y_hat, y = eps_hat)) +
  theme_minimal()
# deber칤as observar en los residuos el patr칩n que en
# los datos no modelizaste o no tuviste en cuenta

```


#### Pregunta 9

> Simula los datos bajo la siguiente hip칩tesis ($x_i = 0.01 + 0.01*(i-1)$) 

$$y_i = 1 - 2x_i(1 + 0.25 \sin(4 \pi x_i)) + \varepsilon_i, \quad \varepsilon_i \sim N(0, \sigma_i = 0.25 * x_{i}^2 )$$


Junta todo en un dataset de 3 columnas: y, x y $\sigma_i$. 쯈u칠 hip칩tesis se incumplen?

```{r}
#| code-fold: true
x <- seq(0.01, 2, l = 500)
eps <- rnorm(n = 500, mean = 0, sd = 0.2 * x^2)
y <- 1 - 2 * x * (1 + 0.25*sin(4 * pi * x)) + eps
datos <- tibble("y" = y, "x" = x, "sigma" =  0.2 * x^2)
```

#### Pregunta 10

> Realiza el ajuste de $y ~ x$ y observa el $R^2$

```{r}
#| code-fold: true
ajuste_lineal <- lm(data = datos, formula = y ~ x)
ajuste_lineal |> summary()
```

#### Pregunta 11

> F칤jate que tenemos un $R^2$ bastante alto pero... 쯦iene sentido su interpretaci칩n? Pinta en un diagrama de puntos + recta de regresi칩n los datos $x$ vs $y$.

```{r}
#| code-fold: true
ggplot(datos, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal()
# Aunque el R^2 es bastante alto, el modelo no tiene sentido,
# dando estimaciones cada vez m치s erradas
```





