---
title: "Data programming and intro to R"
subtitle: "Prepare, clean, transform and enrich data in R"
title-slide-attributes:
  data-background-image: img/background-mucss.webp
  data-background-size: cover
  data-background-opacity: "0.2"
author: "Master in Computational Social Sciences â€¢ Javier Ãlvarez LiÃ©bana"
affiliation: Facultad de Estudios EstadÃ­sticos (UCM)
lang: es
language: custom_lang.yml
format: 
  revealjs:
    theme: [default, style.scss]
    menu:
      side: left
      width: normal
    footer: "[<strong>Javier Ãlvarez LiÃ©bana</strong>](...) â€¢ Master in Computational Social Sciences (UC3M)"
    slide-number: c/t
execute:
  echo: true
---

::: r-fit-text
[Welcome to R!]{.flow}
:::

[**Put your spreadsheets, SAS and SPSS aside**]{style="color:#444442;"}

---

## Hi!

[**Mail**]{.hl-green}: **<javalv09@ucm.es>**.

::: columns
::: {.column width="30%"}
![](img/me.jpeg)
:::

::: {.column width="70%"}
::: incremental
-   [**Javier Ãlvarez LiÃ©bana**]{.hl-yellow} from Carabanchel (Madrid).

-   Degree in Mathematics (UCM). [**PhD in Statistics**]{.hl-yellow} (UGR).

-   In charge of  [**data visualization and analysis**]{.hl-yellow} for the Principality of Asturias (2021-2022) during the COVID pandemic

-   Member of the [**Spanish Society of Statistics and OR**]{.hl-yellow} and the [**Spanish Royal Mathematical Society**]{.hl-yellow}.


:::
:::
:::


Currently, [**Assistant Professor at the Faculty of Statistics of the UCM**]{.hl-yellow}. Disseminating via [**Twitter**](https://twitter.com/dadosdelaplace) e [**Instagram**](https://instagram.com/javieralvarezliebana)


---

## Goals

::: columns
::: {.column width="37%"}
![](https://assets-global.website-files.com/6092cb6b4ac959f39728dd26/6188a97fa499b5fbfe410417_target%20(1).png)
:::

::: {.column width="63%"}
::: incremental
- Take away the [**fear of programming**]{.hl-yellow} â†’ learn to program by programming

- Understanding [**basic R concepts**]{.hl-yellow} from scratch â†’ learning to **abstract** ideas and algorithms

- Utility of programming â†’ [**reproducible, transparent and maintainable workflows**]{.hl-yellow}.

- Introduction to [**analysis and preprocessing of data**]{.hl-yellow} â†’ `{tidyverse}`.

- Handling [**advanced data types**]{.hl-yellow} â†’ `{forcats}`, `{lubridate}` and `{purrr}` packages

:::
:::
:::


---

## Evaluation: intro to R

-  [**Attendance and individual participation**]{.hl-yellow} (30%)

. . .

- [**Final exam**]{.hl-yellow} on 10/09/2024, 15:00-16:10 (70%). 

. . .

* [**Max grade**]{.hl-yellow}: to get a grade greater than 9/10 you should get at least 9/10 in the final exam.

---

## Evaluation: data programming

-  [**Attendance and individual participation**]{.hl-yellow} (10%)

. . .

- [**2 individual tasks**]{.hl-yellow} done during the course (20%-25%)

. . .

- [**1 group task**]{.hl-yellow} between 4 and 6 people (20%). **Deadline**: 23/12/2024.

. . .

- [**Final exam**]{.hl-yellow} with all materials and internet (25%). [**You are exempt if you get more than 7.5/10**]{.hl-purple} in the previous tasks.

. . .

* [**Max grade**]{.hl-yellow}: to get a grade greater than 9/10 you should get at least 9/10 in the individual tasks.


---

## Planning

* [**Final exam (intro R 70%)**]{.hl-yellow}: 10/09/2024 (15:00 - 16:10).

&nbsp;

* [**Individual task I (20%)**]{.hl-yellow}: deadline 03/11/2024

* [**Individual task II (25%)**]{.hl-yellow}: deadline 30/11/2024

* [**Group task (20%)**]{.hl-yellow}: deadline 23/12/2024.

&nbsp;

* [**Final exam (25% if required)**]{.hl-yellow}: TBA


---

## Planning: intro R {#planificacion}

::: column-screen-inset-right
::: {style="font-size:20px"}
|  LESSON | WEEK | DATES | TOPIC | EX. | WORKBOOK | TASK | 
|:------:|:--------:|:--------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| [0-1](#clase-0-1) | S1 | 2 sep | First steps: R base programming | [ğŸ’»](#tu-turno-0-1-1) [ğŸ’»](#tu-turno-0-1-2)  |  |  | 
| [0-2](#clase-0-2) | S1 | 4 sep | First data: concatenate values and databases | [ğŸ’»](#tu-turno-0-2-1) [ğŸ’»](#tu-turno-0-2-2) [ğŸ’»](#tu-turno-0-2-3) |  [ğŸ£](#caso-practico-0-2-1) [ğŸ£](#caso-practico-0-2-2) |  |
| [0-3](#clase-0-3) | S1 | 6 sep | Quarto and if-else | [ğŸ’»](#tu-turno-0-3-1) [ğŸ’»](#tu-turno-0-3-2) [ğŸ’»](#tu-turno-0-3-3) |  [ğŸ£](#caso-practico-0-3-1) [ğŸ£](#caso-practico-0-3-2) [ğŸ£](#caso-practico-0-3-3) |  |
| [0-4](#clase-0-4) | S2 | 10 sep | Final task| | | [ğŸ¯ (70%)](#clase-0-4) |
:::
:::

---

## Planning: data programming {#planificacion-curso}

::: column-screen-inset-right
::: {style="font-size:20px"}
|  LESSON | WEEK | DATES | TOPIC | EX. | WORKBOOK | TASK | 
|:------:|:--------:|:--------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| [1](#clase-1) | S2 | 12 sep | Intro to tidy data | [ğŸ’»](#tu-turno-1-1) [ğŸ’»](#tu-turno-1-2)  | [ğŸ£](#caso-practico-1) |  | 
| [2](#clase-2) | S3 | 19 sep | Tidyverse: by rows | [ğŸ’»](#tu-turno-2-1) [ğŸ’»](#tu-turno-2-2)  | [ğŸ£](#caso-practico-2) |  | 
| [3](#clase-3) | S4 | 26 sep | Tidyverse: by columns | [ğŸ’»](#tu-turno-3-1) [ğŸ’»](#tu-turno-3-2)  | [ğŸ£](#caso-practico-3-1) [ğŸ£](#caso-practico-3-2) [ğŸ£](#caso-practico-3-3)|  | 
| [4](#clase-4) | S5 | 3 oct | Tidyverse: summary | [ğŸ’»](#tu-turno-4-1)  | [ğŸ£](#caso-practico-4-1) [ğŸ£](#caso-practico-4-2) |  | 
| [5](#clase-5) | S6 | 10 oct | Loops | [ğŸ’»](#tu-turno-5-1)  | [ğŸ£](#caso-practico-5-1) [ğŸ£](#caso-practico-5-2) |  |
| [6](#clase-6) | S7 | 17 oct | Functions and joins |  [ğŸ’»](#tu-turno-6-1) [ğŸ’»](#tu-turno-6-2)  | [ğŸ£](#caso-practico-6-1) [ğŸ£](#caso-practico-6-2) [ğŸ£](#caso-practico-6-3)  |  |
| [7](#clase-7) | S8 | 24 oct | Import/export |  [ğŸ’»](#tu-turno-7-1) | [ğŸ£](#caso-practico-7-1) [ğŸ£](#caso-practico-7-2)  |  |
| [8](#clase-8) | S10 | 6 nov | Purrr and forcats packages  |   |  |  |
| [9](#clase-9) | S11 | 13 nov | Github and SQL connection |   |  |  |
:::
:::


  
---

## Materials

* [**Slides**]{.hl-yellow}: slides made with `Quarto` available and updated on **<https://javieralvarezliebana.es/docencia/mucss-data-programming>**. In the slide menu (bottom left) you have an option to  [**download them in pdf**]{.hl-yellow} in `Tools`

&nbsp;

* [**Material**]{.hl-yellow}: [**workbooks**](https://javieralvarezliebana.es/docencia/mucss-data-programming/material/) and extra materials.

* [ğŸ—ƒ **Data**]{.hl-yellow}: datasets that will be used, available on **<https://javieralvarezliebana.es/docencia/mucss-data-programming/material>**

* [ğŸ“š **Extra resources**]{.hl-yellow}:  <https://r4ds.had.co.nz/>, <https://cdr-book.github.io/> and <https://ivelasq.quarto.pub/intro-to-quarto/>.

---

## Datasets

* [ğŸ—ƒ **Data**]{.hl-yellow}: datasets that will be used, available on **<https://github.com/dadosdelaplace/docencia/tree/main/mucss-data-programming/slides/data>**

&nbsp;

* `airquality` from the `{datasets}` package (already installed by default): daily measurements (153 observations) of air quality in New York, from May to September 1973. Measured **6 variables**: ozone, solar radiation, wind, temperature, month and day.

* `surveys`: we have all **poll surveys for Spain from 1982 to 2019** collected from Wikipedia.

* `discursos`: compiles the Christmas speeches of the heads of state in Spain (under dictatorship and democracy) from 1946 to 2021.


---

## Datasets

* [ğŸ—ƒ **Data**]{.hl-yellow}: datasets that will be used, available on **<https://github.com/dadosdelaplace/docencia/tree/main/mucss-data-programming/slides/data>**

&nbsp;

* `relig_income` from the `{tidyr}` package: compiles annual income data by religion (original source <https://www.pewresearch.org/religion/religious-landscape-study/>)

* `who2` from the `{tidyr}` package: WHO data on tuberculosis infections, disaggregated by disease type, sex and age.

* `billboard` from the `{tidyr}` package: top 100 ranking of songs according to Billboard (something like The 40) for the year 2000.

* `world_bank_pop` from the `{tidyr}` package: data from the World Bank about population per country from 2000 to 2018.


# L1: [first steps]{.flow} {#clase-0-1}



[**Introduction to R and RStudio. Working with projects. First uses of functions and packages. Basic data types**]{style="color:#444442;"}

* [ğŸ’» Solved exercises: first steps](#tu-turno-0-1-1)
* [ğŸ’» Solved exercises: first variables](#tu-turno-0-1-2)
* [ğŸ“† Planning](#planificacion)

---

## Requirements

For the course, the only requirements will be:

1. [**Internet connection**]{.hl-yellow} (to download some data and packages).

. . .

2. [**Install R**]{.hl-yellow}: it will be our language. We will download it (for free) from <https://cran.r-project.org/>

. . .

3. [**Install RStudio**]{.hl-yellow} from <https://posit.co/download/rstudio-desktop/>

::: columns
::: {.column width="50%"}

![](img/cranR.jpg){width="420"}

:::


::: {.column width="50%"}

![](img/rstudio.jpg){width="420"}

:::
:::

---

## R vs RStudio

::: columns
::: {.column width="50%"}
![](img/gramatica.webp){width="360"}
:::

::: {.column width="50%"}
![](img/word.jpg){width="430"}
:::
:::


::: {.fragment .fade-in-then-out}

We will program as we write 

:::

::: {.fragment .fade-up}

-   We will need a [**grammar, a language**]{.hl-yellow} (`R`)

::: {.fragment .fade-in}

-   And an environment, such as [**Word**]{.hl-yellow} (`RStudio`) to write it

:::
:::

---

## Installing R

The `R` language will be our [**grammar and spelling**]{.hl-yellow} (our rules of the game)


::: incremental
-   [**Step 1**]{.hl-yellow}: go to <https://cran.r-project.org/> and select your operating system.

-   [**Step 2**]{.hl-yellow}: for Mac, simply click on the **.pkg file**, and open it once downloaded. For Windows systems, we need to click on **install R for the first time** and then on **Download R for Windows**. Once downloaded, open it like any installation file.

-   [**Step 3**]{.hl-yellow}: open the installation executable.

:::

. . .

::: callout-warning

Whenever you need to download something from CRAN (either `R` itself or a package), [**make sure you have an internet connection**]{.hl-orange}.

:::

---

## First operation {auto-animate="true"}

::: columns
::: {.column width="60%"}

To check the installation, after opening `R`, you should see the `R GUI` (Graphical User Interface) with a **white screen** similar to this ([**console**]{.hl-yellow}).

:::

::: {.column width="40%"}
![](img/consola.jpg){width="200"}
:::
:::

. . .

[**First code**]{.hl-yellow}: we will **assign** the value `1` to a variable called `a` (we will write the code in the console and press "enter"). Then we will do the sum `a + b`.

```{r}
#| code-line-numbers: "1"
a <- 1
```

---

## First operation {auto-animate="true"}

::: columns
::: {.column width="60%"}

To check the installation, after opening `R`, you should see the `R GUI` (Graphical User Interface) with a **white screen** similar to this ([**console**]{.hl-yellow}).

:::

::: {.column width="40%"}
![](img/consola.jpg){width="200"}
:::
:::

[**First code**]{.hl-yellow}: we will **assign** the value `1` to a variable called `a` (we will write the code in the console and press "enter"). Then we will do the sum `a + b`.

```{r}
#| code-line-numbers: "2"
a <- 1
b <- 2
```

---

## First operation {auto-animate="true"}

::: columns
::: {.column width="60%"}

To check the installation, after opening `R`, you should see the `R GUI` (Graphical User Interface) with a **white screen** similar to this ([**console**]{.hl-yellow}).

:::

::: {.column width="40%"}
![](img/consola.jpg){width="200"}
:::
:::

[**First code**]{.hl-yellow}: we will **assign** the value `1` to a variable called `a` (we will write the code in the console and press "enter"). Then we will do the sum `a + b`.

```{r}
#| code-line-numbers: "3"
a <- 1
b <- 2
a + b
```

. . .

::: callout-note
## Note that...

In the console, a number `[1]` appears: it's simply an element counter (like counting rows in Word)

:::

---

## Installing R Studio

`RStudio` will be the [**Word**]{.hl-yellow} we will use to write (what is known as an [**IDE: Integrated Development Environment**]{.hl-yellow}).

::: incremental
-   [**Step 1**]{.hl-yellow}: go to the [official RStudio website](https://posit.co/download/rstudio-desktop/) (now called Posit) and select the free download.

-   [**Step 2**]{.hl-yellow}: select the executable that appears according to your operating system.

-   [**Step 3**]{.hl-yellow}: after downloading the executable, open it like any other and let the installation finish.

:::

---

## RStudio Organization

When you open `RStudio` you will likely have three windows:


-   [**Console**]{.hl-yellow}: is the name for the large window that takes up most of your screen. Try writing the same code as before (the sum of the variables) in it. The console is where **we will execute commands and display results**.

![](img/consola_rstudio.jpg){width="420"}

---

## RStudio Organization

When you open `RStudio` you will likely have three windows:

-   [**Environment**]{.hl-yellow}: the small screen (you can adjust the margins with the mouse to your liking) that we have in the top right corner. It will show us the **variables we have defined**.


![](img/environment.jpg){width="420"}

---

## RStudio Organization

When you open `RStudio` you will likely have three windows:

-   [**Multi-purpose panel**]{.hl-yellow}: the window at the bottom right will be used to **look for function help**, as well as to **visualize plots**.

![](img/multiusos.jpg){width="420"}

---

## What is R? Why R?

![](img/meme_barco.jpg)

---


## What is R? Why R?

![](img/incel_excel.png)

`R` is the evolution of the work of Bell Laboratories with the `S` language, which was brought into the open-source world by Ross Ihaka and Robert Gentleman in the 1990s. The version `R 1.0.0` was released on February 29, 2000.


---

## What is R? Why R?

`R` is the [**statistical language par excellence**]{.hl-yellow}, created by and for statisticians, with 6 fundamental advantages [**over Excel, SAS, Stata, or SPSS**]{.hl-red}:

. . .

-   [**Programming language**]{.hl-yellow}: the obvious â†’ [**replicable**]{.hl-purple} analysis

. . .

-   [**Free**]{.hl-yellow}: the philosophy of the `R` community is to share code under **copyleft** â†’ **ethical use of spending and algorithms**

. . .

-   [**Open-source software**]{.hl-yellow}: not only is it free, but it also allows free access to others' code, even to the **source code itself** â†’ [**flexibility and transparency**]{.hl-purple} (Free and Open Source Software FOSS)

---

## What is R? Why R?

`R` is the [**statistical language par excellence**]{.hl-yellow}, created by and for statisticians, with 6 fundamental advantages [**over Excel, SAS, Stata, or SPSS**]{.hl-red}:


-   [**Modular language**]{.hl-yellow}: we have installed the minimum, but there are codes from other people that we can reuse (almost 20,000 [**packages**]{.hl-yellow}) â†’ [**time saving**]{.hl-purple} and [**immediate innovation**]{.hl-purple}

. . .

-   [**High-level language**]{.hl-yellow}: facilitates programming (like Python) â†’ [**lower learning curve**]{.hl-purple}

. . .

- [**Community and employability**]{.hl-yellow}: along with Python, it is the most used language in the field of statistics and data science in research, teaching, companies (LÃ­nea Directa, Mapfre, TelefÃ³nica, Orange, Apple, Spotify, Netflix, El PaÃ­s, Civio, HP, etc.) and public organizations (ISCIII, CNIC, CNIO, INE, IGN, CIS, CEO, DGT, AEMET, RTVE, etc.)

---

## Why programming?

-   [**Automate**]{.hl-yellow} â†’ it will allow you to automate recurring tasks.

-   [**Replicability**]{.hl-yellow} â†’ you will be able to replicate your analysis in the same way every time.

-   [**Flexibility**]{.hl-yellow} â†’ you will be able to adapt the software to your needs.

-   [**Transparency**]{.hl-yellow} â†’ to be audited by the community.

![](img/the_general_problem.png)

---

## Fundamental Idea: Packages

One of the key ideas of `R` is the [**use of packages**]{.hl-yellow}: codes that other people have implemented to **solve a problem**


::: columns
::: {.column width="35%"}
![](img/paquetes.png)
:::

::: {.column width="65%"}
::: {.fragment fragment-index="1"}

-   [**Installation**]{.hl-yellow}: we download the codes from the web (we need internet) â†’ [**buy a book**]{.hl-purple}, only once (per computer)


```{r}
#| eval: false
install.packages("ggplot2")
```
:::

::: {.fragment fragment-index="2"}

-   [**Loading**]{.hl-yellow}: with the package downloaded, we indicate which packages we want to use each time we open `RStudio` â†’ [**take the book off the shelf**]{.hl-purple}

```{r}
#| eval: false
library(ggplot2)
```

:::
:::
:::

---

## Fundamental Idea: Packages

::: columns
::: {.column width="35%"}
![](img/paquetes.png)
:::

::: {.column width="65%"}

Once installed, there are **two ways to use a package** (take it off the shelf)

::: {.fragment fragment-index="1"}

-   [**Whole package**]{.hl-yellow}: with `library()`, using the package name without quotes, we load [**the whole book**]{.hl-purple} into the session


```{r}
#| eval: false
library(ggplot2)
```
:::

::: {.fragment fragment-index="2"}

-   [**Specific functions**]{.hl-yellow} using `package::function+  we indicate that we only want [**a specific page of that book**]{.hl-purple}


```{r}
#| eval: false
ggplot2::geom_point()
```
:::
:::
:::

---

## You will be wrong

During your learning, it will be very common for things not to work out on the first try â†’ [**you will be wrong**]{.hl-yellow}. It will not only be important to accept it but also [**to read the error messages**]{.hl-yellow} to learn from them.


. . .

-   [**Error messages**]{.hl-red}: preceded by **"Error in..."** and will be those failures that [**prevent execution**]{.hl-red}

```{r}
#| error: true
"a" + 1 
```

. . .

-   [**Warning messages**]{.hl-orange}: preceded by **Â«Warning in...Â»** they are the (possible) more delicate errors as they are inconsistencies that [**do not prevent execution**]{.hl-orange}


```{r}
#| warning: true
# Ejecuta la orden pero el resultado es NaN, **Not A Number**, un valor que no existe
sqrt(-1)
```

---

## Scripts (.R files)


::: columns
::: {.column width="35%"}
![](img/abrir_script.jpg){width="350"}
:::

::: {.column width="65%"}

A [**script**]{.hl-yellow} will be the document in which we program, our `.doc` file (here with a `.R` extension) where we will write the commands. To **open our first script**, click on the menu in `File < New File < R Script`.


::: callout-warning
## Be careful

It's important **not to overuse the console**: everything you don't write in a script, when you close, [**will be lost**]{.hl-orange}.

:::

:::
:::



::: callout-warning
## Be careful

`R` is [**case-sensitive**]{.hl-orange}: it is sensitive to uppercase and lowercase, so `x` and `X` represent different variables.

:::


---

## Running the first script

Now we have a **fourth window**: the window where we will [**write our codes**]{.hl-yellow}. How do we run it?

. . .

1. **Write the code** to be executed.

. . .

2. **Save the .R file** by clicking on `Save current document`.

. . .

3. The code does not execute unless we indicate it. We have **three options to run a script**:

- [**Copy and paste**]{.hl-yellow} into the console.
- [**Select lines**]{.hl-yellow} and press `Ctrl+Enter`
- [**Enable Source on Save**]{.hl-yellow} next to save: not only saves but also executes the **entire code**.

---


## Organizing: projects

Just as we usually work [**organized by folders**]{.hl-yellow} on the computer, in `RStudio` we can do the same to work [**efficiently by creating projects**]{.hl-yellow}.

. . .

::: columns
::: {.column width="60%"}

A [**project will be a "folder"**]{.hl-yellow} within `RStudio`, so our root directory will automatically be the project folder itself (allowing us to switch from one project to another using the top right menu).

We can create one in a new folder or in an existing folder."

:::

::: {.column width="40%"}
![](img/rstudio_proyectos.png){width="370"}
:::
:::


---

## ğŸ’» It's your turn {#tu-turno-0-1-1}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Create in your computer a folder of the subject and create inside it the `RStudio` project: it is there where you are going to save everything that we will do along this course, after creating the project you will have an `R Project` file. Then create in this folder two subfolders: `data` (this is where you will save the different datasets that we will use) and `scripts` (this is where you will save the `.R` files of each class).

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Inside the project create a script `Exercises-class1.R` (inside the `scripts` folder). Once created, define in it a variable named `a` and whose value is -1. Execute the code in the (three) ways explained before.

```{r}
#| code-fold: true
a <- -1
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Add below another line to define a variable `b` with the value 5. Then save the multiplication of both variables. Execute the code as you want.

```{r}
#| code-fold: true
#| eval: false
b <- 5
a * b # without saving it
mult <- a * b # save it
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Modify the code below to define two variables c and d, with values 3 and -1. Then divide the variables and save the result.

```{r}
#| eval: false
c <- # you should assign 3
d <- # you should assign -1
```

```{r}
#| code-fold: true
#| eval: false
c <- 3
d <- -1
c / d
div <- c / d
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Assign to `x` a positive value and then compute its square root; assign to `y` a negative number and compute its absolute value using `abs()`.

```{r}
#| code-fold: true
#| eval: false
x <- 5
sqrt(x)

y <- -2
abs(y)
```

::: callout-note
## Note that...

Commands like `sqrt()`, `abs()` or `max()` are what we call [**functions**]{.hl-purple}: lines of code that we have "encapsulated" under a name, and given some input arguments, execute the commands (a sort of shortcut). In the functions the [**arguments will ALWAYS be enclosed in parentheses**]{.hl-yellow}

:::


### [**Exercise 6**]{.hl-yellow}

ğŸ“ Using the variable `x` already defined, complete/modify the code below to store in a new variable `z` the result stored in `x` minus 5.

```{r}
#| eval: false
z <- ? - ? # complete the code
z
```

```{r}
#| code-fold: true
#| eval: false
z <- x - 5
z
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ Define an `x` variable and assign it the value `-1`. Define another `y` and assign it the value `0`. Then perform the operations a) `x` by `y`; b) square root of `x`. What do you get?


```{r}
#| code-fold: true
#| eval: false
x <- -1
y <- 0

x / y
sqrt(x)
```

### [**Exercise 8**]{.hl-yellow}

ğŸ“ Write the code below in your script. Why do you think it doesn't work?

```{r}
#| error: true
x <- -1
y <- 0

X + y
```

:::



---

## From CELL to TABLE

What [**data type**]{.hl-yellow} can we have in each **cell of a table**?



![](img/celdas.jpg)

::: incremental

- [**Cell**]{.hl-yellow}: an individual piece of data of a specific type.
- [**Variable**]{.hl-yellow}: **concatenation** of values of the same type ([**vectors in R**]{.hl-purple}).
- [**Matrix**]{.hl-yellow}: concatenation of variables of the **same type and length**.
- [**Table**]{.hl-yellow}: concatenation of variables of [**different types but the same length**]{.hl-purple}
- [**List**]{.hl-yellow}: concatenation of variables of [**different types and different lengths**]{.hl-purple}
:::

---

## But first...best practices

Before we continue, itâ€™s important to know something as soon as possible: [**starting with programming can be frustrating**]{.hl-yellow}

. . .

Just like when learning a new language, the first obstacle is not so much what to say but how to say it correctly. The same goes for `R`, so letâ€™s [**standardize our programming style**]{.hl-yellow} as much as possible to avoid future errors.

. . .

* [**Tip 1**]{.hl-green}: [**assignment, evaluation, and comparison are not the same**]{.hl-yellow}. If youâ€™ve noticed in `R`, we use `<-` to assign values to variables. We use `=` to evaluate function arguments and `==` to check if two elements are equal.

```{r}
#| eval: false
x <- 1 # asign
x = 1 # evaluation
x == 1 # comparison
```



---

## But first...best practices

* [**Tip 2**]{.hl-green}: program like you write. Just like when writing in Spanish, get used to incorporating [**spaces and line breaks**]{.hl-yellow} to avoid making your code hard to read (it's a good practice, not a requirement, because `R` does not process spaces).


```{r}
#| eval: false
x <- 1 # optimal
x<-1 # meh
x<- 1 # worst (make up your mind)
```

. . .

* [**Tip 3**]{.hl-green}: donâ€™t be chaotic, [**standardize names**]{.hl-yellow}. Always get used to naming variables consistently. The only requirement is that **they must always start with a letter** (and without accents). The most recommended form is `snake_case`.



```{r}
#| eval: false
variable_in_snake_case
anotherHarderToReadFormat
there.are.people.who.use.this
Even_People_Here.Confusing_That_Do_Not_Deserve_Our_ATTENTION
```

---

## But first...best practices

* [**Tip 4**]{.hl-green}: make reading and writing easier, [**set limits**]{.hl-yellow}. In `Tools < Global Options`, you can customize some options in `RStudio`. In `Code < Display`, you can set `Show margin` to display an "imaginary" margin (not interacting with the code) to "force" you to make line breaks.

![](img/show_margin.jpg)


---

## But first...best practices

* [**Tip 5**]{.hl-green}: the [**tab key is your best friend**]{.hl-yellow}. In `RStudio`, thereâ€™s a wonderful tool: if you type part of a variable or function name and press tab, `RStudio` will autocomplete it for you.


![](img/tab-autocompletar.png)  


---

## But first...best practices

* [**Tip 6**]{.hl-green}: no single parentheses. Whenever you open a parenthesis, you must close it. To make this task easier, go to `Tools < Global Options < Code < Display` and enable the `Rainbow parentheses option`.

![](img/rainbow-parentheses.jpg)



---

## But first...best practices

* [**Tip 7**]{.hl-green}: pay attention to the left side. You will not only see the line of code you are on but also, in case of a [**syntax error**]{.hl-red}, `RStudio` will notify you.

![](img/rstudio-error-sintaxis.png)

* [**Tip 8**]{.hl-green}: try to [**always work by projects**]{.hl-yellow} (for this class, create a script `class1.R` in the project we created before)


&nbsp;

See more tips at <https://r4ds.had.co.nz/workflow-basics.html#whats-in-a-name>

---

## Cells: data types

Are there [**variables beyond numbers in data science**]{.hl-yellow}? For example, think about the data you might store about a person:


::: {.fragment .fade-up}
-  Age or weight will be a [**number**]{.hl-yellow}.

```{r}
age <- 33
```
:::

::: {.fragment .fade-up}
- Their name will be a string of [**text (known as string or char)**]{.hl-yellow}.

```{r}
name <- "javi"
```

:::

::: {.fragment .fade-up}
-   The answer to the question "Are you enrolled in the Faculty?" will be what we call a [**logical variable**]{.hl-yellow} (`TRUE` if enrolled or `FALSE` otherwise).


```{r}
enrolled <- TRUE
```
:::

::: {.fragment .fade-up}
-   Their date of birth will be precisely that, a [**date**]{.hl-yellow}.
:::

---

## Numerical variables {auto-animate="true"}

The simplest data (which weâ€™ve already used) will be [**numeric variables**]{.hl-yellow}. To find out the [**data class in R**]{.hl-yellow} of a variable, we use the `class()` function.


```{r}
#| eval: false
#| code-line-numbers: "1"
a <- 5
```

---

## Numerical variables {auto-animate="true"}

The simplest data type (we have already used it) will be the [**numeric variables**]{.hl-yellow}. To know the [**data class in R**]{.hl-yellow} of a variable we have the function `class()`.


```{r}
#| eval: false
#| code-line-numbers: "2"
a <- 5
class(a)
```

. . .

```{r}
#| echo: false
#| include: false
a <- 5
b <- 2
a + b
```

To know its [**typology (format)**]{.hl-yellow} variable we have `typeof()`.

```{r}
typeof(1) # 1 value but stored as a real number (double precision)
typeof(as.integer(1)) # 1 value but stored as a floor number
```

::: callout-note
## Note that...

In `R` we have a collection of functions starting with `as.x()` that serve as [**conversion functions**]{.hl-yellow}: a data that was of one type, we convert it to type `x`.
:::

---


## Numerical variables

In addition to the "common" numbers we will have the [**plus/minus infinity**]{.hl-yellow} coded as `Inf` or `-Inf`.

```{r}
1/0
```

```{r}
-1/0
```

. . .

And values that [**are not real numbers**]{.hl-yellow} _not a number_ (indeterminacies, complexes numbers, etc) encoded as `NaN`.

```{r}
0/0
```

```{r}
sqrt(-2)
```



---

## Numerical variables

With numeric variables we can perform the [**arithmetic operations**]{.hl-yellow} of a calculator: adding (`+`)...

```{r}
a + b
```

. . .

...square root (`sqrt()`)...

```{r}
sqrt(a)
```

. . .

... power (`^2`, `^3`)...

```{r}
a^2
```

. . .

...absolute value (`abs()`), etc.

```{r}
abs(a)
```


---

## String variables

Let us imagine that, in addition to the age of a person we want to store his/her name: now the variable will be of type `character`.

```{r}
name <- "Javi"
class(name)
```

. . .

The [**text strings**]{.hl-yellow} are a type with which we obviously [**cannot perform arithmetic operations**]{.hl-red} (other operations such as pasting or locating patterns can be performed).

```{r}
#| error: true
name + 1 # error when we try to sum 1 to a text
```

. . .

::: callout-warning
## Reminder

Text variables (character or string) are [** ALWAYS in quotes**]{.hl-orange}: `TRUE` (logical, binary value) is not the same as `"TRUE"` (text).

:::

---

## First function: paste

As we have commented `R` we will call [**function**]{.hl-yellow} a piece of [**encapsulated code**]{.hl-yellow} under a name, and which depends on some input [**arguments**]{.hl-yellow}. Our first function will be `paste()`: given two strings, it allows us to paste them together.

```{r}
paste("Javi", "Ãlvarez")
```

. . .

Note that [**default**]{.hl-yellow} pastes strings with a space, but we can add an [**optional argument**]{.hl-yellow} to tell it the separator (in `sep = ...`). 

```{r}
paste("Javi", "Ãlvarez", sep = "*")
```

---

## First function: paste

::: columns
::: {.column width="50%"}
![](img/paste_help.jpg)
:::

::: {.column width="50%"}

How do I know [**what arguments does a function need**]{.hl-yellow}?

By typing `? paste` in the console, you will get a [**help**]{.hl-yellow} in the multipurpose panel, where you can see in its header what arguments the function already has [**default arguments**]{.hl-yellow} assigned to it.

:::
:::

. . .

There is a similar function called `paste0()` that pastes by default with `sep = â€œâ€` (without anything).

```{r}
paste0("Javi", "Ãlvarez")
```

---

## First function: paste

The arguments (and their detail) can also be consulted by **tabulating (after a comma)**.

![](img/tab-functions.png)

--- 

## Functions: default arguments

It is very important to understand the concept of [**default argument of a function**]{.hl-yellow} in `R`: it is a value that the function uses but sometimes we may not see because [**already has a value assigned**]{.hl-yellow}. 
```{r}
# Same
paste("Javi", "Ãlvarez")
paste("Javi", "Ãlvarez", sep = " ")
```

. . .

::: callout-note

The `=` operator is [**reserved for assigning arguments**]{.hl-yellow} within functions. For all other assignments, we will use `<-`.

:::

---

## First package: glue

A more intuitive way to work with text is to use the `{glue}` package: the first thing to do is to "buy the book" (if we have never done it before). After that [**load the package**]{.hl-yellow}

```{r}
#| eval: false
install.packages("glue") # just the first time
library(glue)
```

```{r}
#| echo: false
library(glue)
```

. . .

With the `glue()` function of that package we can use [**variables inside strings**]{.hl-yellow}. For example, "age is ... years old", where the age is stored in a variable.

```{r}
age <- 34
glue("I am {age} old")
```

. . .

Within the keys we can also [**execute operations**]{.hl-yellow}

```{r}
units <- "days"
glue("I am {age * 365} {units} old")
```

---

## Logical variables

Another fundamental type will be the [**logical or binary variables**]{.hl-yellow} (**two values**):

- `TRUE`: [**true**]{.hl-yellow} stored internally as a 1.

- `FALSE`: [**false**]{.hl-yellow} stored internally as a 0.

```{r}
single <- FALSE # Single? --> NO
class(single)
```

. . .

Since they are stored internally as binary variables, we can [**perform arithmetic operations**]{.hl-yellow} on them


```{r}
2 * TRUE
FALSE - 1
```

---

## Logical variables

As we will see shortly, logical variables can actually take a third value: `NA` or [**missing data**]{.hl-yellow}, representing *not available*, and it will be very common to find it within a database.

```{r}
missing <- NA
missing + 1
```


. . .

::: callout-important
## Important

Logical variables [**NOT text variables**]{.hl-red}: `"TRUE"` is a text, `TRUE` is a logical value.

```{r}
#| error: true
TRUE + 1
"TRUE" + 1
```
:::

---

## Logical conditions

Logical values are usually the result of [**evaluate logical conditions**]{.hl-yellow}. For example, imagine that we want to [**check**]{.hl-yellow} whether a person is named Javi.


```{r}
name <- "MarÃ­a"
```


. . .

With the [**logical operator**]{.hl-yellow} `==` we ask if what we have stored on the left is [**same as**]{.hl-purple} what we have on the right: [**we ASK**]{.hl-yellow}

```{r}
name == "Javi"
```

. . .

With its opposite `!=` we ask [**if different**]{.hl-purple}.

```{r}
name != "Javi"
```

. . .

::: callout-note
## Note that...

It is not the same `<-` ([**assignment**]{.hl-yellow}) as `==` (we are [**asking**]{.hl-yellow}, it is a logical comparison).

:::

---

## Logical conditions

In addition to "equal to" versus "different" comparisons, also order comparisons such as [**less than**]{.hl-purple} `<`, [**greater than**]{.hl-purple} `>`, `<=` or `>=`.
**Is the person less than 32 years old?**

```{r}
age <- 34
age < 32 # less than 32 years old?
```

. . .

**Age is greater than or equal to 38 years?**

```{r}
age >= 38
```

. . .

**Is the saved name equal to Javi?**

```{r}
name <- "Javi"
name == "Javi"
```

---

## Date variables

A very special data type: the [**date type data**]{.hl-yellow}.

```{r}
date_char <- "2021-04-21"
```

It looks like a simple text string but [**should represent an instant in time**]{.hl-yellow}. What should happen if [**we add a 1 to a date**]{.hl-purple}?

. . .

```{r}
#| error: true
date_char + 1
```


Dates [**cannot be string/text**]{.hl-red}: we must convert the text string to date.

. . .

&nbsp;

To work with dates we will use the `{lubridate}` package, which we must install before we can use it.

```{r}
#| eval: false
install.packages("lubridate")
```

---

## Date variables

Once installed, of all the packages (books) that we have, we will indicate it to load this one concretely.

```{r}
library(lubridate) 
```

. . .

To [**convert to date type**]{.hl-yellow} we will use the `as_date()` function of the `{lubridate}` package (default in `yyyy-mm-dd` format).


&nbsp;

:::: columns
::: {.column width="50%"}

```{r}
#| error: true

# it's not a date, it's a text!
date_char + 1
class(date_char)
```

:::

::: {.column width="50%"}

```{r}
date <- as_date("2023-03-28")
date + 1
class(date)
```

:::

::::

---

## Date variables

In `as_date()` the default date format is `yyyy-mm-dd` so if the string is not entered correctly...

```{r}
as_date("28-08-2024")
```

. . .

For [**any other format we must specify it**]{.hl-yellow} in the optional argument `format = ...` such that `%d` represents days, `%m` months, `%Y` in 4-year format and `%y` in 2-year format.


```{r}
as_date("28-03-2023", format = "%d-%m-%Y")
as_date("28-03-23", format = "%d-%m-%y")
as_date("03-28-2023", format = "%m-%d-%Y")
as_date("28/03/2023", format = "%d/%m/%Y")
```


---

## Date variables

In this package we have very useful functions for [**date management**]{.hl-yellow}:

- With `today()` we can directly obtain the [**current date**]{.hl-purple}.

```{r}
today()
```

. . .

-  With `now()` we can obtain [**current date and time**]{.hl-purple}

```{r}
now()
```

. . .

- With `year()`, `month()` or `day()` we can [**extract year, month and day**]{.hl-purple}

```{r}
date_today <- today()
year(date_today)
month(date_today)
```

---

## Cheatsheets

![](img/lubridate.png)

::: callout-note
## More information

You have a pdf summary of the most important packages in the [**corresponding folder on campus**]{.hl-green}

:::

---

## ğŸ’» It's your turn {#tu-turno-0-1-2}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Define a variable that stores your age (called `age`) and another with your name (called `name`).

```{r}
#| code-fold: true
age <- 34
name <- "Javi"
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Check with this variable `age` if it is NOT 60 years old or if it is called `"Ornitorrinco"` (you must obtain logical variables as a result).

```{r}
#| code-fold: true
#| eval: false
age != 60 # different to
name == "Ornitorrinco" # equal to
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Why does the lower code give an error?

```{r}
#| error: true
age + name
```


### [**Exercise 4**]{.hl-yellow}

ğŸ“ Define another variable called `siblings` that answers the question "do you have siblings?" and another variable that stores your date of birth (called `birth_date`).

```{r}
#| code-fold: true
siblings <- TRUE

library(lubridate) # if not before
birth_date <- as_date("1989-09-10")
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Define another variable with your last name (called `surname`) and use `glue()` to have, in a single variable called `full_name`, your first and last name separated by a comma.

```{r}
#| code-fold: true
#| eval: false
surname <- "Ãlvarez LiÃ©bana"
full_name <- glue("{name}, {surname}")
full_name
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ From `birth_date` extract the month.

```{r}
#| code-fold: true
#| eval: false
month(birth_date)
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ Calculate the days that have passed since your birth date until today (with the birth date defined in Exercise 4).

```{r}
#| code-fold: true
#| eval: false
today() - birth_date
```
:::

# L2 : [databases]{.flow} {#clase-0-2}

[**Concatenating cells: vectors. First databases**]{style="color:#444442;"}

* [ğŸ’» Solved exercises: vectors](#tu-turno-0-2-1) 

* [ğŸ’» Solved exercises: matrix](#tu-turno-0-2-2) 

* [ğŸ’» Solved exercises: data.frame and tibble](#tu-turno-0-2-3) 

* [ğŸ£ Workbook/case study I-II](#caso-practico-0-2-1)

* [ğŸ“† Planning](#planificacion)

---

## Vectors: concatenation

When working with data, we often have [**columns that represent variables**]{.hl-yellow}: we will refer to these as [**vectors**]{.hl-yellow}, which are a [**concatenation**]{.hl-purple} of cells (values) of the [**same type**]{.hl-purple} (similar to a column in a table).

. . .

The simplest way to create a vector is with the `c()` function (c stands for **concatenate**), and you just need to input the **elements within parentheses, separated by commas**.

```{r}
ages <- c(32, 27, 60, 61)
ages
```

. . .

::: callout-tip

An individual number `x <- 1` (or `x <- c(1)`) is actually a **vector of length one** --> everything we know how to [**do with a number, we can do with a vector of numbers**]{.hl-green}.

:::

---

## Vectors: concatenation

::: columns
::: {.column width="40%"}
![](img/edades_environment.jpg)
:::

::: {.column width="60%"}

As you can see now in the `environment`, we have a **collection of elements** stored.


```{r}
ages # ages = edades in spanish
```
:::
:::

. . .


The [**length of a vector**]{.hl-yellow} can be calculated with `length()`.


```{r}
length(ages)
```

. . .

We can also [**concatenate vectors**]{.hl-yellow} together (it repeats them one after another).

```{r}
c(ages, ages, 8)
```

---

## Numeric sequences

The most common type of vector is numeric, specifically, the well-known [**numeric sequences**]{.hl-yellow} (e.g., the days of the month), used among other things, to index loops.

. . .

The `seq(start, end)` function allows us to create a [**numeric sequence]**{.hl-yellow} from a starting element to an ending one, [**advancing one by one**]{.hl-purple}.


```{r}
seq(1, 31)
```

. . .

Note that if we try this with [**characters, it won't work**]{.hl-red} since there is no predefined order among text strings.

```{r}
#| error: true
"a":"z"
```

---

## Numeric sequences

A shortcut is the `1:n` command, which returns the same as `seq(1, n)`.


```{r}
1:7
```

If the starting element is greater than the ending one, it understands that the sequence is in [**descending order**]{.hl-purple}.

```{r}
7:-3
```

. . .

We can also define [**a different step**]{.hl-yellow} between consecutive elements with the `by = ...` argument.


```{r}
seq(1, 7, by = 0.5) # seq from 1 to 7, with a step of 0.5
```

---

## Numeric sequences

Sometimes we may want to define a [**sequence with a specific length**]{.hl-yellow}.


```{r}
seq(1, 50, l = 7) # seq from 1 to 50 with length equal to 7
```

. . .

We might also want to generate a vector of [**n repeated elements**]{.hl-yellow}.

```{r}
rep(0, 7) # vector of 7 0's
```

. . .

Since they are internally stored as numbers, we can also do this with [**dates**]{.hl-yellow}.


```{r}
seq(as_date("2023-09-01"), as_date("2023-09-10"), by = 1)
```


---

## String vectors

A vector is a **concatenation** of elements of the [**same type**]{.hl-yellow}, but they don't necessarily have to be numbers. Let's create a sample sentence.

```{r}
sentence <- "My name is Javi"
sentence
length(sentence)
```

. . .

In the previous case, it wasn't a vector, it was a single text element. To create a vector, we need to use `c()` again and separate elements with commas.


```{r}
sentence <- c("My", "name", "is", "Javi")
sentence
length(sentence)
```

---

## String vectors

What will happen if we [**concatenate elements of different types**]{.hl-yellow}?

. . .

```{r}
c(1, 2, "javi", "3", TRUE)
```

Note that since all elements must be of the same type, what `R` does is [**convert**]{.hl-yellow} everything to text, violating the [**data integrity**]{.hl-red}.


. . .

```{r}
c(3, 4, TRUE, FALSE)
```

It's important to understand that logical values are actually [**internally stored as 0/1**]{.hl-yellow}.


---

## Operations with vectors

With numeric vectors, we can perform the same [**arithmetic operations**]{.hl-yellow} as with numbers â†’ a [**number is a vector**]{.hl-purple} (of length one).

. . .

What will happen if we [**add or subtract a value**]{.hl-yellow} to a vector?

. . .

```{r}
x <- c(1, 3, 5, 7)
x + 1
x * 2
```

::: callout-warning
## Warning

Unless otherwise specified, in `R`,  vector operations are always [**element by element**]{.hl-orange}.

:::

---

## Adding vectors

Vectors can also interact with each other, so we can define, for example, [**vector sums**]{.hl-yellow} (element by element).


```{r}
x <- c(2, 4, 6)
y <- c(1, 3, 5)
x + y
```

. . .

Since the operation (e.g., a sum) is performed element by element, what will happen if we [**add two vectors of different lengths**]{.hl-yellow}?

. . .


```{r}
z <- c(1, 3, 5, 7)
x + z
```

What it does is [**recycle elements**]{.hl-yellow}: if we have a vector of 4 elements and we add another with 3 elements, it will recycle the elements from the shorter vector.

---

## Comparing vectors

A very common operation is to [**ask questions of the data**]{.hl-yellow} using [**logical conditions**]{.hl-purple}. For example, if we define a vector of temperatures...

[**Which days were below 22 degrees?**]{.hl-yellow}


```{r}
x <- c(15, 20, 31, 27, 15, 29)
```

. . .

```{r}
x < 22
```

This will return a [**logical vector**]{.hl-yellow}, depending on whether **each element** meets the given condition (of the **same length** as the vector being queried).

. . .

If we had a [**missing value**]{.hl-yellow} (due to a sensor error that day), the evaluated condition would also be `NA`.


```{r}
y <- c(15, 20, NA, 31, 27, 7, 29, 10)
y < 22
```

---

## Comparing vectors

[**Logical conditions can be combined**]{.hl-yellow} in two ways:

- [**Intersection**]{.hl-yellow}: [**all**]{.hl-purple} concatenated conditions must be met ([**AND conjunction**]{.hl-purple} with `&`) to return `TRUE`.


```{r}
x < 30 & x > 15
```

- [**Union**]{.hl-yellow}: it is enough for [**at least one**]{.hl-purple} condition to be met ([**OR conjunction**]{.hl-purple} with `|`).


```{r}
x < 30 | x > 15
```

. . .

With `any()` and `all()`, we can check if [**all elements**]{.hl-yellow} satisfy the condition.

```{r}
any(x < 30)
all(x < 30)
```

---

## Getting elements

Another common operation is [**accessing or getting elements**]{.hl-yellow}. The simplest way is to use the `[i]`  operator (access the i-th element).

```{r}
ages <- c(20, 30, 33, NA, 61) 
ages[3] # get the age's third person
```

. . .

Since a number is just a vector of length one, this operation can also be applied using a [**vector of indices to select**]{.hl-yellow}.

```{r}
y <- c("hi", "how", "are", "you", "?")
y[c(1:2, 4)] # first, second and fourth element
```

. . .

::: callout-tip

To access the last element without worrying about its position, you can pass the vector's length as the index `x[length(x)]`.

:::

---

## Removing elements

Sometimes, instead of selecting, we may want to [**remove elements**]{.hl-yellow}. This is done with the same operation but using [**negative indexing**]{.hl-purple}: the opetator `[-i]` Â«un-selectÂ» the i-th element 

```{r}
y
y[-2] # everything except the second element
```


. . .

In many cases, we want to [**select or remove elements based on logical conditions**]{.hl-yellow}, depending on the values, so we will pass the condition itself as the index (remember, `x < 2` returns a logical vector).


```{r}
ages <- c(15, 21, 30, 17, 45)
names <- c("javi", "marÃ­a", "sandra", "carla", "luis")
names[ages < 18] # names of people under 18
```

---


## Stats operations

We can also make use of [**statistical operations**]{.hl-yellow}, such as `sum()`, which, given a vector, returns the sum of all its elements.

```{r}
x <- c(1, -2, 3, -1)
sum(x)
```

[**What happens when a data point is missing?**]{.hl-yellow}

. . .

```{r}
x <- c(1, -2, 3, NA, -1)
sum(x)
```

By default, if we have a missing data point, the [**operation will also result in a missing value**]{.hl-yellow}. To [**ignore that missing data**]{.hl-purple}, we use the optional argument `na.rm = TRUE`.


```{r}
sum(x, na.rm = TRUE)
```

---

## Stats operations

As we've mentioned, logical values are internally stored as 0 and 1, so we can use them in arithmetic operations.

For example, if we want to [**find out the number of elements that meet a condition**]{.hl-yellow} (e.g., less than 3), those that do will be assigned a 1 (`TRUE`), and those that don't will get a 0 (`FALSE`). Therefore, summing the logical vector will give us the number of elements that meet the condition.


```{r}
x <- c(2, 4, 6)
sum(x < 3)
```

---

## Stats operations

Another common operation that can be useful is the [**cumulative sum**]{.hl-yellow} with `cumsum()`, which, given a vector, returns a vector where each element is the sum of the first, the first plus the second, the first plus the second plus the third, and so on.

```{r}
x <- c(1, 5, 2, -1, 8)
cumsum(x)
```

[**What happens when a data point is missing?**]{.hl-yellow}


```{r}
x <- c(1, -2, 3, NA, -1)
cumsum(x)
```

In the case of the cumulative sum, what happens is that [**from that point onward, all subsequent accumulated values will be missing**]{.hl-yellow}.

---

## Stats operations

Another common operation that can be useful is the [**difference (with delay)**]{.hl-yellow} with `diff()` which, given a vector, returns a vector with the second minus the first, the third minus the second, the fourth minus the third...and so on.


```{r}
x <- c(1, 8, 5, 3, 9, 0, -1, 5)
diff(x)
```

. . .

Using the argument `lag = ` we can indicate the [**delay**]{.hl-yellow} of this difference (e.g. `lag = 3` implies that the fourth minus the first, the fifth minus the second, etc.).


```{r}
x <- c(1, 8, 5, 3, 9, 0, -1, 5)
diff(x, lag = 3)
```

---

## Stats operations

Other common operations are [**mean**]{.hl-yellow}, [**median**]{.hl-yellow}, [**percentiles**]{.hl-yellow}, etc.

- [**mean**]{.hl-yellow}: centrality measure that consists of adding all the elements and dividing by the number of elements added. The best known but the [**least robust**]{.hl-red}: given a set, if outliers (very large or very small values) are introduced, the mean is very easily perturbed.


```{r}
x <- c(165, 170, 181, 191, 150, 155, 167, NA, 173, 177)
mean(x, na.rm = TRUE)
```

---

## Stats operations

Other common operations are [**mean**]{.hl-yellow}, [**median**]{.hl-yellow}, [**percentiles**]{.hl-yellow}, etc.


-   [**Median**]{.hl-yellow}: measure of centrality that consists of ordering the elements and keeping the one that occupies the middle.

```{r}
x <- c(165, 170, 181, 191, 150, 155, 167, 173, 177)
median(x)
```

. . .

-   [**Quantiles**]{.hl-yellow}: position measurements (they divide the data into equal parts).

```{r}
quantile(x) # by default quantiles/percentiles 0-25-50-75-100
quantile(x, probs = c(0.1, 0.4, 0.9))
```

---


## Sorting vectors

Finally, a common action is to know [**sort values**]{.hl-yellow}:

- `sort()`: returns the [**sorted vector**]{.hl-yellow}. By default from smallest to largest but with `decreasing = TRUE` we can change it.


```{r}
ages <- c(81, 7, 25, 41, 65, 20, 33, 23, 77)
sort(ages)
sort(ages, decreasing = TRUE)
```

. . .

-   `order()`: returns the [**index vector**]{.hl-yellow} that we would have to use to have the vector ordered

```{r}
order(ages)
ages[order(ages)]
```

---

## ğŸ’» It's your turn {#tu-turno-0-2-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Define the vector `x` as the concatenation of the first 5 odd numbers. Calculate the length of the vector

```{r}
#| code-fold: true
#| eval: false
# Two ways
x <- c(1, 3, 5, 7, 9)
x <- seq(1, 9, by = 2)

length(x)
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Access the third element of `x`. Access the last element (regardless of length, a code that can always be executed). Delete the first element.

```{r}
#| code-fold: true
#| eval: false
x[3]
x[length(x)]
x[-1]
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Get the elements of `x` greater than 4. Calculate the vector `1/x` and store it in a variable.

```{r}
#| code-fold: true
#| eval: false
x[x > 4]
z <- 1/x
z
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Create a vector representing the names of 5 people, one of whom is unknown.

```{r}
#| code-fold: true
#| eval: false
names <- c("Javi", "Sandra", NA, "Laura", "Carlos")
names
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Find from the vector `x` of exercises above the elements greater (strictly) than 1 and less (strictly) than 7. Find a way to find out if all the elements are positive or not.


```{r}
#| code-fold: true
#| eval: false
x[x > 1 & x < 7]
all(x > 0)
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ Given the vector `x <- c(1, -5, 8, NA, 10, -3, 9)`, why does its mean return not a number but what is shown in the code below?

```{r}
x <- c(1, -5, 8, NA, 10, -3, 9)
mean(x)
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ Given the vector `x <- c(1, -5, 8, NA, 10, -3, 9)`, extract the elements occupying the locations 1, 2, 5, 6. 

```{r}
#| code-fold: true
#| eval: false
x <- c(1, -5, 8, NA, 10, -3, 9)
x[c(1, 2, 5, 6)]
x[-2]
```

### [**Exercise 8**]{.hl-yellow}

ğŸ“ Given the `x` vector of the previous exercise, which ones have a missing data? Hint: the `is.something()` functions check if the element is of type `something` (press tab).


```{r}
#| code-fold: true
#| eval: false
is.na(x)
```


### [**Exercise 9**]{.hl-yellow}

ğŸ“ Define the vector `x` as the concatenation of the first 4 even numbers. Calculate the number of elements of `x` strictly less than 5.

```{r}
#| code-fold: true
#| eval: false
x[x < 5] 
sum(x < 5)
```


### [**Exercise 10**]{.hl-yellow}

ğŸ“ Calculate the vector `1/x` and obtain the ordered version (from smallest to largest) in the two possible ways

```{r}
#| code-fold: true
#| eval: false
z <- 1/x
sort(z)
z[order(z)]
```

### [**Exercise 11**]{.hl-yellow}

ğŸ“ Calculate min and max of previous `x` vector

```{r}
#| code-fold: true
#| eval: false
min(x)
max(x)
```

### [**Exercise 12**]{.hl-yellow}

ğŸ“ Find of the vector `x` the elements greater (strictly) than 1 and less (strictly) than 6. Find a way to find out if all the elements are negative or not.

```{r}
#| code-fold: true
#| eval: false
x[x > 1 & x < 7]
all(x > 0)
```

:::


---

## More with string variables

Although we cannot do arithmetic operations with them, some [**operations we can do with the text strings**]{.hl-yellow} will be important.

For that we will use in the future the `{stringr}` package (within the same `{lubridate}` "universe of packages", which we will talk about later).

```{r}
library(stringr)

# Find a correct phone format
phone_number <- c("611093", "292039", "628810585", "600917043")
str_detect(phone_number, pattern = "[6]{1}[0-9]{8}")
```

---

## First databases

When analyzing data we usually have [**several variables**]{.hl-yellow} for each individual: we need a "table" to collect them. The most immediate option is [**matrices**]{.hl-yellow}: concatenation of variables of [**same type and equal length**]{.hl-purple}.

Imagine we have heights and weights of 4 people. How to [**create a dataset with the two variables**]{.hl-yellow}?

. . .

The most common option is to use `cbind()`: [**concatenate (bind) vectors in the form of columns (c)**]{.hl-yellow}

```{r}
#| code-line-numbers: "3"
h <- c(150, 160, 170, 180)
w <- c(63, 70, 85, 95)
data_mat <- cbind(h, w)
data_mat 
```

---

## First databases

We can also [**build the matrix by rows**]{.hl-yellow} with the `rbind()` function (concatenate - bind - by rows - r), although it is [**recommended to have each variable in column**]{.hl-green} and individual in row as we will see later.

```{r}
rbind(h, w) # Matrix by rows
```

. . .

- We can [**"view" the matrix**]{.hl-yellow} with `View(matrix)`.

. . .

-   We can [**check dimensions**]{.hl-yellow} with `dim()`, `nrow()` and `ncol()`: matrices are a type of **tabular data** (organized in rows and columns).

```{r}
dim(data_mat)
nrow(data_mat)
ncol(data_mat)
```

---

## First databases

We can also [**"flip" (transposed matrix)**]{.hl-yellow} with `t()`.

```{r}
t(data_mat)
```

. . .

Since we now have two dimensions in our data, to [**access elements with `[]`**]{.hl-yellow} we must provide **two comma-separated indexes**: row and column indexes 

```{r}
data_mat[2, 1] # second row, first column
data_mat[1, 2] # first row, second column
```

---

## First databases

In some cases we will want to get the [**total data for an individual**]{.hl-yellow} (a particular row but all columns) or the values of [**a whole variable**]{.hl-yellow} for all individuals (a particular column but all rows). To do so, we leave [**one of the indexes**]{.hl-yellow} unfilled.

```{r}
data_mat[2, ] # second individual
data_mat[, 1] # first variable
```

. . .

Much of what we have learned with vectors we can do with matrices, so we can for example access multiple rows and/or columns using the [**sequences of integers 1:n**]{.hl-yellow}


```{r}
data_mat[c(1, 3), 1] # first variable for first and third individual
```


---

## First databases

We can also define a [**matrix from a numeric vector**]{.hl-yellow}, rearranging the values in the form of a matrix (knowing that the elements are [**placed by columns**]{.hl-purple}).

```{r}
z <- matrix(1:9, ncol = 3) 
z
```

. . .

We can even [**define an array of constant values**]{.hl-yellow}, e.g. of zeros (to be filled later)


```{r}
matrix(0, nrow = 2, ncol = 3)
```


---

## Matrix operations

With matrices it is the same as with vectors: when we apply an [**arithmetic operation we do it element by element**]{.hl-yellow}

```{r}
z/5
```

. . .

To perform [**operations in a matrix sense**]{.hl-yellow} we must add `%%%`, for example, to multiply matrices it will be `%*%`.

```{r}
z * t(z)
z %*% t(z)
```


---

## Matrix operations

We can also [**perform operations by columns/rows**]{.hl-yellow} without loops with the `apply()` function, and we will indicate as **arguments**

- the matrix
- the sense of the operation (`MARGIN = 1` for rows, `MARGIN = 2` for columns)
- the function to apply
- extra arguments needed by the function

. . .

For example, to apply an average to each variable, it will be `mean` applied with `MARGIN = 2` (same function for each column).

```{r}
# Mean for each column (MARGIN = 2)
apply(data_mat, MARGIN = 2, FUN = "mean")
```



---

## ğŸ’» It's your turn {#tu-turno-0-2-2}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ Modify the code below to define an `x` matrix of ones, with 3 rows and 7 columns.

```{r}
#| eval: false
x <- matrix(0, nrow = 2, ncol = 3)
x
```

```{r}
#| code-fold: true
#| eval: false
x <- matrix(1, nrow = 3, ncol = 7)
x
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ To the above matrix, add 1 to each number in the matrix and divide the result by 5. Then calculate its transpose

```{r}
#| code-fold: true
#| eval: false
new_matrix <- (x + 1)/5
t(new_matrix)
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Why does the code below return such a warning message?

```{r}
#| warning: TRUE
matrix(1:15, nrow = 4)
```



### [**Exercise 4**]{.hl-yellow}

ğŸ“ Define the matrix `x <- matrix(1:12, nrow = 4)`. Then get the data of the first individual, the data of the third variable, and the element `(4, 1)`.

```{r}
#| code-fold: true
#| eval: false
x <- matrix(1:12, nrow = 4)
x[1, ] # first row
x[, 3] # third column
x[4, 1] # (4, 1) element
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Define a matrix of 2 variables and 3 individuals such that each variable captures the height and age of 3 persons, so that the age of the second person is unknown (absent). Then calculate the mean of each variable (we should get a number!).

```{r}
#| code-fold: true
#| eval: false
data <- cbind("age" = c(20, NA, 25), "h" = c(160, 165, 170))
apply(data, MARGIN = 2, FUN = "mean", na.rm = TRUE) # mean by columns

```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ Why does the lower code return an error? What is wrong?

```{r}
#| error: true
mat <- cbind("age" = c(15, 20, 25), "names" = c("javi", "sandra", "carlos"))
mat
mat + 1
```

:::

---

## Second attempt: data.frame

Arrays have the same problem as vectors: if we put together data of different types, it [**data integrity is compromised**]{.hl-red} as it converts them (see the code below: the ages and the `TRUE/FALSE` are converted to text).


```{r}
#| code-line-numbers: "4-5"
ages <- c(14, 24, NA)
single <- c(TRUE, NA, FALSE)
names <- c("javi", "laura", "lucÃ­a")
mat <- cbind(ages, single, names)
mat
```

. . .

In fact, since they are not numbers, we can no longer perform arithmetic operations.

```{r}
#| error: true
mat + 1
```

---

## Second attempt: data.frame

In order to work with [**variables of different type**]{.hl-yellow} we have in `R` what is known as [**data.frame**]{.hl-yellow}: concatenation of variables of equal length but which can be of [**different type**]{.hl-purple}.

```{r}
table <- data.frame(ages, single, names)
class(table)
table
```

---

## Second attempt: data.frame

Since a `data.frame` is already an attempt at a `database` the variables are not mere mathematical vectors: [**they have a meaning**]{.hl-yellow} and we can (we must) [**give them names**]{.hl-purple} that describe their meaning.

```{r}
library(lubridate)
table <-
  data.frame("ages" = ages, "single" = single, "names" = names,
             "birth_date" = as_date(c("1989-09-10", "1992-04-01", "1980-11-27")))
table
```

---

## Second attempt: data.frame

[**We have our first data set!**]{.hl-yellow} (strictly speaking we can't talk about a database but for the moment it looks like one). You can visualize it by typing its name in console or with `View(table)`.

![](img/view_tabla.jpg)

---

## Get variables

If we want to access its elements, being again **tabulated data**, we can access as in the matrices ([**not recommended**]{.hl-red}): again [**we have two indexes**]{.hl-yellow} (rows and columns, leaving free the one we don't use)


```{r}
table[2, ]  # second row (all variables)
table[, 3]  # third column (all individuals)
table[2, 1] # first variable of the second individual
```

. . .

::: columns
::: {.column width="25%"}
![](img/menu_data_frame.jpg)
:::

::: {.column width="75%"}

But it also has the advantages of a [**database**]{.hl-yellow} : we can [**access the variables by name**]{.hl-purple} ([**recommended**]{.hl-green} since the variables can change position and now they have a meaning), putting the name of the table followed by the symbol `$` (with the **tab**, a menu of columns to choose from will appear).

:::
:::

---

## Ask functions

- `names()`: shows us the variable names

```{r}
names(table)
```

. . .

- `dim()`: shows dimensions (also `nrow()` and `ncol()`)

```{r}
dim(table)
```

. . .

-  Variables can be accessed by name

```{r}
table[c(1, 3), "names"]
table$names[c(1, 3)]
```

---

## Add a variable

If we have one already created and we want to [**add a column**]{.hl-yellow} it is as simple as using the `data.frame()` function we have already seen to concatenate the column. Let's add for example a new variable, the number of siblings of each individual.

```{r}
# add a new column
siblings <- c(0, 2, 3)
table <- data.frame(table, "n_sib" = siblings)
table
```

---

## Last attempt: tibble

Tables in `data.frame` format have some [**limitations**]{.hl-red}. The main one is that [**does not allow recursion**]{.hl-red}: imagine that we define a database with heights and weights, and we want a third variable with the BMI.


```{r}
#| error: true
data.frame("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70),
           "BMI" = weight / (height^2))
```

. . .


Hereafter we will use the `tibble` ([**enhanced data.frame**]{.hl-yellow}) format from the `{tibble}` package.

```{r}
library(tibble)
data_tb <- 
  tibble("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70), "BMI" = weight / (height^2))
class(data_tb)
data_tb
```

---

## Last attempt: tibble

```{r}
data_tb <- 
  tibble("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70), "BMI" = weight / (height^2))
class(data_tb)
data_tb
```

Las tablas en formato `tibble` nos permitirÃ¡ una [**gestiÃ³n mÃ¡s Ã¡gil, eficiente y coherente**]{.hl-yellow} de los data, con 4 ventajas principales:

. . .

- [**Metainformation**]{.hl-yellow}: if you look at the header, it automatically tells us the number of rows and columns, and the type of each variable

. . .

- [**Recursivity**]{.hl-yellow}: allows you to define the variables sequentially (as we have seen)



---

## Last attempt: tibble

- [**Consistency**]{.hl-yellow}: if you access a column that does not exist, it warns you with a warning

```{r}
#| warning: true
data_tb$invent
```

. . .

- [**By rows**]{.hl-yellow}: create by rows (copy and paste from a table) with `tribble()`.

```{r}
tribble(~colA, ~colB,
        "a",   1,
        "b",   2)
```

. . .

::: callout-tip
The `{datapasta}` package allows us to [**copy and paste**]{.hl-green} tables from web pages and simple documents.
:::


---


## In summary...

- Each [**cell can be of a different type**]{.hl-yellow}: numbers, text, dates, logical values, etc. A [**vector is a concatenation of cells**]{. hl-yellow} (the future columns of our tables) --> In `R` by default operations are done [**element to element**]{.hl-yellow}.

. . .

- A [**matrix**]{.hl-yellow} allows us to concatenate [**variables of the SAME type and SAME length**]{.hl-yellow} --> tabular data.

. . .

- A [**data.frame**]{.hl-yellow} allows us to concatenate [**variables of DIFFERENT type and SAME length**]{.hl-yellow} --> we will use [**tibble**]{.hl-yellow} as an enhanced database option.

---

## ğŸ’» It's your turn {#tu-turno-0-2-3}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ Load from the `{datasets}` package the `airquality` dataset (New York air quality variables from May through September 1973). Is the airquality dataset of type tibble? If not, convert it to tibble (look in the package documentation at <https://tibble.tidyverse.org/index.html>).

```{r}
#| code-fold: true
#| eval: false
library(tibble)
class(datasets::airquality)
airquality_tb <- as_tibble(datasets::airquality)
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Once converted to `tibble` get the name of the variables and the dimensions of the data set. How many variables are there? How many days have been measured?

```{r}
#| code-fold: true
#| eval: false
names(airquality_tb)
ncol(airquality_tb)
nrow(airquality_tb)
```


### [**Exercise 3**]{.hl-yellow}

ğŸ“ Filters only the data of the fifth observation

```{r}
#| code-fold: true
#| eval: false
airquality_tb[5, ]
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Filter only the data for the month of August. How to tell it that we want only the rows that meet a specific condition?

```{r}
#| code-fold: true
#| eval: false
airquality_tb[airquality_tb$Month == 8, ]

# other way
var_month <- airquality_tb$Month
airquality_tb[var_month == 8, ]
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Select those data that are not from July or August.

```{r}
#| code-fold: true
#| eval: false
airquality_tb[airquality_tb$Month != 7 & airquality_tb$Month != 8, ]
airquality_tb[!(airquality_tb$Month %in% c(7, 8)), ]
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ Modify the following code to keep only the ozone and temperature variables (no matter what position they are).

```{r}
#| eval: false
airquality_tb[, 3]
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ Select the temperature and wind data for August. 

```{r}
#| code-fold: true
#| eval: false
airquality_tb[airquality_tb$Month == 8, c("Temp", "Wind")]
```

### [**Exercise 8**]{.hl-yellow}

ğŸ“ Translate the name of the variables into your native language.


```{r}
#| code-fold: true
#| eval: false
names(airquality_tb) <- c("ozono", "rad_solar", "viento", "temp", "mes", "dia") 
```

:::


---

## ğŸ£ Case study I {#caso-practico-0-2-1}

In the `{datasets}` package (already installed by default) we have several datasets and one of them is `airquality`. Below I have extracted 3 variables from that dataset (note that it is done with `data$variable`, that dollar will be important in the future).The data captures [**daily measurements (n = 153 observations) of air quality**]{.hl-yellow} in New York, from May to September 1973. Six **6 variables** were measured: ozone levels, solar radiation, wind, temperature, month and day.

```{r}
library(datasets)
temperature <- airquality$Temp
month <- airquality$Month
day <- airquality$Day
```

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/intro-r-base-tibbles-mucss/)


---

## ğŸ£ Case study II {#caso-practico-0-2-2}

We will consider the `surveys.RData` file in which we have all poll surveys for Spain from 1982 to 2019.

```{r}
load(file = "./data/surveys.RData")
survey_data
```


Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/intro-r-base-tibbles-mucss/)



# L3: [if-else and Quarto]{.flow} {#clase-0-3}

[**Flow structures: if-else and loops. Functions in R. Quarto**]{style="color:#444442;"}

* [ğŸ’» Solved exercises: if-else](#tu-turno-0-3-1) 

* [ğŸ’» Solved exercises: loops](#tu-turno-0-3-2)

* [ğŸ’» Solved exercises: functions](#tu-turno-0-3-3)

* [ğŸ£ Workbook/case study I-II-III](#caso-practico-0-3-1)

* [ğŸ“† Planning](#planificacion)

---

## Flow structures

A [**flow or control structure**]{.hl-yellow} consists of a series of commands oriented to [**decide the path**]{.hl-yellow} that your code must follow

* If condition A is met, what happens?

* What if B happens?

* How can I repeat the same expression (depending on a variable)?

. . .

If you have programmed before, you may be familiar with what are known as [**conditional structures**]{.hl-yellow} such as `if (bla bla) {...} else {...}` or [**loops**]{.hl-yellow} `for/while` (to be avoided whenever possible).

---

## If

One of the most famous control structures are those known as [**conditional structures**]{.hl-yellow} `if`.

> IF a set of conditions is met (TRUE), then execute whatever is inside the curly brackets.


For example, the structure `if (x == 1) { code A }` what it will do is [**execute code A in braces**]{.hl-yellow} but [**ONLY IF**]{.hl-purple} the [**condition in brackets is true**]{.hl-purple} (only if `x` is 1). In any other case, it will do nothing

. . .

For example, let's define a vector of ages of 8 people


```{r}
ages <- c(14, 17, 24, 56, 31, 20, 87, 73)
ages < 18
```

---

## If


Our conditional structure will do the following: [**if there is a minor, it will print**]{.hl-yellow} a message.

```{r}
if (any(ages < 18)) { 
  
  print("There is a minor")
  
}
```

---

## If

```{r}
#| eval: false
if (any(ages < 18)) { 
  
  print("There is a minor")
  
}
```


In case the [**conditions are not true**]{.hl-yellow} inside `if()` (`FALSE`), nothing happens.


```{r}
if (all(ages >= 18)) { 
  
  print("All of them are of legal age")
  
}
```

**We get no message** because the condition `all(ages >= 18)` is not `TRUE`, so it does not execute anything.

---

## If-else

The structure `if (condition) { code A }` can be combined with an `else { code B }`: when the [**condition is not checked**]{.hl-yellow}, it will [**execute the alternative code B**]{. hl-yellow} inside `else { }`, allowing us to decide what happens when it is satisfied and when it is not

. . .

For example, `if (x == 1) { code A } else { code B }` will execute A if `x` is equal to 1 and B in any other case.

```{r}
if (all(ages >= 18)) { 
  
  print("All of them are of legal age")
  
} else {
  
  print("There is a minor")
}
```

---

## If-else

Esta estructura `if - else` puede ser [**anidada**]{.hl-yellow}: imagina que queremos ejecutar un cÃ³digo si todos son menores; si no sucede, pero todos son mayores de 16, hacer otra cosa; en cualquier otra cosa, otra acciÃ³n.

```{r}
if (all(ages >= 18)) { 
  
  print("All of them are of legal age")
  
} else if (all(ages >= 16)) {
  
  print("There is a minor but all of them are greater or equal to 16 years old")
  
} else { print("There are any persons under 16 years of age") }
```

::: callout-note
## Tip

You can **collapse the structures** by clicking on the left arrow in your script.

:::


---

## If-else vectorized


This conditional structure can be [**vectorized**]{.hl-yellow} (in a single line) with `if_else()` (from the `{dplyr}` package), whose arguments are

* the condition to evaluate

* what happens when it is met and when not

* an optional argument for when the condition to evaluate is `NA`

We will label without are greater/lesser and an `unknown` when we don't know.

```{r}
library(dplyr)
ages <- c(NA, ages)
if_else(ages >= 18, "legal age", "minor", missing = "unknown")
```

In `R` base there is `ifelse()`: it does not let you specify what to do with the absent ones but allows you to specify different types of data in `TRUE` and `FALSE`.

---

## ğŸ’» It's your turn {#tu-turno-0-3-1}


[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ What will be the output of the following code?

```{r}
#| eval: false
if_else(sqrt(9) < 2, sqrt(9), 0)
```

```{r}
#| eval: false
#| code-fold: true

The output is 0 since sqrt(9) equals 3, and since it is not less than 2, it returns the second argument which is 0.
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ What will be the output of the following code?

```{r}
#| eval: false
x <- c(1, NA, -1, 9)
if_else(sqrt(x) < 2, 0, 1)
```

```{r}
#| eval: false
#| code-fold: true

The output is the vector c(0, NA, NA, 1) since sqrt(1) is less than 2, sqrt(9) is not, and in the case of both sqrt(NA) (root of absent) and sqrt(-1) (returns NaN, not a number), its square root cannot be checked whether it is less than 2 or not, so the output is NA.
```


### [**Exercise 3**]{.hl-yellow}

ğŸ“ Modify the code below so that, when the square root of a number cannot be verified to be less than 2, it returns -1.

```{r}
#| eval: false
x <- c(1, NA, -1, 9)
if_else(sqrt(x) < 2, 0, 1)
```

```{r}
#| eval: false
#| code-fold: true
x <- c(1, NA, -1, 9)
if_else(sqrt(x) < 2, 0, 1, missing = -1)
```


### [**Exercise 4**]{.hl-yellow}

ğŸ“ What are the values of `x` and `y` of the lower code for `z <- 1`, `z <- -1` and `z <- -5`?

```{r}
#| eval: false
z <- -1
if (z > 0) {
  
  x <- z^3
  y <- -sqrt(z)
  
} else if (abs(z) < 2) {
  
  x <- z^4
  y <- sqrt(-z)
  
} else {
  
  x <- z/2
  y <- abs(z)
  
}
```

```{r}
#| eval: false
#| code-fold: true
In the first case x = 1 and y = -1. In the second case x = 1 and y = 1. In the third case -1 and 2.
```


### [**Exercise 5**]{.hl-yellow}

ğŸ“ What will happen if we execute the code below?

```{r}
#| eval: false
z <- "a"
if (z > 0) {
  
  x <- z^3
  y <- -sqrt(z)
  
} else if (abs(z) < 2) {
  
  x <- z^4
  y <- sqrt(-z)
  
} else {
  
  x <- z/2
  y <- abs(z)
  
}
```

```{r}
#| code-fold: true
#| eval: false

# will give error since it is not a numeric argument
Error in z^3 : non-numeric argument to binary operator
```


### [**Exercise 6**]{.hl-yellow}

ğŸ“ From the `{lubridate}` package, the `hour()` function returns the time of a given date, and the `now()` function returns the date and time of the current time. With both functions, have `cat()` (`cat()`) print â€œgood nightâ€ only after 21:00.

```{r}
#| code-fold: true
#| eval: false

# loading library
library(lubridate)

# Current date-time
current_dt <- now()

# If structure
if (hour(current_dt) > 21) {
  
  cat("Good night") # print or cat (two ways of printing)
}
```


:::

---

## Communicate: rmd and Quarto

One of the [**main strengths**]{.hl-yellow} of `R` is the [**easiness to generate reports, books, webs, notes and even slides**]{.hl-yellow} (this same material for example). To do this, [**install**]{.hl-purple} before

::: columns
::: {.column width="40%"}
- the `{rmarkdown}` package (to generate `.rmd` files)

```{r}
#| eval: false
install.packages("rmarkdown")
```

- install [**Quarto**](https://quarto.org/docs/get-started/) (if you already knew `R`, the â€œnewâ€ `.rmd` now as `.qmd`)

:::

::: {.column width="60%"}
![](img/quarto.png)
:::
:::

---

## Communicate: rmd and Quarto

So far we have only programmed in scripts (`.R` files) within projects, but in many occasions [**we will not work alone**]{.hl-yellow} and we will need to [**communicate the results**]{.hl-yellow} in different formats:

- notes (for ourselves)
- slides
- web
- reports


For all this we will use [**Quarto**]{.hl-yellow} (see more in <https://ivelasq.quarto.pub/intro-to-quarto/>)

---

## Communicate: rmd and Quarto

The `.qmd` (or `.rmd` before) extension files will allow us to easily combine:- [**Markdown**]{.hl-yellow}: 

- [**typed language**]{.hl-purple} that allows us to create simple content (wordpress type, with text, **bold**, _cursives_, etc) with a readable layout.

. . .

- [**Math (latex)**]{. hl-yellow}: language for writing mathematical notation such as $x^2$ or $\sqrt{y}$ or $\int_{a}^{b} f(x) dx$.

. . .

- [**Code and outputs**]{.hl-yellow}: we can not only show the final step but also the code you have been doing (in `R`, `Python`, `C++`, `Julia`, ...), with [**code boxes called CHUNKS**]{.hl-purple}.

. . .

- Images, [**graphs**]{.hl-yellow}, tables, styles (css, js), etc.

---

## Communicate: rmd and Quarto

The main advantage of making this type of material in Quarto/Rmarkdown is that, by doing it from `RStudio`, you can generate a [**report or presentation without leaving the programming environment**]{.hl-yellow} in which you are working. This way you can analyze the data, summarize it and at the same time communicate it with the same tool.


. . .

Recently the `RStudio` team developed [**Quarto**]{.hl-yellow}, an improved version of Rmarkdown (`.qmd` files), with a slightly more aesthetic and simpler format. You have all the documentation and examples at [**https://quarto.org/**](https://quarto.org/)

---

## Quarto examples

::: panel-tabset
### Webs

![](./img/website.png){height="350"}

### Books

![](./img/book.png){height="350"}

### Blogs

![](./img/blog.png){height="350"}

### Slides

![](./img/presentation.png){height="350"}

### Journals

![](https://user-images.githubusercontent.com/163582/42351114-e5deaa1c-8078-11e8-90de-2aff57bba255.png){height="350"}
:::

Images obtained from <https://ivelasq.quarto.pub/intro-to-quarto/#/working-with-the-rstudio-visual-editor>

---

## Our first report

::: columns
::: {.column width="55%"}
![](img/quarto-create.png)
:::

::: {.column width="45%"}
We are going to create the [**first rmarkdown file with Quarto**]{.hl-yellow} with extension `.qmd`. For this we will only need to click on

`File << New File << Quarto Document`
:::
:::

---

## Our first report

:::: columns
::: {.column width="45%"}
![](img/quarto-format.png)
:::

::: {.column width="55%"}
After doing so, several [**output format options**]{.hl-yellow}:

- `.pdf` file

- `.html` file ([**recommendable**]{.hl-yellow}): dynamic document, allows user interaction, like a â€œweb pageâ€.

- `.doc` file (not recommended).


:::
::::

. . .

For the moment we will leave the [**default HTML format**]{.hl-yellow} checked, and we will write the [**title**]{.hl-yellow} of our document. After that we will have our [**file .qmd**]{.hl-yellow} (it is no longer an .R script like the ones we have opened so far).
---

## Our first report

:::: columns
::: {.column width="60%"}
![](img/quarto-example.png)
:::

::: {.column width="40%"}

You should have something similar to the image capture with [**two editing modes**]{.hl-yellow}: `Source` (with code, the recommended option until you master it) and `Visual` (more like a blog).

:::
::::

To [**run the WHOLE document**]{.hl-yellow} you must click `Render on Save` and hit save.

---

## Quarto output format

![](img/quarto-prueba-html.png)

You should have obtained an [**html output similar to this**]{.hl-yellow} (and a [**html file**]{.hl-yellow} has been generated on your computer).

---

## Editor: source vs visual

As indicated, you have two ways of working: with pure code and something similar to a Notion (blog).

![](./img/rstudio-source-visual.png)

Image retrieved from <https://ivelasq.quarto.pub/intro-to-quarto/#/working-with-the-rstudio-visual-editor>

---

## Our first report

:::: columns
::: {.column width="50%"}
![](img/quarto-example.png)

:::

::: {.column width="50%"}

A `.qmd` file is [**basically divided into three parts**]{.hl-yellow}:

* [**Header**]{.hl-yellow}: the part you have at the beginning between `---`.

* [**Text**]{. hl-yellow}: which we can format and enhance with bold (written as **bold**, with double asterisk at the beginning and end), italics (_cursive_, with underscore at the beginning and end) or highlight function or variable names from R. You can add equations like $x^2$ (I have written `$x^2$`, between dollars).

* [**R code**]{.hl-yellow}

:::
::::

---

## Header {auto-animate="true"}

The [**header is in YAML**]{.hl-yellow} format and contains the [**metadata**]{.hl-yellow} of the document.

:::: columns
::: {.column width="60%"}

* `title` and `subtitle`: the title/subtitle of the document
* `author`: author of the document
* `format`: output format (we can customize)
  * `theme`: if you have any style file
  * `toc`: if you want index or not
  * `toc-location`: index position
  * `toc-title`: index title
* `editor`: if you are in visual or source mode.

:::

::: {.column width="40%"}

``` yaml
---
title: "prueba"
format:
  html:
editor: visual
---
```

:::
::::

---

## Header {auto-animate="true"}

The [**header is in YAML**]{.hl-yellow} format and contains the [**metadata**]{.hl-yellow} of the document.

:::: columns
::: {.column width="60%"}

* `title` and `subtitle`: the title/subtitle of the document
* `author`: author of the document
* `format`: output format (we can customize)
  * `theme`: if you have any style file
  * `toc`: if you want index or not
  * `toc-location`: index position
  * `toc-title`: index title
* `editor`: if you are in visual or source mode.

:::

::: {.column width="40%"}

``` yaml
---
title: "prueba"
author: "javier Ã¡lvarez liÃ©bana"
format:
  html:
editor: visual
---
```

:::
::::

---

## Header {auto-animate="true"}

The [**header is in YAML**]{.hl-yellow} format and contains the [**metadata**]{.hl-yellow} of the document.

:::: columns
::: {.column width="60%"}

* `title` and `subtitle`: the title/subtitle of the document
* `author`: author of the document
* `format`: output format (we can customize)
  * `theme`: if you have any style file
  * `toc`: if you want index or not
  * `toc-location`: index position
  * `toc-title`: index title
* `editor`: if you are in visual or source mode.

:::

::: {.column width="40%"}

``` yaml
---
title: "prueba"
author: "javier Ã¡lvarez liÃ©bana"
format:
  html:
    style: style.css
    toc: true
editor: visual
---
```

:::
::::

---

## Header {auto-animate="true"}

The [**header is in YAML**]{.hl-yellow} format and contains the [**metadata**]{.hl-yellow} of the document.

:::: columns
::: {.column width="60%"}

* `title` and `subtitle`: the title/subtitle of the document
* `author`: author of the document
* `format`: output format (we can customize)
  * `theme`: if you have any style file
  * `toc`: if you want index or not
  * `toc-location`: index position
  * `toc-title`: index title
* `editor`: if you are in visual or source mode.

:::

::: {.column width="40%"}

``` yaml
---
title: "prueba"
author: "javier Ã¡lvarez liÃ©bana"
format:
  html:
    style: style.css
    toc: true
    toc-location: left
editor: visual
---
```

:::
::::

---

## Header {auto-animate="true"}

The [**header is in YAML**]{.hl-yellow} format and contains the [**metadata**]{.hl-yellow} of the document.

:::: columns
::: {.column width="60%"}

* `title` and `subtitle`: the title/subtitle of the document
* `author`: author of the document
* `format`: output format (we can customize)
  * `theme`: if you have any style file
  * `toc`: if you want index or not
  * `toc-location`: index position
  * `toc-title`: index title
* `editor`: if you are in visual or source mode.

:::

::: {.column width="40%"}

``` yaml
---
title: "prueba"
author: "javier Ã¡lvarez liÃ©bana"
format:
  html:
    style: style.css
    toc: true
    toc-location: left
    toc-title: Ãndice
editor: visual
---
```

:::
::::


---

## Text

Regarding typing there is only one [**important thing**]{.hl-yellow}: unless we indicate otherwise, [**EVERYTHING we are going to type is (normal)**]{.hl-yellow} text; no R code.

:::: columns
::: {.column width="35%"}
![](img/quarto-prueba-qmd2.png){width=350}
![](img/quarto-prueba-html2.png){width=320}
:::

::: {.column width="65%"}
We are going to start by writing a section at the beginning (`# Intro` and behind it, for example, the sentence

> This material has been designed by Professor Javier Ãlvarez LiÃ©bana, professor at the Complutense University of Madrid

In addition to the `Running Code` we will add a `#` pad: the [**outside-chunks**]{.hl-yellow} pads will help us create [**epigraphs (sections)**]{.hl-yellow} in the document.


:::
::::


---

## Index

:::: columns
::: {.column width="40%"}
![](img/quarto-indice-qmd-2.png){width=370}
![](img/quarto-indice-html2.png){width=370}
:::

::: {.column width="60%"}

To make the [**index capture those sections**]{.hl-yellow} we will modify the header of the file as shown in the image (you can change the location of the index and the title if you want to test).

:::
::::

---

## Text

Let's [**customize the text**]{.hl-yellow} a bit by doing the following:

:::: columns
::: {.column width="50%"}
![](img/quarto-texto-mejorado-qmd.png){width=370}
![](img/quarto-texto-mejorado-html.png){width=370}
:::

::: {.column width="50%"}

* We will add [**bold to the name**]{.hl-yellow} (putting ** at the beginning and at the end).

* We will add [**cursive**]{.hl-yellow} to the word material (putting _ at the beginning and at the end).

* We will add a [**link**]{.hl-yellow} <https://www.ucm.es>, associating it to the name of the University. To do this we put the title in square brackets and just behind the link in brackets `[â€œUniversidad Complutense de Madridâ€](https://www.ucm.es)`.

:::
::::

---

## Code

To [**include R code**]{.hl-yellow} we must create our [**code boxes called chunks**]{.hl-yellow}: high in the path in our markdown text where we can include code from almost any language (and its outputs).

&nbsp;

:::: columns
::: {.column width="50%"}
![](img/quarto-chunk-qmd.png){width=470}
:::

::: {.column width="50%"}

To include one you must go [**header**]{.hl-yellow} as follows you have a shortcut `Command + Option + I` (Mac) or `Ctrl + Shift + I` (Windows)

:::

::::

---

## Code

Inside this box (which now has a different color in the document) [**write code R**]{.hl-yellow} as we have been doing so far in the scripts.

:::: columns
::: {.column width="50%"}
![](img/quarto-chunk-1-qmd.png){width=410}
![](img/quarto-chunk-1-html.png){width=410}
:::

::: {.column width="50%"}

Let's for example define two variables and their sum in the following way, writing this code in our `.qmd` (inside that chunk)
 
```{r}
# R code
x <- 1
y <- 2
x + y
```

:::

::::


---

## Running chunks


:::: columns
::: {.column width="50%"}
![](img/quarto-tag-chunks-qmd.png){width=400}
![](img/quarto-tag-chunks-html.png){width=400}
:::

::: {.column width="50%"}

Chunks can have a [**name or tag**]{.hl-yellow}, so that we can reference them again to avoid repeating code.

:::
::::


---

## Running chunks

:::: columns
::: {.column width="40%"}
![](img/quarto-inline-qmd.png){width=400}
![](img/quarto-inline-html.png){width=380}
:::

::: {.column width="60%"}

In each chunk there are [**two buttons**]{.hl-yellow}:

* [**play**]{.hl-yellow} button: activates the [**play and exit of that particular chunk**]{.hl-yellow} (you can view it within your own `RStudio`)

* [**rewind**]{.hl-yellow} button: activates the [**play and exit of all chunks up to that one**]{.hl-yellow} (without reaching it).


&nbsp;

In addition we can [**include R code inside the text line**]{.hl-yellow} (instead of displaying the text x execute the R code displaying the variable).

:::
::::



---

## Customizing chunks

The [**chunks can be customized**]{.hl-yellow} with options at the beginning of the chunk preceded by `#|`:

* `#| echo: false`: [**execute code**]{.hl-green} and [**show result**]{.hl-green} but [**does not display code**]{.hl-red} in the output. hl-red} on output.

* `#| include: false`: [**executes code**]{.hl-green} but [**does not display result**]{.hl-red} and [**does not display code**]{.hl-red} on output.

* `#| eval: false`: [**does not execute code**]{. hl-red}, [**does not display result**]{.hl-red} but [**does display code**]{.hl-green} on output.

* `#| message: false`: [**executes code**]{.hl-green} but [**does not display output messages**]{.hl-red}.

* `#| warning: false`: [**runs code**]{.hl-green} but [**does not display warning messages**]{.hl-red}.

* `#| error: true`: [**runs code**]{.hl-green} and [**allows errors**]{.hl-green} displaying the error message in the output.


![](img/quarto-options-chunk.png){width=380}

These options can be applied chunk by chunk or set globally with `knitr::opts_chunk$set()` at the beginning of the document (within a chunk).

---

## Customizing chunks

If we want to apply the **option to all chunks by default** we must include it at the end of the header, as [**run options**]{.hl-yellow}

``` yaml
---
title: "Â¡Hola!"
format: html
editor: visual
execute:
  echo: false
---
```

---

## Organizing

In addition to text and code we can enter the following:

* [**Equations**]{.hl-yellow}: you can also add equations like $x^2$ (I have written `$x^2$`, the equation between dollars).

* [**Lists**]{. hl-yellow}: you can itemize elements by putting `* Step 1: ... *Step 2: ...`

* [**Cross-references**]{.hl-yellow}: you can tag parts of the document (the tag is constructed with `{#section-name}`) and then call them with `[Section](@section-name)`.

---

## Figures and images

:::: columns
::: {.column width="50%"}
![](img/quarto-fig-qmd.png){width=340}
![](img/quarto-fig-html.png){width=390}
:::

::: {.column width="50%"}


Finally, we can also [**add captions to graphics or images**]{.hl-yellow} by adding `#| fig-cap: "..."`.

:::
::::

. . .

:::: columns
::: {.column width="65%"}

Notice that the [**caption is in the margin**]{.hl-yellow} (for example). You can change it by entering [**header settings**]{.hl-yellow} (everything about figures starts with `fig-`, and you can see the options by tabbing). You have more information at **<https://quarto.org/>**

:::

::: {.column width="35%"}
![](img/quarto-cabecera-desplegable.png){width=400}
:::
::::

---

## Styles

:::: columns
::: {.column width="50%"}
![](img/quarto-estilos-qmd.png){width=400}
![](img/quarto-estilos-html.png){width=400}
:::

::: {.column width="50%"}

Finally you can add a [**custom theme**]{.hl-yellow} including a [**style file**]{.hl-yellow} (`.scss` or `.css` file). I have left one for you at <https://github.com/dadosdelaplace/docencia-R-master-bio-2324/tree/main/material>.

::: callout-important
## Important

The style file must be in the same folder as the `.qmd` file.

:::
:::
::::

---

## Styles

You can also do it in a simple way [**adding a bit of HTML**]{.hl-yellow} to the text. For example, to customize the color of a text it goes between square brackets and right after the text, between braces, the style options

``` html
This word is [red]{style="color:red;"} ...
```

``` html
... and this is [green in bold]{style="color:green; font-weight: bold;"}
```

. . .

This word is [red]{style="color:red;"} ...

... and this is [green in bold]{style="color:green; font-weight: bold;"}

---

## Revealjs

You can add some â€œanimationsâ€ using what is known as Revealjs (javascript), specifying it in the header and using [**blocks**]{.hl-yellow} of that language delimited by `:::` at the beginning and end, and the word of the â€œtoolâ€ to use. For example `{.incremental}` transitions the elements.


``` yaml
format:
  revealjs
```
&nbsp;

``` revealjs
::: {.incremental}
- I
- am
- Javi
:::
```


::: {.incremental}
- I
- am
- Javi
:::

---

## Call blocks

You can also use the [**callout-blocks**]{.hl-yellow} which by default are `note`, `tip`, `warning`, `caution` and `important` (although you can create and customize them). To do this, just use `::{.callout-type}` and the type you want to use

``` html
:::{.callout-tip}

Note that there are five types of callouts, including: 
`note`, `tip`, `warning`, `caution`, and `important`.

:::
```

. . .

:::{.callout-tip}

Note that there are five types of callouts, including: 
`note`, `tip`, `warning`, `caution`, and `important`.

:::

. . .

:::{.callout-caution}

Use them wisely, sometimes a lot of aesthetic resources can be dizzying.

:::

---

## Multiple columns layout

With `:::: columns` we can define a layout of [**multiple columns**]{.hl-yellow} where each one is defined by `::: {.column width=â€œ65%â€} something :::`, indicating next to the percentage how much you want each column to occupy (be careful not to leave spaces!).

``` html
:::: columns
::: {.column width="65%"}
This is how to define a vector
:::
::: {.column width="35%"}
x <- c(1, 2, 3)
x
:::
::::
```
&nbsp;

. . .

:::: columns
::: {.column width="65%"}
This is how to define a vector
:::

::: {.column width="35%"}
```{r}
x <- c(1, 2, 3)
x
```
:::
::::


---

## Non-R code

In addition `{reticulate}` allows us to create `python` chunks inside a Quarto in `R` (see <https://quarto.org/docs/computations/python.html> to create jupyter notebooks directly from Quarto).


```{r}
#| echo: false
#| eval: false
library(reticulate)
```

```{r}
#| eval: false
# install.packages("reticulate")
library(reticulate)

install_python("3.9.12") # Installing python if you have not done before

# Installing Python libraries
reticulate::py_install("numpy")
reticulate::py_install("matplotlib")
```



```{python}
#| eval: false
import numpy as np
import matplotlib.pyplot as plt
r = np.arange(0, 2, 0.05)
theta = 2 * np.pi * r
fig, ax = plt.subplots(
  subplot_kw = {'projection': 'polar'} 
)
ax.plot(theta, r)
plt.show()
```


---


## ğŸ£ Case study I: flow structures {#caso-practico-0-3-1}

To practice control structures we are going to perform a [**simulation exercise**]{.hl-yellow}

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/flow-structure-functions)

---

## ğŸ£ Case study II: functions {#caso-practico-0-3-2}

Define a function called `temperature_converter` that, given a temperature in Fahrenheit, Celsius or Kelvin, converts it to any of the others

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/flow-structures-functions)

---

## ğŸ£ Case study III: mock task {#caso-practico-0-3-3}

Let's perform a small simulation before delivery using the `starwars` dataset from the `{dplyr}` package.

![](https://sm.ign.com/t/ign_latam/screenshot/default/baby-yoda-nombre_3x56.1280.jpg)

---

## ğŸ£ Case study III: mock task

```{r}
library(dplyr)
starwars
```

We have **different variables of the Star Wars characters**, with characteristics of their hair, skin, height, name, etc.

---

## ğŸ£ Case study III: mock task

> Create a `.qmd` document with name, title, format and index. Each subsequent Exercise will be a subsection of the document. Run the chunks you consider and comment on the outputs to answer each question

. . .

> Exercise 1. How many characters are stored in the database? How many characteristics have been measured for each one?

. . .

> Exercise 2. Extract in two different variables `names` and `ages` the corresponding variables from the table. What type is the variable name? And the variable birth_year?

. . . 

> Exercise 3. Obtain the vector of names of the characters sorted from oldest to youngest.


---

## ğŸ£ Case study III: mock task

> Exercise 4. Get help from the unique() function. Use it to find out what modalities the qualitative variable for eye color has. How many different ones are there?

. . .

>  Exercise 5. Are there ANY missing values in the eye color variable?

. . .

> Exercise 6. Calculate the mean and standard deviation of the height and weight variables (watch out for missing values). Define a new tibble with these two variables and incorporate a third variable called â€œBMIâ€ that calculates the body mass index. Incorporate with `$ $` the formula used for BMI.


# Final task: [foundations of R base]{.flow} {#clase-0-4}

[**Final task (70%)**: 10/09/2024 from 15:00 to 16:10]{style="color:#444442;"}

---

## Final task (intro R)

The day of the submission you will have uploaded a [**submission template**]{.hl-yellow} in `.qmd` format on campus.

1. **Unzip the folder** (important! if you don't unzip, even if you can edit the `.qmd`, you won't be able to generate the `. html`)

2. **Edit the header** with your name and ID

3. You must **fill in each chunk** with the code you consider (in some I have left hints) and **change** from `#| eval: false` to `#| eval: true` (if you remove them directly, by default it is already true)

4. You must **comment** with normal text what you consider to answer the questions.

5. It will be [**MANDATORY**]{.hl-yellow} to upload the generated `.html` file (only that file will be corrected) so render as you fill in the document, don't leave it to the end.

# [DATA PROGRAMMING]{.flow}

# L1: [tidydata]{.flow} {#clase-1}

[**Our favorite format: tibble. Tidyverse: an universe of tidy data**]{style="color:#444442;"}

* [ğŸ’» Task correction](#tu-turno-1-1)
* [ğŸ’» Solved exercises: tidy data](#tu-turno-1-2)
* [ğŸ£ Workbook/case study](#caso-practico-1)
* [ğŸ“† Planning](#planificacion-curso)

---

## ğŸ’» Task correction {#tu-turno-1-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

---

## Previously, in Breaking Bad...

Our [**final database format**]{.hl-yellow} will be the `tibble` type object, an enhanced `data.frame`.

```{r}
library(tibble)
tibble("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70), "BMI" = weight / (height^2))
```

- [**Metainformation**]{.hl-yellow}: in the header it automatically tells us the number of rows and columns, and the type of each variable.

- [**Recursivity**]{.hl-yellow}: allows to define the variables sequentially (as we have seen).

- [**Consistency**]{.hl-yellow}: if you access a column that does not exist it warns you with a warning.

- [**By rows**]{.hl-yellow}: allows to create by rows with `tribble()`.

---

## Previously, in Breaking Bad...

To define a `tibble()` ourselves we have two options:

* [**Concatenating vectors**]{.hl-yellow} that we already have defined, making use of the `tibble()` function of the `{tibble}` package (already included in `{tidyverse}`)

```{r}
height <- c(1.7, 1.8, 1.6)
weight <- c(80, 75, 70)
BMI <- weight / (height^2)
tibble("height" = height, "weight" = weight, "BMI" = BMI)
```

---

## Previously, in Breaking Bad...

* [**Directly in a tibble**]{.hl-yellow} manually providing values and variable names

```{r}
tibble("height" = c(1.7, 1.8, 1.6),
       "weight" = c(80, 75, 70),
       "BMI" = weight / (height^2))
```

---

## R base vs Tidyverse

So far, everything we have done in `R` has been done in the programming paradigm known as [**R base**]{.hl-yellow}. When `R` was born as a language, many of those who programmed in it imitated forms and methodologies inherited from other languages, based on the use of

- Loops [**for**]{.hl-yellow} and [**while**]{.hl-yellow}

- Dollar `$` to access to the variables 

- Structures [**if-else**]{.hl-yellow}

And although knowing these structures can be interesting in some cases, in [**most cases they are obsolete and we will be able to avoid them**]{.hl-red} (especially loops) since `R` is specially [**designed to work in a functional way**]{.hl-yellow} (instead of element-by-element).

---

## What is tidyverse?

::: columns
::: {.column width="50%"}
![](img/tidyverrse_universe.jpg)
:::

::: {.column width="50%"}
![](img/flow_tidyverse.jpg)
:::
:::

In this context of functional programming, a decade ago `{tidyverse}` was born, a [**â€œuniverseâ€ of packages**]{.hl-yellow} to guarantee an efficient, coherent and lexicographically simple to understand workflow, based on the idea that [**our data is clean and tidy**]{.hl-purple}.

---

## What is tidyverse?

::: columns
::: {.column width="45%"}
![](img/tidyverrse_universe.jpg)

- `{lubridate}`: date management
- `{rvest}`: web scraping
- `{tidymodels}`: modeling/prediction

:::

::: {.column width="55%"}

- `{tibble}`: optimizing data.frame
- `{tidyr}`: data cleaning
- `{readr}`: load rectangular data (.csv), `{readxl}`: import .xls and .xlsx files
- `{dplyr}`: grammar for debugging
- `{stringr}`: text handling
- `{purrr}`: list handling
- `{forcats}`: qualitative handling
- `{ggplot2}`: data visualization

:::
:::



---

## What is tidyverse?

::: columns
::: {.column width="45%"}
![](img/tidyverrse_universe.jpg)

- `{lubridate}`: date management
- `{rvest}`: web scraping
- `{tidymodels}`: modeling/prediction

:::

::: {.column width="55%"}

- `{tibble}`: [**optimizing data.frame**]{.hl-yellow}
- `{tidyr}`: [**data cleaning**]{.hl-yellow}
- `{readr}`: load rectangular data (.csv), `{readxl}`: import .xls and .xlsx files
- `{dplyr}`: grammar for debugging
- `{stringr}`: text handling
- `{purrr}`: list handling
- `{forcats}`: qualitative handling
- `{ggplot2}`: data visualization

:::
:::


---

## Basic idea: tidy data

> Tidy datasets are all alike, but every messy dataset is messy in its own way (Hadley Wickham, Chief Scientist en RStudio)

::: {style="font-size:120px; text-align: center; color:#F8DF58;"}
<b>TIDY</b><b>[VERSE</b>]{style="color:#CAB0EE;"}
:::

The [**universe**]{.hl-purple} of `{tidyverse}` packages is based on the idea introduced by **Hadley Wickham** (the God we pray to) of [**standardizing**]{.hl-yellow} the format of data to

::: incremental
- [**systematize**]{.hl-green} debugging
- make it easier [**simpler**]{.hl-green} to manipulate
- [**legible**]{.hl-green} code.
:::

---

## Rules

The first thing will therefore be to understand what the [**tidydata sets**]{.hl-yellow} are, since the whole `{tidyverse}` is based on the data being standardized.

::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
1.  Each [**variable**]{.hl-yellow} in a [**single column**]{.hl-purple}
:::

::: {.fragment .fade-in}
2.  Each [**individual**]{.hl-yellow} in a [**different row**]{.hl-purple}
:::

::: {.fragment .fade-in}
3.  Each [**cell**]{.hl-yellow} with a [**single value**]{.hl-purple}
:::

::: {.fragment .fade-in}
4.  Each [**dataset**]{.hl-yellow} in a [**tibble**]{.hl-purple}
:::

::: {.fragment .fade-in}
5.  If we want to join [**multiple datasets**]{.hl-yellow} we must have a [**common (key) column**]{.hl-purple}.
:::
:::

::: {.column width="50%"}
![](img/tidy_def.jpg){width="160%"}
:::
:::

---

## Pipe

In `{tidyverse}` the [**operator pipe (pipe)**]{.hl-yellow} defined as `|>` ([**ctrl+shift+M**]{.hl-purple}) will be key: it will be a [**pipe that traverses the data**]{.hl-yellow} and transforms it.
. . .

::: columns
::: {.column width="50%"}

In R base, if we want to apply three functions `first()`, `second()` and `third()` in order, it would be

```{r}
#| eval: false
third(second(first(data)))
```
:::

::: {.column width="50%"}

In `{tidyverse}` we can [**read from left to right**]{.hl-yellow} and separate data from the actions

```{r}
#| eval: false
data |> first() |> second() |> third()
```
:::
:::


. . .

::: callout-caution
## Important

Since version 4.1.0 of `R` we have `|>`, a **native** pipe available [**outside tidyverse**]{.hl-purple}, replacing the [**old pipe**]{.hl-red} `%>%` which depended on the `{magrittr}` package (quite problematic).

:::

---

## Pipe

The main advantage is that the [**code is very readable (almost literal)**]{.hl-yellow} and you can do large operations on the data with very little code.

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  tidy(...) |>
  filter(...) |>
  select(...) |>
  arrange(...) |>
  modify(...) |>
  rename(...) |>
  group(...) |>
  count(...) |>
  summarise(...) |>
  plot(...)
```
:::

::: {.column width="50%"}
<center><img src="img/logo_pipe.png" width="360px"/></center>
:::
:::

---

## Messy data

But what does the [**non-tidy (messy) data**]{.hl-yellow} look like? Let's load the `table4a` table from the `{tidyr}` package (we already have it loaded from the `{tidyverse}` environment).


```{r}
library(tidyr)
table4a
```


[**What could be wrong?**]{.hl-red}

---

## Pivot longer

::: columns
::: {.column width="40%"}
```{r}
table4a
```
:::

::: {.column width="60%"}
â Each [**row represents two observations**]{.hl-red} (1999 and 2000) â†’ the columns `1999` and `2000` should actually themselves be [**values of a variable**]{.hl-yellow} and not column names.
:::
:::

. . .

We will include a [**new column**]{.hl-yellow} that stores the year and another one that stores the value of the variable of interest in each of those years. And we will do it with the `pivot_longer()` function: [**pivot the table**]{.hl-yellow} to long format:

```{r}
table4a |> 
  pivot_longer(cols = c("1999", "2000"), names_to = "year", values_to = "cases")
```

---

## Pivot longer

::: columns
::: {.column width="50%"}
```{r}
table4a |> 
  pivot_longer(cols = c("1999", "2000"),
               names_to = "year",
               values_to = "cases")
```
:::

::: {.column width="50%"}
![](img/table4a.jpg)
:::
:::

- `cols`: [**name of the variables to pivot**]{.hl-yellow}.
- `names_to`: name of the new variable to which we send the [**header**]{.hl-yellow} of the table (the names).
- `values_to`: name of the new variable to which we are going to send the [**data**]{.hl-yellow}.

---

## Messy data

Let's see another example with table `table2`.

```{r}
table2
```


[**What could be wrong?**]{.hl-red}

---

## Pivot wider

::: columns
::: {.column width="60%"}
```{r}
#| echo: false
table2
```
:::

::: {.column width="40%"}
â Each [**observation is divided into two rows**]{.hl-red} â†’ the [**records with the same year should be the same**]{.hl-yellow}
:::
:::

. . .

What we will do will be the opposite: with `pivot_wider()` [**we will widen the table**]{.hl-yellow}

```{r}
table2 |>  pivot_wider(names_from = type, values_from = count)
```

---

## Messy data

Let's see another example with table `table3`.

```{r}
table3
```


[**What could be wrong?**]{.hl-red}

---

## Separate

::: columns
::: {.column width="60%"}
```{r}
table3
```
:::

::: {.column width="40%"}
â Each [**cell contains several values**]{.hl-red}
:::
:::

. . .

What we will do is make use of the `separate()` function to send [**separate each value**]{.hl-yellow} to a different column.


```{r}
table3 |> separate(rate, into = c("cases", "pop"))
```

---

## Separate

```{r}
table3 |> separate(rate, into = c("cases", "pop"))
```

Notice that the data, although it has separated them, [**kept them as text**]{.hl-red} when in fact they should be numeric variables. For this we can add the optional argument `convert = TRUE`.

. . .

```{r}
table3 |> separate(rate, into = c("cases", "pop"), convert = TRUE)
```

---

## Messy data

Let's see the last example with table `table5`.

```{r}
table5
```


[**What could be wrong?**]{.hl-red}

---

## Unite

::: columns
::: {.column width="50%"}
```{r}
table5
```
:::

::: {.column width="50%"}
â We have [**same values divided in two columns**]{.hl-red}
:::
:::

. . .

We will use `unite()` to [**unite the values**]{.hl-yellow} of century and year in the same column

```{r}
table5 |> unite(col = whole_year, century, year, sep = "")
```

---

## Nest data

We can also [**nest datasets inside another one**]{.hl-yellow}: imagine we have a dataset with variables `x` and `y`, with two records, another with one and another with 3 of them.

```{r}
data <-
  tibble("dataset" = c(1, 1, 2, 3, 3, 3), 
         "x" = c(0, 2, NA, -2, 6, 7),
         "y" = c(-1, NA, 5, 1.5, NA, -2))
data
```

In reality everything that has an equal value in `dataset` should form its own `tibble` so let's create one inside the one we have

---

## Nest data

For it we will use the function `nest()` indicating it which variables form the datasets that will be nested (in this case variables `x` and `y`). Notice that inside what it stores is a variable of type list (since each dataset has a different length).

```{r}
data_nest <-
  data |>
  nest(data = c(x, y))
data_nest
```

---

## Nest data

To [**unnest**]{.hl-yellow} just use the `unnest()` function indicating the column to unnest.

```{r}
data_nest |> unnest(cols = c(data))
```

---

## Example: world bank pop

In the `{tidyr}` package we have the `world_bank_pop` dataset which contains data from the World Bank about population per country from 2000 to 2018.

```{r}
library(tidyr)
world_bank_pop
```

[**What could be wrong?**]{.hl-red}

---

## Example: world bank pop

First of all, we can see that we effectively have the same variable in 18 columns: population.

. . .

What we should have is a column called `pop` with these values and another `year` indicating to which year corresponds the measurement. And for this we will do it with `pivot_longer()`.

```{r}
world_bank_pop_tidy <-
  world_bank_pop |> 
  pivot_longer(cols = -(country:indicator), names_to = "year", values_to = "value")
world_bank_pop_tidy
```

---

## Example: world bank pop

```{r}
world_bank_pop_tidy
```

[**Is everything correct?**]{.hl-red}

. . .

If you notice we have two types of population measures, total `...TOTL` and its growth `...GROW`, but in addition we have them for each country in global `SP.POP...` and only in urban area `SP.URB...`.

```{r}
unique(world_bank_pop_tidy$indicator)
```

---

## Example: world bank pop


What should be done?

. . .

We will separate this variable into 3: one for the prefix `SP` (which we will eliminate later), one for the area (`POP/URB`) and one for the value (`variable`), which can be total or growth.

```{r}
world_bank_pop_tidy2 <-
  world_bank_pop_tidy |>
  separate(indicator, c("dummy", "area", "variable"))
world_bank_pop_tidy2$dummy <- NULL
world_bank_pop_tidy2
```

---

## Example: world bank pop

This can be done in a simpler way by indicating in the variable that we want to eliminate that it is `NA` inside `separate()`.

```{r}
world_bank_pop_tidy <-
  world_bank_pop_tidy |>
  separate(indicator, c(NA, "area", "variable"))
world_bank_pop_tidy
```

. . .

Have we got it yet? Think carefully: does each variable have its own column?

---

## Example: world bank pop

If you actually look at the total population and growth variables, they should be different variables, since they even have different units: one is inhabitants, the other is percentage points.

. . .

To do the reverse of the initial operation, `pivot_wider()` (later we will use a tremendously useful function, `{janitor}`'s `clean_names()` which unifies variable names).

```{r}
world_bank_pop_tidy <-
  world_bank_pop_tidy |>
  pivot_wider(names_from = "variable", values_from = "value") |> 
  janitor::clean_names()
world_bank_pop_tidy
```

---

## Example: world bank pop

The complete code would be this: short, concise, readable and self-descriptive.

```{r}
world_bank_pop_tidy <-
  world_bank_pop |> 
  pivot_longer(cols = -(country:indicator), names_to = "year", values_to = "value") |> 
  separate(indicator, c(NA, "area", "variable")) |> 
  pivot_wider(names_from = "variable", values_from = "value") |> 
  janitor::clean_names()
world_bank_pop_tidy
```

---

## Example: who dataset

In`{tidyr}` package we have `who2` dataset (World Health Organization dataset)

```{r}
library(tidyr)
who2
```

**Is it tidy data? Why?**

---

## Example: who dataset

First step for tidy data: we must pivot the table (tip: use paper and pen to sketch how the database should look like) so that there is a column called `cases` (since all columns starting from `year` is actually the same, cases of a disease).

. . .

```{r}
who_tidy <-
  who2 |> 
  pivot_longer(cols = -(country:year), names_to = "type", values_to = "cases")
who_tidy
```

---

## Example: who dataset

If you notice there are a lot of rows that do not make sense to keep because we have no cases! Investigate the `pivot_longer()` options to see how we can directly remove them in the pivot.

. . .

```{r}
who_tidy <-
  who2 |> 
  pivot_longer(cols = -(country:year), names_to = "type", values_to = "cases",
               values_drop_na = TRUE)
who_tidy
```


---

## Example: who dataset

Now in `type` we have coded the information as `diagnosis_sex_age`. How to separate it in 3 columns? Investigate both `separate()` and `pivot_longer()` options.

```{r}
# separate
who_tidy <-
  who_tidy |> 
  separate(col = "type", into = c("diagnosis", "sex", "age"))

# pivot_longer
who_tidy <-
  who2 |> 
  pivot_longer(cols = -(country:year), names_to = c("diagnosis", "sex", "age"),
               values_to = "cases", values_drop_na = TRUE,
               names_sep = "_")
who_tidy
```
 


---

## Example: who dataset

Finally, separate in two (`age_inf`, `age_sup`) the age range (which are numbers). Think about how to do it since it is not always 4 numbers (if there is no upper age range defined, put `Inf` as an upper bound).

. . .

```{r}
who_tidy <-
  who_tidy |> 
  separate(col = "age", into = c("age_inf", "age_sup"), sep = -2, convert = TRUE)
who_tidy$age_inf <- if_else(is.na(who_tidy$age_inf), 65, who_tidy$age_inf)
who_tidy$age_sup <- if_else(who_tidy$age_sup == 65, Inf, who_tidy$age_sup)
who_tidy
```

---


## ğŸ’» It's your turn {#tu-turno-1-2}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}


ğŸ“ Use the original `who2` dataset from the `{tidyr}` package and try to answer the question: how many cases of tuberculosis were there in Spain in 1995 among women? Do it without converting it to tidydata. After that, pivot in a simple way and compare the code to be done when we have tidydata to when we don't. Which one is more readable if you didn't know `R`? Which one has higher error probability?

```{r}
#| code-fold: true
#| eval: false

# messy data
sum(who2[who2$country == "Spain" & who2$year == 1995,
     names(who2)[str_detect(names(who2), "f_")]], na.rm = TRUE)

# tidy data (at this moment)
sum(who_tidy[who_tidy$country == "Spain" &
           who_tidy$year == 1995 &
           who_tidy$sex == "f", ]$cases)

# in the future
who_tidy |> 
  filter(country == "Spain" & year == 1995 & sex == "f") |> 
  summarise(sum(cases))
```


### [**Exercise 2**]{.hl-yellow}

ğŸ“ Using `who_tidy` determine which sex has had more cases, men or women? Create a new variable `avg_age` (mean age of the interval): if the range is 25 to 34, the mean age will be $(25 + 34)/2 = 29.5$ (if `Inf` above, `NA`)

```{r}
#| code-fold: true
#| eval: false

# f vs m
sum(who_tidy[who_tidy$sex == "m", ]$cases)
sum(who_tidy[who_tidy$sex == "f", ]$cases)

# ave age
who_tidy$ave_age <- 
  if_else(is.infinite(who_tidy$age_sup), NA, (who_tidy$age_inf + who_tidy$age_sup)/2)
```


### [**Exercise 3**]{.hl-yellow}

ğŸ“ If we must choose a country in which we have the lowest probability of infection, which country, between the United Kingdom (`United Kingdom of Great Britain and Northern Ireland`) and France (similar population), had the fewest cases in the most recent year (whichever it was, even if the table was updated)?

```{r}
#| code-fold: true
#| eval: false

last_cases <- who_tidy[who_tidy$year == max(who_tidy$year), ]
sum(last_cases[last_cases$country == "United Kingdom of Great Britain and Northern Ireland", "cases"])
sum(last_cases[last_cases$country == "France", "cases"])
# better France
```


### [**Exercise 4**]{.hl-yellow}

ğŸ“ Take a look at table `table4b` in package `{tidyr}`. Is it tidydata? If not, what is wrong, how to convert it to tidy data in case it is not already?

```{r}
#| code-fold: true
#| eval: false
table4b |>
  pivot_longer(cols = "1999":"2000", names_to = "year",
               values_to = "cases")
```


### [**Exercise 5**]{.hl-yellow}

ğŸ“ Take a look at the `billboard` table in the `{tidyr}` package. Is it tidydata? If not, what is wrong, how to convert it to tidy data in case it is not already?

```{r}
#| code-fold: true
#| eval: false
billboard |>
  pivot_longer(cols = "wk1":"wk76",
               names_to = "week",
               names_prefix = "wk",
               values_to = "position",
               values_drop_na = TRUE)
```

:::


---


## ğŸ£ Case study {#caso-practico-1}

Let's perform a case study with the `relig_income` table in `{tidyr}` package. As indicated (`? relig_income`), the table represents the number of people in each annual income bracket (20k = 20 000$) and in each religion.

```{r}
#| eval: false
relig_income
```


&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidy-data-mucss)

# L2: [tidyverse (rows)]{.flow} {#clase-2}

[**Tidyverse: actions by rows**]{style="color:#444442;"}

* [ğŸ’» Solved exercises: filter](#tu-turno-2-1) 

* [ğŸ’» Solved exercises: slice, sample, arrange](#tu-turno-2-2) 

* [ğŸ£ Workbook/caso study](#caso-practico-2)

* [ğŸ“† Planning](#planificacion-curso)

---

## Preprocessing: dplyr

Within `{tidyverse}` we will use the `{dplyr}` package for the [**preprocessing process**]{.hl-yellow} of the data.

::: columns
::: {.column width="60%"}
![](img/dplyr.png){width=450}
:::

::: {.column width="40%"}
```{r}
#| eval: false
data |>
  tidy(...) |>
  filter(...) |>
  select(...) |>
  arrange(...) |>
  modify(...) |> # mutate in the code
  rename(...) |>
  group(...) |>
  count(...) |>
  summarise(...) |>
  plot(...) # actually ggplot
```
:::
:::

The idea is that the [**code is as readable as possible**]{.hl-yellow}, as if it were a **list of instructions** that when read tells us in a very obvious way what it is doing.


---

## Assumption: tidydata

::: columns
::: {.column width="50%"}

All the preprocessing process we are going to perform is on the [**assumption that our data is in tidydata**]{.hl-yellow}

:::

::: {.column width="50%"}
![](img/tidy_def.jpg){width="160%"}
:::
::::

Remember that in `{tidyverse}` the [**pipe operator**]{.hl-yellow} defined as `|>` ([**ctrl+shift+M**]{.hl-purple}) will be key: it will be a [**pipe that traverses the data**]{.hl-yellow} and transforms it.


. . .

Let us practice with the `starwars` dataset from the `{dplyr}` package.

```{r}
#| eval: false
library(tidyverse)
starwars
```

---


## Sampling

:::: columns
::: {.column width="60%"}

One of the most common operations is what is known in statistics as [**sampling**]{.hl-yellow}: a [**selection or filtering of records (rows)**]{.hl-yellow} (a subsample).


:::

::: {.column width="40%"}

![](img/muestreo.jpeg){width=500}
:::
::::

. . .


* [**Non-random (by quota)**]{.hl-purple}: based on logical conditions on the records (`filter()`).

. . .

* [**Non-random (intentional/discretionary)**]{.hl-purple}: based on a position (`slice()`).

. . .

* [**Simple random**]{.hl-purple} (`slice_sample()`).

. . .

* [**Stratified**]{.hl-purple} (`group_by()` + `slice_sample()`).


---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

The simplest action by rows is when [**filter records**]{.hl-yellow} based on some logical condition: with `filter()` only individuals meeting certain conditions will be selected (non-random sampling by conditions).


::: incremental
-   `==`, `!=`: [**equal**]{.hl-purple} or [**different**]{.hl-yellow} to (`|> filter(variable == "a")`)
-   `>`, `<`: [**greater**]{.hl-purple} or [**less**]{.hl-yellow} than (`|> filter(variable < 3)`)
-   `>=`, `<=`: [**greater or equal**]{.hl-yellow} or [**less or equal**]{.hl-purple} than (`|> filter(variable >= 5)`)
-   `%in%`: values [**belong**]{.hl-yellow} to a set of discrete options (`|> filter(variable %in% c("blue", "green"))`)
-   `between(variable, val1, val2)`: if continuous values are [**inside of a range**]{.hl-yellow} (`|> filter(between(variable, 160, 180))`)
:::

---

## Filter rows: filter()

These [**logical conditions**]{.hl-yellow} can be [**combined**]{.hl-yellow} in different ways (and, or, or mutually exclusive).


![](img/tablas_verdad.png)

. . .


::: callout-tip
## Important

Remember that inside `filter()` there must always be something that returns a [**vector of logical values**]{.hl-green}.

:::

---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about... [**filter**]{.hl-yellow} the characters with [**brown eyes**]{.hl-purple}?

. . .

[**What type of variable is it?**]{.hl-yellow} --> The `eye_color` variable is qualitative so it is represented by texts.

. . .

```{r}
#| echo: false
#| include: false
library(tidyverse)
```

```{r}
starwars |>
  filter(eye_color == "brown")
```

---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about... [**filter**]{.hl-yellow} the characters that [**do not have brown eyes**]{.hl-purple}?

. . .


```{r}
starwars |>
  filter(eye_color != "brown")
```

---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about ... [**filter**]{.hl-yellow} characters that [**have brown or blue eyes**]{.hl-purple}?

. . .

```{r}
starwars |>
  filter(eye_color %in% c("blue", "brown"))
```

---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

Note that `%in%` is equivalent to concatenating several `==` with a conjunction or (`|`)

```{r}
starwars |>
  filter(eye_color == "blue" | eye_color == "brown")
```

---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about ... [**filter**]{.hl-yellow} the characters that [**are between 120 and 160 cm**]{.hl-purple}?

. . .

[**What type of variable is it?**]{.hl-yellow} --> The variable `height` is a continuous quantitative variable so we must filter by ranges of values (intervals) --> we will use `between()`.

. . .

```{r}
starwars |>
  filter(between(height, 120, 160))
```


---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you... [**filter**]{.hl-yellow} characters that [**have eyes and are not human**]{.hl-purple}?

. . .

```{r}
starwars |>
  filter(eye_color == "brown" & species != "Human")
```

---

## Filter rows: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  filtro(condition)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you... [**filter**]{.hl-yellow} characters that [**have eyes and are not human, or are over 60 years old**]{.hl-purple}? Think it through: the [**parentheses are important**]{.hl-yellow}: $(a+b)*c$ is not the same as $a+(b*c)$.

. . .

```{r}
starwars |>
  filter((eye_color == "brown" & species != "Human") | birth_year > 60)
```

---

## Drop missings: drop_na()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  drop_missings(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na(var1, var2, ...)
```
:::
:::

There is a special **filter** for one of the most common operations in debugging: [**remove absent**]{.hl-yellow}. For this we can use inside a filter `is.na()`, which returns `TRUE/FALSE` depending on whether it is absent, or ...

. . .

Use `drop_na()`: if we do not specify a variable, it removes records with missing in any variable. Later on we will see how to [**impute those missing**]{.hl-yellow} 

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na(mass, height)
```

```{r}
#| echo: false
starwars |>
  drop_na(mass, height, sex) |> 
  select(name, mass, height, hair_color) |> 
  slice(1:7)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na()
```

```{r}
#| echo: false
starwars |>
  drop_na() |> 
  select(name, mass, height, hair_color) |> 
  slice(1:7)
```
:::
:::

---

## ğŸ’» It's your turn {#tu-turno-2-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ Select from the starwars set only those characters that are androids or whose `species` value is unknown.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter(species == "Droid" | is.na(species))
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Select from the starwars set only the characters whose weight is between 65 and 90 kg.

```{r}
#| code-fold: true
#| eval: false
starwars |> filter(between(mass, 65, 90))
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ After clearing absent in all variables, select from the starwars set only the characters that are human and come from Tatooine.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na() |> 
  filter(species == "Human" & homeworld == "Tatooine")
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Select from the original starwars set non-human characters, `male` in sex and measuring between 120 and 170 cm, or characters with brown or red eyes.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter((species != "Human" & sex == "male" &
            between(height, 120, 170)) |
           eye_color %in% c("brown", "red"))
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Look for information in the `str_detect()` function help of the `{stringr}` package (loaded in `{tidyverse}`). Tip: test the functions you are going to use with some test vector beforehand so that you can check how they work. After you know what it does, filter out only those characters with the last name `Skywalker`.

```{r}
#| code-fold: true
#| eval: false
starwars |> filter(str_detect(name, "Skywalker"))
```
:::

---

## Slices of data: slice()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> slice(positions)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice(positions)
```
:::
:::

Sometimes we may be interested in performing a [**non-random discretionary sampling**]{.hl-yellow}, or in other words, [**filter by position**]{.hl-yellow}: with `slice(positions)` we can select specific rows by passing as argument a [**index vector**]{.hl-yellow}.

. . .

::: columns
::: {.column width="50%"}
```{r}
#| eval: false

# fila 1
starwars |>
  slice(1)
```

```{r}
#| echo: false
starwars |> slice(1) |> select(name:hair_color)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false

# from the 7th to the 9th row
starwars |>
  slice(7:9)
```

```{r}
#| echo: false
starwars |> slice(7:9) |> select(name:hair_color)
```
:::
:::

. . .

```{r}
#| eval: false

# 2, 7, 10 and 31th rows
starwars |>
  slice(c(2, 7, 10, 31))
```

```{r}
#| echo: false
starwars |>
  slice(c(2, 7, 10, 31)) |> select(name:sex)
```

---

## Slices of data: slice()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  slice(positions)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice(positions)
```
:::
:::

We have default options:

* with `slice_head(n = ...)` and `slice_tail(n = ...)` we can get the [**header and tail**]{.hl-yellow} of the table

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice_head(n = 2)
```

```{r}
#| echo: false
starwars |> slice_head(n = 2) |> select(name:hair_color)
```
:::

::: {.column width="\"50%"}
```{r}
#| eval: false
starwars |> slice_tail(n = 2)
```

```{r}
#| echo: false
starwars |> slice_tail(n = 2) |> select(name:hair_color)
```
:::
:::

---

## Slices of data: slice()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  slice(positions)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice(positions)
```
:::
:::

We have default options:

* with `slice_max()` and `slice_min()` we get the [**rows with smallest/largest value of a variable**]{.hl-yellow} (if tie, all unless `with_ties = FALSE`) which we indicate in `order_by = ...`.

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice_min(mass, n = 2)
```

```{r}
#| echo: false
starwars |> slice_min(n = 2, order_by = mass) |> select(name:hair_color)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice_max(height, n = 2)
```

```{r}
#| echo: false
starwars |> slice_max(n = 2, order_by = height) |> select(name:hair_color)
```
:::
:::

---

## Random sampling: slice_sample()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  slice_aleatorias(positions)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice_sample(positions)
```
:::
:::

The so-called [**simple random sampling**]{.hl-yellow} is based on [**selecting individuals randomly**]{.hl-yellow}, so that each one has certain [**probabilities**]{.hl-yellow} of being selected. With `slice_sample(n = ...)` we can randomly extract n (a priori equiprobable) records.

```{r}
starwars |> slice_sample(n = 2)
```

. . .

::: callout-important
## Important

[**"Random" does not imply equiprobable**]{.hl-yellow}: a normal die is just as random as a trick die. There are no things "more random" than others, they simply have different underlying probability laws.


:::

---

## Random sampling: slice_sample()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  slice_random(positions)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice_sample(positions)
```
:::
:::

We can also indicate the [**proportion of data to sample**]{.hl-yellow} (instead of the number) and if we want it to be [**with replacement (that can be repeated)**]{.hl-yellow}.

```{r}
# 5% of random rows with replacement
starwars |> 
  slice_sample(prop = 0.05, replace = TRUE)

```


---


## Random sampling: slice_sample()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  slice_random(positions)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice_sample(positions)
```
:::
:::

As we said, "random" is not the same as "equiprobable", so we can pass a [**probability vector**]{.hl-yellow}. For example, let's force that it is very improbable to draw a row other than the first two rows

```{r}
starwars |>
  slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85)))
```

. . .

```{r}
starwars |>
  slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85)))
```

---

## sample()

The `slice_sample()` function is simply a `{tidyverse}` integration of the basic `R` function known as `sample()` that allows us to [**sample elements**]{.hl-yellow}


. . .

For example, let's [**sample 10 rolls of a die**]{.hl-yellow}, telling it

- [**support**]{.hl-purple} of our random variable (allowed values in `x`)
- [**sample size**]{.hl-purple} (`size`)
- [**replacement**]{.hl-purple} (if `TRUE` then they can come out repeated, as in the case of the die).

```{r}
sample(x = 1:6, size = 10, replace = TRUE)
```

---

## sample()

The previous option generates events of a random variable [**equiprobable**]{.hl-yellow} but as before, we can assign a vector of probabilities or [**mass function**]{.hl-yellow} to it with the argument `prob = ...`.


```{r}
sample(x = 1:6, size = 50, replace = TRUE,
       prob = c(0.5, 0.2, 0.1, 0.1, 0.05, 0.05))
```

---


## sample()

**How would you make the following statement?**

&nbsp;

Suppose that seasonal flu episodes have been studied in a city. Let $X_m$ and $X_p$ be random variables such that $X_m=1$ if the mother has flu, $X_m=0$ if the mother does not have flu, $X_p=1$ if the father has flu and $X_p=0$ if the father does not have flu. The theoretical model associated with this type of epidemics indicates that the joint distribution is given by $P(X_m = 1, X_p=1)=0.02$, $P(X_m = 1, X_p=0)=0.08$, $P(X_m = 1, X_p=0)=0. 1$ and $P(X_m = 0, X_p=0)=0.8$

**Generate a sample** of size $n = 1000$ (support `"10"`, `"01"`, `"00"` and `"11"`) by making use of `runif()` and by making use of `sample()`.


---


## Sort by rows: arrange()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> sort(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> arrange(var1, var2, ...)
```
:::
:::

We can also [**order by rows**]{.hl-yellow} according to some variable with `arrange()`.

```{r}
#| eval: false
starwars |> arrange(mass)
```

```{r}
#| echo: false
starwars |> arrange(mass) |> select(name:eye_color) |> slice(1:5) 
```

. . .

By [**from lowest to highest**]{.hl-yellow} but we can [**reverse the order**]{.hl-purple} with `desc()`.


::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |> arrange(desc(height))
```

```{r}
#| echo: false
starwars |> arrange(desc(height)) |> select(name:mass) |> slice(1:5) 
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> arrange(mass, desc(height))
```

```{r}
#| echo: false
starwars |> arrange(mass, desc(height)) |> select(name:mass) |> slice(1:5) 
```
:::
:::

---

## Remove duplicates: distinct()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> no_duplicates(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> distinct(var1, var2, ...)
```
:::
:::

Many times we will need to make sure that there are no duplicates in some variable (DNI) and we can [**delete duplicate rows**]{.hl-yellow} with `distinct()`.

```{r}
starwars |> distinct(sex)
```

. . .

To keep all the columns of the table we will use `.keep_all = TRUE`.

```{r}
#| eval: false
starwars |> distinct(sex, .keep_all = TRUE)
```

```{r}
#| echo: false
starwars |> distinct(sex, .keep_all = TRUE) |> slice(1:3)
```

---

## Including rows: bind_rows()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
tibble1 |> include_rows(tibble2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
tibble1 |> bind_rows(tibble2)
```
:::
:::

Finally, we can [**bind new rows**]{.hl-yellow} with `bind_rows()` with [**new observations in table**]{.hl-red} (if columns do not match fill with absent)

```{r}
data <-
  tibble("name" = c("javi", "laura"), "age" = c(33, 50))
data
```

. . .

```{r}
data |> bind_rows(tibble("name" = c("carlos", NA), "cp" = c(28045, 28019)))
```

---


## ğŸ’» It's your turn {#tu-turno-2-2}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Select only the characters that are human and brown-eyed, then sort them in descending height and ascending weight.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter(eye_color == "brown" & species == "Human") |> 
  arrange(height, desc(mass))
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Randomly extracts 3 records.

```{r}
#| code-fold: true
#| eval: false
starwars |> slice_sample(n = 3)
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Extracts 10% of the records randomly.

```{r}
#| code-fold: true
#| eval: false
starwars |> slice_sample(prop = 0.1)
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“R andomly draws 10 characters but in such a way that the probability of each character being drawn is proportional to its weight (heavier, more likely).

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(mass) |> 
  slice_sample(n = 10, weight_by = mass)
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Select the 3 oldest characters.

```{r}
#| code-fold: true
#| eval: false
starwars |> slice_max(birth_year, n = 3)
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ To find out what unique values are in the hair color, remove duplicates of the `hair_color` variable by first removing the missing ones from the `hair_color` variable.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(hair_color) |> 
  distinct(hair_color)
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ Of the characters that are human and taller than 160 cm, eliminate duplicates in eye color, eliminate absent in weight, select the 3 tallest, and order from tallest to shortest in weight. Return the table.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter(species == "Human" & height > 160) |> 
  distinct(eye_color, .keep_all = TRUE) |> 
  drop_na(mass) |> 
  slice_max(height, n = 3) |> 
  arrange(desc(mass))
```

:::


---

## ğŸ£ Case study {#caso-practico-2}

Let's go back to a known dataset: in the `{datasets}` package (already installed by default) we had several datasets and one of them was `airquality` which we already worked with. The data captures [**daily measurements (n = 153 observations) of air quality**]{.hl-yellow} in New York, from May to September 1973.

At that time we worked it from the R base perspective and extracted some variables from it. The objective now will be to work it from the `{tidyverse}` perspective looking at the differences from one form to the other.

```{r}
#| eval: false
library(datasets)
airquality
```

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).


# L3: [tidyverse (columns)]{.flow} {#clase-3}

[**Tidyverse: actions by columns**]{style="color:#444442;"}

* [ğŸ’» Solved exercises: select](#tu-turno-3-1) 

* [ğŸ’» Solved exercises: mutate, if_else, case_when](#tu-turno-3-2) 

* [ğŸ£ Workbook/case study I: viogen survey](#caso-practico-3-1)

* [ğŸ£ Workbook/case study II: Taylor Swift again](#caso-practico-3-2)

* [ğŸ£ Workbook/case study III: The Lord of the Rings](#caso-practico-3-3)

* [ğŸ“† Planning](#planificacion-curso)

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> select(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

Up to now all operations performed (even if we used column info) were by rows. In the case of columns, the simplest action is to [**select variables by name**]{.hl-yellow} with `select()`, giving as arguments the column names [**without quotes**]{.hl-purple}.

```{r}
starwars |> select(name, hair_color)
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> select(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

The `select()` function allows us to select several variables at once, including [**concatenating their names as if they were numerical indexes**]{.hl-yellow} with `:`

```{r}
#| eval: false
starwars |> select(name:eye_color) 
```

```{r}
#| echo: false
starwars |> select(name:eye_color) |> slice(1:4)
```

. . .

And we can [**deselect columns**]{.hl-yellow} with `-` in front of it

```{r}
#| eval: false
starwars |>  select(-mass, -(eye_color:starships))
```

```{r}
#| echo: false
starwars |> select(-mass, -(eye_color:starships)) |> slice(1:4)
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> select(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

We have also [**reserved words**]{.hl-yellow}: `everything()` [**all variables**]{.hl-purple}....

```{r}
#| eval: false
starwars |> select(mass, homeworld, everything())
```

```{r}
#| echo: false
starwars |> select(mass, homeworld, everything()) |> slice(1:4)
```

. . .

...and `last_col()` to refer to [**last column**]{.hl-purple}.

```{r}
#| eval: false
starwars |> select(name:mass, homeworld, last_col())
```

```{r}
#| echo: false
starwars |> select(name:mass, homeworld, last_col()) |> slice(1:4)
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> select(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

We can also play with [**patterns**]{.hl-yellow} in the name, those that [**begin with a prefix**]{.hl-purple} (`starts_with()`), [**end with a suffix**]{. hl-purple} (`ends_with()`), [**contain text**]{.hl-purple} (`contains()`) or fulfill a [**regular expression**]{.hl-purple} (`matches()`).

```{r}
# variables which col name finish as "color" and contains sex and gender
starwars |> select(ends_with("color"), matches("sex|gender"))
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> select(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

We can even [**select by numeric range**]{.hl-yellow} if we have variables with a prefix and numbers.

```{r}
data <-
  tibble("wk1" = c(115, 141, 232), "wk2" = c(7, NA, 17),
         "wk3" = c(95, 162, NA), "wk4" = c(11, 19, 15),
         "wk5" = c(NA, 262, 190), "wk6" = c(21, 15, 23))
```

. . .

With `num_range()` we can select with a prefix and a numeric sequence.

```{r}
data |> select(num_range("wk", 1:4))
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> select(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

Finally, we can select columns by [**datatatype**]{.hl-yellow} using `where()` and inside a function that returns a logical value of datatype.

```{r}
# just numeric and string columns
starwars |> select(where(is.numeric) | where(is.character))
```


---

## Move columns: relocate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  move(var1, after = var2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  relocate(var1, .after = var2)
```
:::
:::

To facilitate the [**relocation of variables**]{.hl-yellow} we have a function for it, `relocate()`, indicating in `.after` or `.before` [**behind**]{.hl-purple} or [**in front**]{.hl-purple} of which columns we want to move them.

```{r}
starwars |> relocate(species, .before = name)
```

---

## Rename: rename()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> rename(new = old)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> rename(new = old)
```
:::
:::

Sometimes we may also want to [**modify the â€œmeta-information â€**]{.hl-yellow} of the data, [**renaming columns**]{.hl-yellow}. To do this we will use `rename()` by typing [**first the new name**]{.hl-purple} and then the [**old**]{.hl-purple}.

```{r}
starwars |> rename(nombre = name, altura = height, peso = mass)
```

---

## Extract columns: pull()


::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> extract(var)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> pull(var)
```
:::
:::


If you look at the output of the `select()` [**still a tibble table**]{.hl-yellow}, it preserves the nature of our data.

```{r}
starwars |> select(name)
```

---


## Extract columns: pull()


::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> extract(var)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> pull(var)
```
:::
:::


Sometimes we will not want such a structure but [**literally extract the column in a VECTOR**]{.hl-yellow}, something we can do with `pull()`.


```{r}
starwars |> pull(name)
```


---


## ğŸ’» It's your turn {#tu-turno-3-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Filter the set of characters and keep only those that do not have a missing data in the `height` variable. With the data obtained from the previous filter, select only the variables name, height, as well as all those variables that CONTAIN the word color in their name.

```{r}
#| code-fold: true
#| eval: false

starwars_2 <-
  starwars |> 
  drop_na(height) |> 
  select(name, height, contains("color"))
```


### [**Exercise 2**]{.hl-yellow}

ğŸ“ With the data obtained from the previous Exercise, translate the names of the columns into Spanish (or your motherlanguage).

```{r}
#| code-fold: true
#| eval: false

starwars_2 |> 
  rename(nombre = name, altura = height, color_pelo = hair_color,
         color_piel = skin_color, color_ojos = eye_color)
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ With the data obtained from Exercise 1, place the hair color variable just after the name variable.

Con los data obtenidos del Exercise anterior, coloca la variable de color de pelo justo detrÃ¡s de la variable de nombres.

```{r}
#| code-fold: true
#| eval: false

starwars_2 |>
  relocate(hair_color, .after = name)
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ With the data obtained from the Exercise 1, check how many unique modalities there are in the hair color variable (without using `unique()`).

```{r}
#| code-fold: true
#| eval: false

starwars_2 |>
  distinct(hair_color)
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ From the original data set, it removes the list type columns, and then removes duplicates in the `eye_color` variable. After removing duplicates it extracts that column into a vector.

```{r}
#| code-fold: true
#| eval: false

starwars |> 
  select(-where(is.list)) |> 
  distinct(eye_color, .keep_all = TRUE) |> 
  pull(eye_color)
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ From the original starwars dataset, with only the characters whose height is known, extract in a vector with that variable.

```{r}
#| code-fold: true
#| eval: false

starwars |> 
  drop_na(height) |> 
  pull(height)
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ After obtaining the vector from the previous Exercise, use this vector to randomly sample 50% of the data so that the probability of each character being chosen is inversely proportional to their height (shorter, more options).

```{r}
#| code-fold: true
#| eval: false

heights <-
  starwars |> 
  drop_na(height) |> 
  pull(height)
  
starwars |> 
  slice_sample(prop = 0.5, weight_by = 1/heights)
```

:::



---

## Modify columns: mutate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> modify(new_var = funcion())
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> mutate(new_var = function())
```
:::
:::

In many occasions we will want to [**modify or create variables**]{.hl-yellow} with `mutate()`. 

. . . 

Let's create for example a new variable `height_m` with the height in meters.

```{r}
starwars |> mutate(height_m = height / 100)
```

---

## Modify columns: mutate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> modify(new_var = funcion())
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> mutate(new_var = function())
```
:::
:::

In addition with the optional arguments we can [**reposition the modified column**]{.hl-yellow}

```{r}
starwars |> 
  mutate(height_m = height / 100,
         BMI = mass / (height_m^2), .before = name)
```

---

## Modify columns: mutate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> modify(new_var = funcion())
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> mutate(new_var = function())
```
:::
:::

::: callout-important
## Important

When we apply `mutate()`, we must remember that the [**operations are performed vector by vector**]{.hl-yellow}, element by element, so the function we use inside must return a vector of equal length. Otherwise, [**it will return a constant**]{.hl-red}.

:::

. . .

```{r}
starwars |> 
  mutate(constante = mean(mass, na.rm = TRUE), .before = name)
```

---

## Recategorize: if_else()

We can also combine `mutate()` with the `if_else()` control expression to [**recategorize the variable**]{.hl-yellow}: if [**a condition**]{.hl-purple} is met, it does one thing, otherwise another.


```{r}
starwars |> 
  mutate(human = if_else(species == "Human", "Human", "Not Human"),
         .after = name) |> 
  select(name:mass)
```

---

## Recategorize: case_when()

For [**more complex categorizations**]{.hl-yellow} we have `case_when()`, for example, to create a category of characters based on their height.

```{r}
starwars |> 
  drop_na(height) |> 
  mutate(altura = case_when(height < 120 ~ "dwarf",
                            height < 160 ~ "short",
                            height < 180 ~ "normal",
                            height < 200 ~ "tall",
                            TRUE ~ "giant"), .before = name)
```

---

## nest data

We can also [**nest or embed datasets inside each other**]{.hl-yellow}. Imagine that we have a dataset of `x` and `y` variables with 2 records, another one with the same variables but only one record and another one with 3 records.

```{r}
data_1 <- tibble("x" = c(0, 2), "y" = c(-1, NA))
data_2 <- tibble("x" = c(NA), "y" = c(5))
data_3 <- tibble("x" = c(-2, 6, 7), "y" = c(1.5, NA, -2))
```

. . .

So far the only way we know how to [**bind the 3 datasets**]{.hl-yellow} is by using `bind_rows()` (by the way, if you use the argument `.id = â€œvariable_nameâ€` we can make it add a new variable that tells us to which dataset each row belonged.

```{r}
data <- bind_rows(data_1, data_2, data_3, .id = "dataset")
data
```

---

## nest data

```{r}
data <- bind_rows(data_1, data_2, data_3, .id = "dataset")
data
```

However, in many occasions we will want to have [**all 3 in the same object BUT each dataset on its own**]{.hl-yellow}: an object (a list) that stores the 3 datasets separated from each other

. . .

To do this we will use the `nest()` function indicating which common variables form the datasets (in this case `x` and `y`).


```{r}
data_nest <-
  data |>
  nest(data = c(x, y))
data_nest
```

---

## nest data

```{r}
data_nest
```

Note that now `data_nest` is a list as each stored dataset could have different lengths

---

## nest data

To [**unnest we can use unnest()**]{.hl-yellow} indicating the column containing the datasets


```{r}
data_nest |> unnest(cols = c(data))
```

---

## ğŸ’» It's your turn {#tu-turno-3-2}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Select only the variables name, height and as well as all those variables related to the color, while keeping only those that are not absent in the height.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  select(name, height, contains("color")) |> 
  drop_na(height)
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ With the data obtained from the previous Exercise, translate the names of the columns into Spanish or your mother language.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  select(name, height, contains("color")) |> 
  drop_na(height) |> 
  rename(nombre = name, altura = height,
         color_pelo = eye_color, color_piel = skin_color,
         color_pelo = hair_color)
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ With the data obtained from the previous Exercise, place the hair color variable just after the name variable.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  select(name, height, contains("color")) |> 
  drop_na(height) |> 
  rename(nombre = name, altura = height,
         color_pelo = eye_color, color_piel = skin_color,
         color_pelo = hair_color) |> 
  relocate(color_pelo, .after = nombre)
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ With the original data, check how many unique modalities there are in the hair color variable.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  distinct(hair_color) |> 
  nrow()
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ From the original dataset, select only the numeric and text variables. Then define a new variable called `under_18` to recategorize the age variable: `TRUE` if under age and `FALSE` if not.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  select(where(is.numeric) | where(is.character)) |> 
  mutate(under_18 = birth_year < 18)
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ From the original dataset, create a new column named `auburn` that tells us TRUE if the hair color contains that word and FALSE otherwise (reminder `str_detect()`).

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  mutate(auburn = str_detect(hair_color, "auburn"))
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ From the original dataset, include a column that calculates BMI. After that, create a new variable that values `NA` if not human, `underweight` below 18, `normal` between 18 and 30, `overweight` above 30.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  mutate(IMC = mass / ((height/100)^2),
         IMC_recat = case_when(species != "Human" ~ NA,
                               IMC < 18 ~ "underweight",
                               IMC < 30 ~ "normal",
                               TRUE ~ "overweight"),
         .after = name)
```

:::

---


## ğŸ£ Case study I: CIS feminismos {#caso-practico-3-1}


pending to submit

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).



--- 

## ğŸ£ Case study II: Taylor Swift {#caso-practico-3-2}

Let's go back to the analysis of Taylor Swift songs we did in the previous installment.


```{r}
library(taylor)
taylor_album_songs
```

The difference is that now we will try to do everything from a **tidyverse view instead of R base** (it is interesting that you try to translate from one to the other to know how to master both views)

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).


---

## ğŸ£ Case study III: The Lord of the Rings {#caso-practico-3-3}


To practice some `{dplyr}` functions we are going to use data from the [**Lord of the Rings trilogy**]{.hl-yellow} movies. We will load the data directly from the web (Github in this case), without going through the computer before, simply **indicating as path the web where the file is**

* The Fellowship of the Ring -> <https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/The_Fellowship_Of_The_Ring.csv>

* The 2 Towers -> <https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/The_Two_Towers.csv>

* The Return of the King -> <https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/The_Return_Of_The_King.csv>.

```{r}
#| code-fold: true
library(readr)
lotr_1 <-
  read_csv(file = "https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/The_Fellowship_Of_The_Ring.csv")
lotr_2 <-
  read_csv(file = "https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/The_Two_Towers.csv")
lotr_3 <-
  read_csv(file = "https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/The_Return_Of_The_King.csv")
```


Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).


# L4: [tidyverse (summaries)]{.flow} {#clase-4}

[**Summarise and group_by(). Count and summaries**]{style="color:#444442;"}


* [ğŸ’» Solved exercises](#tu-turno-4-1) 

* [ğŸ£ Workbook/case study I: billboard](#caso-practico-4-1)

* [ğŸ£ Workbook/case study II: soccer](#caso-practico-4-2)

* [ğŸ“† Planning](#planificacion-curso)

---


## count()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> count(var1, var2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> count(var1, var2)
```
:::
:::

So far we have only transformed or queried the data but we have not generated statistics. Let's start with the simple: [**how to count (frequencies)?**]{.hl-yellow}

. . .

When used alone `count()` will simply return the number of records, but when used with `count()` variables it calculates what is known as [**frequencies**]{.hl-yellow}: [**number of elements of each modality**]{.hl-purple}.

```{r}
starwars |> count(sex)
```

---

## count()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> count(var1, var2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> count(var1, var2)
```
:::
:::

Also if we pass several variables it calculates what is known as a [**contiguity table**]{.hl-yellow}. With `sort = TRUE` it will return the [**ordered count**]{.hl-purple} (most frequent first).


```{r}
starwars |> count(sex, gender, sort = TRUE)
```

---

## group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  group(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::
:::

One of the most powerful [**functions**]{.hl-yellow} to combine with the actions seen is `group_by()`, which will allow us to [**group our records**]{.hl-yellow} beforehand.


```{r}
starwars |> 
  group_by(sex) |>
  count() |>
  ungroup()
```

---

## group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  group(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::
:::

When applying `group_by()` it is important to understand that it [**DOES NOT MODIFY the data**]{.hl-yellow}, but creates a [**group variable**]{.hl-yellow} (sub-tables for each group) that will modify future actions: the [**operations will be applied to each sub-table separately**]{.hl-purple}

. . .

For example, imagine that we want to extract the highest character with `slice_max()`.

```{r}
starwars |> slice_max(height)
```


---

## group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  group(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::
:::

What if we want to [**extract the tallest character but...of each of the sexes**]{.hl-yellow}?

. . .

```{r}
starwars |>
  group_by(sex) |> 
  slice_max(height) |> 
  ungroup()
```

---

## group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  group(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::
:::

::: columns
::: {.column width="50%"}
![](img/tidydatatutor_1.jpg)
:::

::: {.column width="50%"}
![](img/tidydatatutor_2.jpg)
:::
:::

The web <https://tidydatatutor.com/> allows to visualize the operations of `{tidyverse}` (doing with the old pipe `%>%`)

---

## group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  group(var1, var2) |> 
  some_action() |> 
  ungroup()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  some_action() |>
  ungroup()
```
:::
:::

::: callout-important
## Important

You should always remember to [**make ungroup**]{.hl-red} to remove the created group variable.

:::

. . .

The "new" version of `{dplyr}` now [**allows to include the group variable**]{.hl-yellow} in the call to many functions with the argument `by = ...` or `.by = ...`.

```{r}
#| eval: false
starwars |> slice_max(height, by = sex)
```

```{r}
#| echo: false
starwars |> slice_max(height, by = sex) |> select(name:eye_color)
```

---

## Row-by-row: rowwise()

A very useful option used before an operation is also `rowwise()`: every [**operation that comes afterwards will be applied on each row separately**]{.hl-yellow}. For example, let's define a dummy set of grades.

```{r}
grades <- tibble("maths" = c(7.5, 8, 9.1, 3),
                 "language" = c(8, 6, 6.5, 9.2))
```

. . .

If we apply the average directly the value will be identical since it has done the global average, but we would like to get an [**average per record**]{.hl-yellow}. For that we will use `rowwise()`.

```{r}
grades |> 
  rowwise() |> 
  mutate(ave_grades = mean(c(maths, language)))
```

---

## Summary: summarise()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> simple_summary()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> summarise()
```
:::
:::

Finally we have `summarise()`, which will allow us to get statistical summaries. For example, let's [**calculate the average of the heights**]{.hl-yellow}.

```{r}
starwars |> 
  drop_na(height) |> 
  summarise(ave_height = mean(height))
```

. . .

::: callout-warning
##  Be careful

Notice that `mutate()` returns [**as many rows as original records**]{.hl-yellow}, while with `summarise()` it calculates a [**new summary dataset**]{.hl-purple}, only including what is indicated.

:::

---

## Summary: summarise()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> simple_summary()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> summarise()
```
:::
:::

If we also [**combine this with the grouping**]{.hl-yellow} of `group_by()` or `.by = ...`, in a few lines of code you can get [**disaggregated statistics**]{.hl-purple}.

```{r}
starwars |> 
  drop_na(sex, height, mass) |> 
  summarise(ave_height = mean(height),
            ave_mass = mean(mass),
            .by = sex)
```

---

## Summary: reframe()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |> complex_summary()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> reframe()
```
:::
:::

In the new `{dplyr}` they have included `reframe()` to avoid `summarise()` problems when [**we return more than one value per variable**]{.hl-yellow} in more complex summaries.


::: columns
::: {.column width="50%"}
```{r}
#| warning: true
starwars |>
  drop_na(mass) |>
  summarise(quantile(mass))
```
:::

::: {.column width="50%"}
```{r}
starwars |>
  drop_na(mass) |>
  reframe(quantile(mass))
```
:::
:::

---

## across()

One trick is to [**make use of selectors**]{.hl-yellow} `across()` and `where()`. The former allows us to [**act on several columns by name**]{.hl-purple} (with `mutate()` or `summarise()`).


```{r}
starwars |> summarise(ave = across(height:mass, mean, na.rm = TRUE), .by = sex)
```

. . .

The second, `where()`, allows us to do the same but [**selecting by type**]{.hl-yellow}.

```{r}
starwars |> 
  summarise(across(where(is.numeric), mean, na.rm = TRUE), .by = c(sex, gender))
```


---

## ğŸ’» It's your turn {#tu-turno-4-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ Calculate how many characters there are of each species, ordered from most to least frequent.

```{r}
#| code-fold: true
#| eval: false
starwars |> count(species, sort = TRUE)
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ After eliminating missing variables for weight and height, add a new variable to calculate the BMI of each character, and determine the average BMI of our characters disaggregated by gender.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(mass, height) |> 
  mutate(BMI = mass / ((height/100)^2)) |> 
  summarise(ave_BMI = mean(BMI), .by = sex)
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Obtain the youngest character for each gender.

```{r}
#| code-fold: true
#| eval: false
starwars |> # reminder that birth_year is in fact the age
  slice_min(birth_year, by = sex)
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Get the age of the youngest and oldest character of each sex.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(birth_year) |>
  summarise(min(birth_year), max(birth_year), .by = sex)
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Determine the number of characters in each decade (take a look at `round()`, first without disaggregating and then disaggregated by sex.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  count(birth_decade = round(birth_year, -1))
```
:::

---

## ğŸ£ Case study I: billboard {#caso-practico-4-1}

We are going to do a **summary of what we learned** in `{tidyverse}` with the billboard table of the `{tidyr}` package. The dataset represents something similar to the top 40 (but American version and a top 100 instead of 40): for each artist and song we store the date when it entered the ranking, and the position it occupied in the ranking in each of the weeks (`wk1`, `wk2`, ...).


```{r}
#| eval: false
billboard
```

```{r}
#| echo: false
billboard[, 1:8]
```


Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).


---

## ğŸ£ Case study II: soccer  {#caso-practico-4-2}

Let's continue **practicing what we learned** in `{tidyverse}` with the file `futbol.csv`, where we have **data of the players of the 5 main men's soccer leagues**, from 2005 to 2019, compiling different statistics. The data has been extracted directly using the `{worldfootballR}` package, which allows us to extract data from <https://www.fbref.com>.

```{r}
data <- read_csv(file = "./data/futbol.csv")
data
```

---

## ğŸ£ Case study II: soccer


The variables capture the following information:

* `season`, `team`, `league`: season, team and league.
* `player`, `country`, `position`, `date_birth`: name, country, position and birth of year of each player. 
* `minutes_playing`, `matches`: total minutes playing and 90' matches played
* `goals`, `assist`: goals and assists.
* `pk`, `pk_attemp`, `goals_minus_pk`: penalties, penalties attempted and goals excluding penalties. 
* `yellow_card`, `red_card`: yellow/red cards.

---

## ğŸ£ Case study II: soccer

```{r}
data
```

&nbsp;


Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).

---

## ğŸ£ Case study III: speechs


Although we cannot do arithmetic operations with them, some [**operations we can do with the text strings**]{.hl-yellow} will be important. For that we will use the `{stringr}` package (within the same `{lubridate}` â€œuniverse of packagesâ€).

```{r}
library(stringr)
```

The dataset will be `discursos` (speeches, extracted from <https://github.com/lirondos/discursos-de-navidad>) where are stored the christmas speeches of the heads of state of Spain from 1946 to 2021 (in dictatorship and in democracy)

```{r}
load(file = "./data/discursos.RData")
# discursos = speeches in spanish
```

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/tidyverse-mucss/).


# L5: [loops]{.flow} {#clase-5}

[**Coming back to R base: loops**]{style="color:#444442;"}


* [ğŸ’» Solved exercises](#tu-turno-5-1) 

* [ğŸ£ Workbook/case study I](#caso-practico-5-1)

* [ğŸ£ Workbook/case study II](#caso-practico-5-2)


---

## Loops

Although in most occasions they can be replaced by other more efficient and readable structures, it is important to know one of the most famous control expressions: the [**loops**]{.hl-yellow}.

* `for { }`: allows [**repeating the same code**]{. hl-yellow} in a [**prefixed and known number**]{.hl-purple} of times.

* `while { }`: allows [**repeating the same code**]{.hl-yellow} but in an [**undetermined number of times**]{.hl-purple} (until a **condition** is no longer fulfilled).


---

## For loop {auto-animate="true"}

A [**for**]{.hl-yellow} loop is a structure that allows to [**repeat**]{.hl-yellow} a set of commands a [**finite, prefixed and known number of times**]{.hl-purple} given a set of indices.

Let's define a vector `x <- c(0, -7, 1, 4)` and another empty variable `y`. After that we will define a for loop with `for () { }`: inside the brackets we will indicate an index and some values to traverse, inside the braces the code to execute in each iteration (in this case, fill `y` as `x + 1`).


```{r}
x <- c(0, -7, 1, 4)
y <- c()
```

---

## For loop {auto-animate="true"}

A [**for**]{.hl-yellow} loop is a structure that allows to [**repeat**]{.hl-yellow} a set of commands a [**finite, prefixed and known number of times**]{.hl-purple} given a set of indices.

Let's define a vector `x <- c(0, -7, 1, 4)` and another empty variable `y`. After that we will define a for loop with `for () { }`: inside the brackets we will indicate an index and some values to traverse, inside the braces the code to execute in each iteration (in this case, fill `y` as `x + 1`).


```{r}
x <- c(0, -7, 1, 4)
y <- c()

for (i in 1:4) {
  
}
```

---

## For loop {auto-animate="true"}

A [**for**]{.hl-yellow} loop is a structure that allows to [**repeat**]{.hl-yellow} a set of commands a [**finite, prefixed and known number of times**]{.hl-purple} given a set of indices.

Let's define a vector `x <- c(0, -7, 1, 4)` and another empty variable `y`. After that we will define a for loop with `for () { }`: inside the brackets we will indicate an index and some values to traverse, inside the braces the code to execute in each iteration (in this case, fill `y` as `x + 1`).


```{r}
x <- c(0, -7, 1, 4)
y <- c()

for (i in 1:4) {
  y[i] <- x[i] + 1
}
```

---

## For loop

Note that because `R` works in a [**default vector**]{.hl-yellow} manner, the loop is the same as doing `x + 1` directly.

```{r}
x <- c(0, -7, 1, 4)
y <- c()

for (i in 1:4) {
  y[i] <- x[i] + 1
}
y

y2 <- x + 1
y2
```

---

## For loop

Another common option is to indicate the indexes â€œautomaticallyâ€: from the first `1` to the last (corresponding to the length of x `length(x)`).

```{r}
x <- c(0, -7, 1, 4)
y <- c()

for (i in 1:length(x)) {
  y[i] <- x[i] + 1
}
y

```


---

## For loop

Thus the [**general structure of a for-loop**]{.hl-yellow} will always be as follows

```{r}
#| eval: false
for (index in set) { 
  cÃ³digo (usually depending on index)
}
```

In the case of for loops [**ALWAYS**]{.hl-green} we know how many iterations we have (as many as there are elements in the set to be indexed).

---

## Avoiding loop

As we have already learned with the `{microbenchmark}` package, we can check how [**loops are usually very inefficient**]{.hl-yellow} (hence we should avoid them in most occasions)

```{r}
library(microbenchmark)
x <- 1:1000
microbenchmark(y <- x^2, 
               for (i in 1:100) { y[i] <- x[i]^2 },
               times = 500)
```

---
 
## For loop


We can see another example of a [**combining numbers and text**]{.hl-yellow} loop: we define a vector of ages and names, and print the i-th name and age.

```{r}
names <- c("Javi", "Sandra", "Carlos", "Marcos", "Marta")
ages <- c(33, 27, 18, 43, 29)

for (i in 1:5) { 
  
  print(glue("{names[i]} are {ages[i]} old")) 
  
}
```


---

## For loop

Although they are usually indexed with numeric vectors, loops can be [**indexed on any vector structure**]{.hl-yellow}, regardless of the type of the set.

```{r}
library(stringr)
week_days <- c("monday", "tuesday", "wednesday", "thursday",
               "friday", "saturday", "sunday")

for (days in week_days) {
  
  print(days)
}
```

---

## For + if-else

Let's **combine conditional structures and loops**: using the `swiss` set of the `{datasets}` package, let's assign `NA` if the fertility values are greater than 80.

```{r}
for (i in 1:nrow(swiss)) {
  
  if (swiss$Fertility[i] > 80) { 
    
    swiss$Fertility[i] <- NA
    
  }
}
```

. . .

This is Â«the sameÂ» as a vectorized `if_else()`.

```{r}
data("swiss")
swiss$Fertility <- if_else(swiss$Fertility > 80, NA, swiss$Fertility)
```


---

## While loop

Another way to create a loop is with the `while { }` structure, which will loop [**an unknown number of times**]{.hl-yellow}, until a condition [**stops being met**]{.hl-yellow} (in fact it may never end). For example, we will inialize a variable `times <- 1`, which we will increment at each step, and we will not exit the loop until `times > 3`.

```{r}
times <- 1
while(times <= 3) {
  
  print(glue("Not yet, we are in the {times}-th iteration")) 
  times <- times + 1
  
}
print(glue("Now! We are in the {times}-th iteration")) 
```

---

## While loop

A `while` loop will always look like this

```{r}
#| eval: false
while(condition) {
  
  code to be executed while condition is TRUE
  # usually some variable is updated here
  
}
```

---
  
## While loop

What happens when the [**condition is never FALSE**]{.hl-yellow}? Try it yourself

```{r}
#| eval: false
while (1 > 0) {
  
  print("Press ESC to exit")
  
}
```

&nbsp;

::: callout-warning
## Warning

A `while { }` loop can be quite â€œdangerousâ€ if we do not control well how to stop it.

:::

---

## While loop

We have two reserved commands to [**abort a loop or force it forward**]{.hl-yellow}:

* `break`: allows [**abort a loop**]{.hl-yellow} even if its end has not been reached

```{r}
for(i in 1:10) {
  if (i == 3) {
    
    break # if i = 3, we abort
    
  }
  print(i)
}
```

---

## While loop

We have two reserved commands to [**abort a loop or force it forward**]{.hl-yellow}:

* `next`: [**forces a loop to advance to the next iteration**]{.hl-yellow} 

```{r}
for(i in 1:5) {
  if (i == 3) {
    
    next # if i = 3, we advance to the next iteration
    
  }
  print(i)
}
```


---


## ğŸ’» It's your turn {#tu-turno-5-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ Modify the code below to print a message on the screen if and only if all the data in `airquality` is for a month other than January.

```{r}
#| eval: false
library(datasets)
months <- airquality$Month

if (months == 2) {
  print("No data in January")
}
```

```{r}
#| code-fold: true
#| eval: false
library(datasets)
months <- airquality$Month

if (all(months != 1)) {
  print("No data in January")
}
```


### [**Exercise 2**]{.hl-yellow}

ğŸ“ Modify the code below to store in a variable called `temp_high` a `TRUE` if any of the records has a temperature above 90 degrees Fahrenheit and `FALSE` in any other case.

 
```{r}
#| eval: false
temp <- airquality$Temp

if (temp == 100) {
  print("Some of the records have temperatures in excess of 90 degrees Fahrenheit")
}
```

 
```{r}
#| eval: false
#| code-fold: true
# Option 1
temp <- airquality$Temp
temp_high <- FALSE
if (any(temp > 90)) {
   temp_high <- TRUE
}

# Option 2
temp_high <- any(airquality$Temp > 90)
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Modify the code below to design a `for` loop of 5 iterations that only loops through the first 5 odd (and at each step of the loop prints them)

```{r}
#| eval: false
for (i in 1:5) {
  
  print(i)
}
```

```{r}
#| eval: false
#| code-fold: true
for (i in c(1, 3, 5, 7, 9)) {
  
  print(i)
}
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Modify the code below to design a `while` loop that starts with a counter `count <- 1` and stops when it reaches 6

```{r}
#| eval: false
count <- 1
while (count == 2) {
  
  print(count)
}
```

```{r}
#| eval: false
#| code-fold: true
count <- 1
while (count < 6) {
  
  print(count)
  count <- count + 1
  
}
```


:::

---

## ğŸ£ Case study I: simulations {#caso-practico-5-1}

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/flow-structures-functions/). On it you will have to design some simulation studies using **conditional loops and structures**.

---

## ğŸ£ Case study II: Monty Hall problem {#caso-practico-5-2}

Imagine you are in a TV contest where you are given a choice of 3 doors: in one there is a millionaire prize and in the other 2 there is an oreo cookie.

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/flow-structures-functions/). On it you will have to design some simulation studies using **conditional loops and structures**.

# L6: [functions and joins]{.flow} {#clase-6}

[**Coming back to R base: functions. Joins**]{style="color:#444442;"}

* [ğŸ’» Solved exercises](#tu-turno-6-1) 

* [ğŸ’» Solved exercises](#tu-turno-6-2) 

* [ğŸ£ Workbook/case study I](#caso-practico-6-1)

* [ğŸ£ Workbook/case study II](#caso-practico-6-2)

* [ğŸ“† Planning](#planificacion-curso)


## Own functions {auto-animate="true"}

Not only can we use **default functions** that come already loaded in packages, we can also [**create our own functions**]{.hl-yellow} to **automate tasks**. How to [**create our own function**]{.hl-purple}? Let's look at its **basic scheme**:

* [**Name**]{.hl-yellow}: for example `name_fun` (no spaces or strange characters). To the name we [**assign the reserved word**]{.hl-yellow} `function()`.

* Define [**input arguments**]{.hl-yellow} (inside `function()`).

* [**Body**]{.hl-yellow} of the function inside `{ }`.

* We end the function with the [**output arguments**]{.hl-yellow} with `return()`.


```{r}
#| eval: false
name_fun <- function() {
  
}
```

---

## Own functions {auto-animate="true"}

Not only can we use **default functions** that come already loaded in packages, we can also [**create our own functions**]{.hl-yellow} to **automate tasks**. How to [**create our own function**]{.hl-purple}? Let's look at its **basic scheme**:

* [**Name**]{.hl-yellow}: for example `name_fun` (no spaces or strange characters). To the name we [**assign the reserved word**]{.hl-yellow} `function()`.

* Define [**input arguments**]{.hl-yellow} (inside `function()`).

* [**Body**]{.hl-yellow} of the function inside `{ }`.

* We end the function with the [**output arguments**]{.hl-yellow} with `return()`.

```{r}
#| eval: false
name_fun <- function(arg1, arg2, ...) {
  
}
```

---

## Own functions {auto-animate="true"}

Not only can we use **default functions** that come already loaded in packages, we can also [**create our own functions**]{.hl-yellow} to **automate tasks**. How to [**create our own function**]{.hl-purple}? Let's look at its **basic scheme**:

* [**Name**]{.hl-yellow}: for example `name_fun` (no spaces or strange characters). To the name we [**assign the reserved word**]{.hl-yellow} `function()`.

* Define [**input arguments**]{.hl-yellow} (inside `function()`).

* [**Body**]{.hl-yellow} of the function inside `{ }`.

* We end the function with the [**output arguments**]{.hl-yellow} with `return()`.

```{r}
#| eval: false
name_fun <- function(arg1, arg2, ...) {
  
  code to be executed
  
}
```

---


## Own functions {auto-animate="true"}

Not only can we use **default functions** that come already loaded in packages, we can also [**create our own functions**]{.hl-yellow} to **automate tasks**. How to [**create our own function**]{.hl-purple}? Let's look at its **basic scheme**:

* [**Name**]{.hl-yellow}: for example `name_fun` (no spaces or strange characters). To the name we [**assign the reserved word**]{.hl-yellow} `function()`.

* Define [**input arguments**]{.hl-yellow} (inside `function()`).

* [**Body**]{.hl-yellow} of the function inside `{ }`.

* We end the function with the [**output arguments**]{.hl-yellow} with `return()`.

```{r}
#| eval: false
name_fun <- function(arg1, arg2, ...) {
  
  code to be executed
  
  return(var_output)
  
}
```


---

## Own functions

* `arg1, arg2, ...`: will be the [**input arguments**]{.hl-yellow}, the arguments that the function takes to execute the code inside.

* `code`: lines of code that we want to [**execute the function**]{.hl-yellow}.

* `return(var_output)`: the [**output arguments**]{.hl-yellow} will be entered.


```{r}
#| eval: false
name_fun <- function(arg1, arg2, ...) {
  
  # Code to be executed
  code
  
  # Output
  return(var_output)
  
}
```

::: callout-important
## Important

All variables that we define inside the function are [**LOCAL variables: they will only exist inside the function**]{.hl-yellow} unless we specify otherwise.

:::

---

## Own functions {auto-animate="true"}

Let's look at a very simple example of a function for [**calculating the area of a rectangle**]{.hl-yellow}.

Since the area of a rectangle is calculated as the **product of its sides**, we will need just that, its sides: those will be the [**input arguments**]{.hl-yellow} and the [**value to return**]{.hl-purple} will be just its **area** ($side_1 * side_2$).

```{r}
# We define the name of function and input arguments
compute_area <- function(side_1, side_2) {
  
}
```

---


## Own functions {auto-animate="true"}

Let's look at a very simple example of a function for [**calculating the area of a rectangle**]{.hl-yellow}.

Since the area of a rectangle is calculated as the **product of its sides**, we will need just that, its sides: those will be the [**input arguments**]{.hl-yellow} and the [**value to return**]{.hl-purple} will be just its **area** ($side_1 * side_2$).

```{r}
# We define the name of function and input arguments
compute_area <- function(side_1, side_2) {
  
  area <- side_1 * side_2
  
}
```

---


## Own functions {auto-animate="true"}

Let's look at a very simple example of a function for [**calculating the area of a rectangle**]{.hl-yellow}.

Since the area of a rectangle is calculated as the **product of its sides**, we will need just that, its sides: those will be the [**input arguments**]{.hl-yellow} and the [**value to return**]{.hl-purple} will be just its **area** ($side_1 * side_2$).

```{r}
# We define the name of function and input arguments
compute_area <- function(side_1, side_2) {
  
  area <- side_1 * side_2
  return(area)
  
}
```

---

## Own functions

We can also make a direct definition of variables **without storing along the way**.

```{r}
# We define the name of function and input arguments
compute_area <- function(side_1, side_2) {
  
  return(side_1 * side_2)
  
}
```

. . .

[**How to apply our function?**]{.hl-yellow}

```{r}
compute_area(5, 3) # area of 5 x 3 rectangle
compute_area(1, 5) # area of 1 x 5 rectangle
```

---

## Own functions

::: callout-tip

Although it is not necessary, it is [**recommendable to make explicit the calling of the arguments**]{.hl-green}, specifying in the code what value is for each argument so that it does not depend on its order, making the code more readable.

:::


```{r}
compute_area(side_1 = 5, side_2 = 3) # area of 5 x 3 rectangle
compute_area(side_2 = 3, side_1 = 5) # area of 5 x 3 rectangle
```

---

## Default arguments

Imagine now that we realize that 90% of the time we use such a function to [**default calculate the area of a square**]{.hl-yellow} (i.e., we only need one side). To do this, we can define [**default arguments**]{.hl-yellow} in the function: they will take that value unless we assign another one.

Why not assign `side_2 = side_1` **default**, to save lines of code and time?

. . .

```{r}
compute_area <- function(side_1, side_2 = side_1) {
  
  # Code to be executed
  area <- side_1 * side_2
  
  # Output
  return(area)
  
}
```

---

## Default arguments


```{r}
compute_area <- function(side_1, side_2 = side_1) {
  
  # Code to be executed
  area <- side_1 * side_2
  
  # Output
  return(area)
  
}
```


Now [**default**]{.hl-yellow} the second side will be equal to the first (if added it will use both).


```{r}
compute_area(side_1 = 5) # square
compute_area(side_1 = 5, side_2 = 7) # rectangle
```

---
 

## Multiple outputs

Let's complicate the function a bit and add in the output the values of each side, labeled `side_1` and `side_2`, [**packing the output in a vector**]{.hl-yellow}.

```{r}
#| code-line-numbers: "7-8"
compute_area <- function(side_1, side_2 = side_1) {
  
  # Code
  area <- side_1 * side_2
  
  # Output
  return(c("area" = area, "side_1" = side_1, "side_2" = side_2))
  
}
```

---

## Multiple outputs

We can complicate the output a little more by adding a fourth variable that tells us, depending on the arguments, [**whether rectangle or square**]{.hl-yellow}, having to add a character (or logic) variable in the output.

```{r}
#| code-line-numbers: "7-9"
compute_area <- function(side_1, side_2 = side_1) {
  
  # Code
  area <- side_1 * side_2
  
  # Output
  return(c("area" = area, "side_1" = side_1, "side_2" = side_2,
           "type" = if_else(side_1 == side_2, "square", "rectangle")))
  
}
compute_area(5, 3)
```

. . .

[**Problem**]{.hl-red}: when trying to put numbers and text together, it converts everything to numbers. We could store it all in a `tibble()` as we have learned or in an object known in `R` as [**lists**]{.hl-yellow} (we will see it later).

---

## Order of arguments

Before we did not care about the order of the arguments, but now the [**order of the input arguments matters**]{.hl-yellow}, since we include `side_1` and `side_2` in the output. 

. . .

::: callout-note
## Tip

As mentioned, it is highly recommended to make the function call [**explicitly setting the arguments**]{.hl-yellow} to improve **legibility and interpretability**.

```{r}
# Equivalent to compute_area(5, 3)
compute_area(side_1 = 5, side_2 = 3)
```

:::

---

## Generating knowledge

It seems silly what we have done but we have crossed an important frontier: we have gone from [**consuming knowledge**]{.hl-yellow} (code from other packages, elaborated by others), to [**generating knowledge**]{.hl-purple}, creating our own functions.

. . .

Functions are going to be key in your day-to-day work because they will allow you to automate code that you are going to repeat over and over again: by packaging that code under an alias (function name) you will [**be able to use it over and over again without programming it (so doing twice as much work will not imply working twice as much)**]{.hl-yellow}

---

## Local vs global variables

An important aspect to think about with functions: what happens if we [**name a variable inside**]{.hl-yellow} a function to which we have **forgotten to assign** a value inside the function.

. . .

We must be cautious when using functions in `R`, since due to the [**"lexicographic rule â€**]{.hl-yellow}, if a variable is not defined inside the function, `R` will [**look for that variable in the environment**]{.hl-purple} of variables.


```{r}
x <- 1
fun_example <- function() {
    
  print(x) # No output, just doing an action
}
fun_example()
```

---

## Local vs global variables

If a variable [**is already defined outside the function (global environment)**]{.hl-yellow}, and is also used inside changing its value, the value [**only changes inside**]{.hl-yellow} but [**not in the global environment**]{.hl-red}.

```{r}
x <- 1
fun_example <- function() {
    
  x <- 2
  print(x) # value inside of function
}
```

```{r}
# value inside of function (local)
fun_example()
# value output of function (global)
print(x)
```

---

## Local vs global variables


If we want it to change locally as well as [**globally**]{.hl-yellow} we must use the [**double assignment**]{.hl-yellow} (`<<-`).

```{r}
x <- 1
y <- 2
fun_example <- function() {
  
  # no change in a global way, just locally
  x <- 3 
  # change in a global way
  y <<- 0 #<<
  
  print(x)
  print(y)
}

fun_example() # value inside function (local)
x # global value
y # global value
```

---


## ğŸ’» It's your turn {#tu-turno-6-1}

[**Try to perform the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Ex 1**]{.hl-yellow}

ğŸ“ Modify the code below to define a function called `sum_function`, so that given two elements, it returns their sum.

```{r}
#| eval: false
name <- function(x, y) {
  sum_output <- # code
  return()
}
# we apply the function
sum_function(3, 7)
```

```{r}
#| code-fold: true
#| eval: false
sum_function<- function(x, y) {
  sum_output <- x + y
  return(sum_output)
}
sum_function(3, 7)
```

### [**Ex 2**]{.hl-yellow}

ğŸ“ Modify the code below to define a function called `product_function`, so that given two elements, it returns their product, but by default it calculates the square

```{r}
#| eval: false
name <- function(x, y) {
  prod_output <- # code
  return()
}
product_function(3)
product_function(3, -7)
```

```{r}
#| code-fold: true
#| eval: false
product_function <- function(x, y = x) {
  
  prod_output <- x * y
  return(prod_output)
  
}
product_function(3)
product_function(3, -7)
```

### [**Ex 3**]{.hl-yellow}

ğŸ“ Define a function called `equal_names` that, given two names, tells us if they are equal or not. Do this by considering case-sensitive, and case-insensitive. Use the `{stringr}` package.

```{r}
#| code-fold: true
#| eval: false
# Case-sensitive
equal_names <- function(person_1, person_2) {
  
  return(person_1 == person_2)
  
}
equal_names("Javi", "javi")
equal_names("Javi", "LucÃ­a")

# Case-insensitive
library(stringr)
equal_names <- function(person_1, person_2) {
  
  return(str_equal(person_1, person_2, ignore_case = TRUE))
  
  # other option
  # return(str_to_lower(person_1) == str_to_lower(person_2))
  
  # other option
  # return(str_to_upper(person_1) == str_to_upper(person_2))
  
}
equal_names("Javi", "javi")
equal_names("Javi", "LucÃ­a")
```

### [**Ex 4**]{.hl-yellow}

ğŸ“ Create a function called `compute_BMI` that, given two arguments (weight and height in meters) and a name, returns a list with the BMI ($weight/(height^2)$) and the name.

```{r}
#| code-fold: true
#| eval: false
compute_BMI <- function(name, weight, height) {
  
  return(list("name" = name, "BMI" = weight/(height^2)))
  
}
```

### [**Ex 5**]{.hl-yellow}

ğŸ“ Repeat the previous exercise but with another optional argument called units (by default, `units = â€œmetersâ€`). Develop the function so that it does the right thing if `units = â€œmetersâ€` and if `units = â€œcentimetersâ€`.

```{r}
#| code-fold: true
#| eval: false
compute_BMI <- function(name, weight, height, units = "meters") {
  
  if (units == "meters") {
    
    return(list("name" = name, "BMI" = weight / (height^2)))
  } else if (units == "centimeters") {
    
    return(list("name" = name, "BMI" = weight / ((height/100)^2)))
  }
}
```

 
### [**Ex 6**]{.hl-yellow}

ğŸ“ Create a fictitious tibble of 7 persons, with three variables (invent name, and simulate weight, height in centimeters), and apply the defined function so that we obtain a fourth column with their BMI.

```{r}
#| code-fold: true
#| eval: false
data <-
  tibble("name" = c("javi", "sandra", "laura",
                       "ana", "carlos", "leo", NA),
         "weight" = rnorm(n = 7, mean = 70, sd = 1),
         "height" = rnorm(n = 7, mean = 168, sd = 5))

data |> 
  mutate(BMI = compute_BMI(name, weight, height, units = "centimeters")$BMI)
```


### [**Ex 7**]{.hl-yellow}

ğŸ“ Create a function called `shortcut` that has two numeric arguments `x` and `y`. If both are equal, you should return `equal` and have the function terminate automatically (think about when a function exits). WARNING: `x` and `y` could be vectors. If they are different (of equal length) calculate the proportion of different elements. If they are different (being of different length), it returns the elements that are not common.

```{r}
#| code-fold: true
#| eval: false
shortcut <- function(x, y) {
  
  if (all(x == y) & length(x) == length(y)) { return("equal") }
  else {
   
    if (length(x) == length(y)) {
      
      n_diff <- sum(x != y) / length(x)
      return(n_diff)
      
    } else {
      
      diff_elem <- unique(c(setdiff(x, y), setdiff(y, x)))
      return(diff_elem)
    }
    
  }
}
```


:::



---

## ğŸ£ Case study I: converter {#caso-practico-6-1}

To practice with functions we are going to create a complete **temperature converter** that, given a temperature in Fahrenheit, Celsius or Kelvin, converts it to any of the others.

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/flow-structures-functions/)



---

## Joins

When working with data we will not always have the information in a single table, and sometimes, we will be interested in [**cross-referencing**]{.hl-yellow} information from different sources.

. . .

For this we will use a classic of every language that handles data: the famous [**join**]{.hl-yellow}, a tool that will allow us to [**cross one or several tables**]{.hl-yellow}, making use of a [**identifying column**]{.hl-yellow} of each one of them.

```{r}
#| eval: false
table_1 |>
  xxx_join(table_2, by = id)
```

---

## Joins

* `inner_join()`: only [**records with id in both**]{.hl-yellow} tables survive.

* `full_join()`: keeps [**all records in both**]{.hl-yellow} tables.

* `left_join()`: keeps [**all the records of the first table**]{.hl-yellow}, and looks for which ones have id also in the second one (in case of [**not having it, it fills with NA**]{.hl-yellow} the fields of the 2nd table).

* `right_join()`: keeps [**all records in the second table**]{.hl-yellow}, and searches which ones have id also in the first one.

![](img/sql-joins.jpg)    



---

## Joins

Let's test the various joins with a simple example

```{r}
tb_1 <- tibble("key" = 1:3, "val_x" = c("x1", "x2", "x3"))
tb_2 <- tibble("key" = c(1, 2, 4), "val_y" = c("y1", "y2", "y3"))
```

:::: columns
::: {.column width="50%"}

```{r}
tb_1
```

:::

::: {.column width="50%"}

```{r}
tb_2
```

:::
::::

---


## left_join()

Imagine that we want to [**incorporate**]{.hl-yellow} to `tb_1` the [**information from table_2**]{.hl-yellow}, identifying the records by the key column (`by = "key"`, the column it has to cross): we want to keep all the records of the first table and look for which ones have the same value in `key` also in the second one.

. . .

:::: columns
::: {.column width="50%"}

```{r}
tb_1 |> 
  left_join(tb_2, by = "key")
```

:::

::: {.column width="50%"}

![](img/left_join.jpg)

:::
::::



---

## left_join()


```{r}
tb_1 |>
  left_join(tb_2, by = "key")
```

Notice that the [**records in the first one whose key was not found in the second one**]{.hl-yellow} has given them the value of [**absent**]{.hl-yellow}.

---

## right_join()

The `right_join()` will perform the opposite operation: we will now [**incorporate**]{.hl-yellow} to `tb_2` the [**information from table_2**]{.hl-yellow}, identifying the records by the `key` column: we want to keep all the records of the second one and look for which ones have id (same value in `key`) also in the first table.

. . .

:::: columns
::: {.column width="50%"}


```{r}
tb_1 |> 
  right_join(tb_2, by = "key")
```

:::

::: {.column width="50%"}


![](img/right_join.jpg)

:::
::::


---

## right_join()


```{r}
tb_1 |>
  right_join(tb_2, by = "key")
```

Notice that now the [**records of the second one whose key was not found in the first one**]{.hl-yellow} are the ones given the value of [**absent**]{.hl-yellow}.

---

## keys and suffixes

The key columns we will use for the crossover [**will not always be named the same**]{.hl-yellow}.

```{r}
tb_1 <- tibble("key_1" = 1:3, "val_x" = c("x1", "x2", "x3"))
tb_2 <- tibble("key_2" = c(1, 2, 4), "val_y" = c("y1", "y2", "y3"))
```

. . .

* `by = c("key_2" = "key_2")`: we will indicate in which column of each table are the keys that we are going to cross.

:::: columns
::: {.column width="50%"}

```{r}
# Left
tb_1  |> 
  left_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

```{r}
# Right
tb_1 |> 
  right_join(tb_2, by = c("key_1" = "key_2"))
```

:::
::::


---

## keys and suffixes

We can also [**cross over several columns at the same time**]{.hl-yellow} (it will interpret as equal record the one that has the same set of keys), with `by = c("var1_t1" = "var1_t2", "var2_t1" = "var2_t2", ...)`. Let's modify the previous example

```{r}
tb_1 <- tibble("k_11" = 1:3, "k_12" = c("a", "b", "c"),  "val_x" = c("x1", "x2", "x3"))
tb_2 <- tibble("k_21" = c(1, 2, 4), "k_22" = c("a", "b", "e"), "val_y" = c("y1", "y2", "y3"))
```

. . .

:::: columns
::: {.column width="50%"}

```{r}
# Left
tb_1 |> 
  left_join(tb_2,
            by = c("k_11" = "k_21", "k_12" = "k_22"))
```

:::

::: {.column width="50%"}

```{r}
# Right
tb_1 |> 
  right_join(tb_2,
             by = c("k_11" = "k_21", "k_12" = "k_22"))
```

:::
::::

---

## keys and suffixes

It could also happen that when crossing two tables, there are [**columns of values named the same**]{.hl-yellow}

```{r}
tb_1 <- tibble("key_1" = 1:3, "val" = c("x1", "x2", "x3"))
tb_2 <- tibble("key_2" = c(1, 2, 4), "val" = c("y1", "y2", "y3"))
```

. . .

```{r}
# Left
tb_1 |>
  left_join(tb_2, by = c("key_1" = "key_2"))
```

Notice that [**default adds the suffixes**]{.hl-yellow} `.x` and `.y` to tell us which table they come from.

---

## keys and suffixes


This [**suffix can be specified**]{.hl-yellow} in the optional argument `suffix = ...`, which allows us to [**distinguish the variables**]{.hl-yellow} of one table from another.

```{r}
# Left
tb_1 |>
  left_join(tb_2, by = c("key_1" = "key_2"),
            suffix = c("_table1", "_table2"))
```

---

## full_join()

The two previous cases form what is known as [**outer joins**]{.hl-yellow}: crosses where observations are kept that appear in at least one table. The third outer join is known as `full_join()` which will [**keep observations from both**]{.hl-yellow} tables, [**adding rows**]{.hl-yellow} that do not match the other table.

:::: columns
::: {.column width="50%"}

```{r}
tb_1  |> 
  full_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

![](img/full_join.jpg)

:::
::::

---

## inner_join()

Opposite the outer join is what is known as [**inner join**]{.hl-yellow}, with `inner_join()`: a join in which only the [**observations that appear in both tables**]{.hl-yellow} are kept, only those records that are patched are kept.

:::: columns
::: {.column width="50%"}


```{r}
tb_1 |> 
  inner_join(tb_2,  by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

![](img/inner_join.png)

:::
::::



---

## inner_join()

Note that in terms of records, `inner_join` if it is commutative, **we don't care about the order of the tables**: the only thing that changes is the order of the columns it adds.

:::: columns
::: {.column width="50%"}


```{r}
tb_1 |> 
  inner_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

```{r}
tb_2 |> inner_join(tb_1, by = c("key_2" = "key_1"))
```

:::
::::

---

## semi/anti_join()

Finally we have two interesting tools to [**filter (not cross) records**]{.hl-yellow}: `semi_join()` and `anti_join()`. The [**semi join**]{.hl-yellow} leaves us in the [**first table the records whose key is also in the second table**]{.hl-yellow} (like an inner join but without adding the info from the second table). And the second one, the anti join, does just the opposite (those that are not).


:::: columns

::: {.column width="50%"}

```{r}
# semijoin
tb_1 |> 
  semi_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

```{r}
# antijoin
tb_1 |> 
  anti_join(tb_2, by = c("key_1" = "key_2"))
```

:::
::::

---

## ğŸ’» It's your turn {#tu-turno-6-2}

For the exercises we will use the tables available in the package `{nycflights13}`.

```{r}
library(nycflights13)
```

* **airlines**: name of airlines (with their abbreviation).
* **airports**: airport data (names, longitude, latitude, altitude, etc).
* **flights**, **planes**: flight and aircraft data.
* **weather**: hourly weather data.

---

## ğŸ’» It's your turn


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ From package `{nycflights13}` incorporates into the `flights` table the airline data in `airlines`. We want to maintain all flight records, adding the airline information to the airlines table.


```{r}
#| code-fold: true
#| eval: false
flights_airlines <-
  flights |> 
  left_join(airlines, by = "carrier")
flights_airlines
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ To the table obtained from the crossing of the previous section, include the data of the aircraft in `planes`, but including only those flights for which we have information on their aircraft (and vice versa). 

```{r}
#| code-fold: true
#| eval: false

flights_airlines_planes <- 
  flights_airlines |> 
  inner_join(planes, by = "tailnum")
flights_airlines_planes
```


### [**Exercise 3**]{.hl-yellow}

ğŸ“ Repeat the previous exercise but keeping both `year` variables (in one is the year of flight, in the other is the year of construction of the aircraft), and distinguishing them from each other


```{r}
#| code-fold: true
#| eval: false

flights_airlines_planes <- 
  flights_airlines |>
  inner_join(planes, by = "tailnum",
             suffix = c("_flight", "_build_aircraft"))
flights_airlines_planes
```


### [**Exercise 4**]{.hl-yellow}

ğŸ“ To the table obtained from the previous exercise includes the longitude and latitude of the airports in `airports`, distinguishing between the latitude/longitude of the airport at destination and at origin.


```{r}
#| code-fold: true
#| eval: false

flights_airlines_planes |> 
  left_join(airports |> select(faa, lat, lon),
            by = c("origin" = "faa")) |> 
  rename(lat_origin = lat, lon_origin = lon) |> 
  left_join(airports |> select(faa, lat, lon),
            by = c("dest" = "faa")) |> 
  rename(lat_dest = lat, lon_dest = lon)
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Filter from `airports` only those airports from which flights depart. Repeat the process filtering only those airports where flights arrive.


```{r}
#| code-fold: true
#| eval: false

airports |> 
  semi_join(flights, by = c("faa" = "origin"))
airports |> 
  semi_join(flights, by = c("faa" = "dest"))
```

### [**Exercise 6**]{.hl-yellow}

ğŸ“ How many flights do we not have information about the aircraft? Eliminate flights that do not have an aircraft ID (other than NA) beforehand.


```{r}
#| code-fold: true
#| eval: false

flights |>
  drop_na(tailnum) |>
  anti_join(planes, by = "tailnum") |>
  count(tailnum, sort = TRUE) 
```

:::

---

## ğŸ£ Case study II: Beatles {#caso-practico-6-2}

We will use to practice simple joins the `band_members` and `band_instruments` datasets already included in the `{dplyr}` package.

```{r}
library(dplyr)
band_members
band_instruments
```

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/joins-import-mucss/#case-study-i-beatles-and-rolling-stones)

---

## ğŸ£ Case study III: income by municipalities {#caso-practico-6-3}

In the file `municipios.csv` we have stored the information of the municipalities of Spain as of 2019.

* The variable `LAU_code` represents the code as local administrative unit in the EU (see more at <https://ec.europa.eu/eurostat/web/nuts/local-administrative-units>).

* The variable `codigo_ine` is formed by joining the province code and the community code (each province has a code from 1 to 52, it does not depend on the ccaa).

```{r}
# 2019 data
mun_data <- read_csv(file = "./data/municipios.csv")
mun_data
```

---

## ğŸ£ Case study III: income by municipalities

On the other hand, in the file `renta_mun` we have the average per capita income of each administrative unit (municipalities, districts, provinces, autonomous communities,...) for different years.

```{r}
renta_mun <- read_csv(file = "./data/renta_mun.csv")
renta_mun
```

---

## ğŸ£ Case study III: income by municipalities

Before we start let's [**normalize variable names**]{.hl-yellow} using `clean_names()` from the `{janitor}` package.

```{r}
mun_data <-
  mun_data |> 
  janitor::clean_names()
renta_mun <-
  renta_mun |> 
  janitor::clean_names()
```

&nbsp;

Try to answer the questions posed in the [**workbook**](https://javieralvarezliebana.quarto.pub/joins-import-mucss/#case-study-ii-income-by-municipalities)

# L7: [import/exports]{.flow} {#clase-7}

[**Import and export data**]{style="color:#444442;"}

* [ğŸ’» Solved exercises](#tu-turno-7-1) 

* [ğŸ£ Workbook/case study I](#caso-practico-7-1)

* [ğŸ“† Planning](#planificacion-curso)

---


## Import/export

So far we have only used data already loaded in packages but many times [**we will need to import data externally**]{.hl-yellow}. One of the main [**strengths**]{.hl-yellow} of `R` is that we can import data very easily in different formats:


* [**R native formats**]{.hl-yellow}: `.rda`, `.RData` and `.rds` formats.

* [**Rectangular (tabular) data**]{.hl-yellow}: `.csv` and `.tsv` formats

* [**Untabulated data**]{.hl-yellow}: `.txt` format.

* [**Data in excel**]{.hl-yellow}: `.xls` and `.xlsx` formats

* [**Data from SAS/Stata/SPSS**]{.hl-yellow}: `.sas7bdat`, `.sav` and `.dat` formats

* [**Data from Google Drive**]{.hl-yellow}

* [**Data from API's**]{.hl-yellow}: aemet, catastro, twitter, spotify, etc.

---

## R native formats

The [**simplest**]{.hl-yellow} files to import into `R` (and which usually take up less disk space) are its own [**native extensions**]{.hl-yellow}: files in `.RData`, `.rda` and `.rds` formats. To load the former we simply need to [**use the native**]{.hl-yellow} function `load()` by providing it the file path.

* `RData` file: we are going to import the file `world_bank_pop.RData`, which includes the dataset `world_bank_pop`


```{r}
load("./data/world_bank_pop.RData")
world_bank_pop
```


---

## R native formats

* `.rda` file: we will import the airquality dataset from `airquality.rda`

```{r}
load("./data/airquality.rda")
airquality |> as_tibble()
```

---

## R native formats

Note that files loaded with `load()` are [**automatically loaded into the environment**]{.hl-yellow} (with the originally saved name), and not only datasets can be loaded: `load()` allows us to load multiple objetcs (not only a tabular data)

Native `.rda` and `.RData` files are a properly way to save your environment.

```{r}
load(file = "./data/multiple_objects.rda")
```


---

## R native formats

* `.rds` files: for this type we must use `readRDS()`, and we need to incorporate a [**argument `file`**]{.hl-yellow} with the path. In this case we are going to import [**lung cancer data**]{.hl-purple} from the North Central Cancer Treatment Group. Note that now [**.rds import files are a unique database**]{.hl-yellow}

```{r}
lung_cancer <-
  readRDS(file = "./data/NCCTG_lung_cancer.rds") |>
  as_tibble()
lung_cancer
```


::: callout-important

## Important

The [**paths**]{.hl-yellow} must always be [**without spaces, Ã±, or accents**]{.hl-yellow}. 

:::

---

## Tabular data: readr

The `{readr}` package within the `{tidyverse}` environment contains several useful functions for [**loading rectangular data (without formatting)**]{.hl-yellow}.

:::: columns
::: {.column width="50%"}

* `read_csv()`: `.csv` files whose [**separator is comma**]{.hl-purple}
* `read_csv2()`: [**semicolon**]{.hl-purple}
* `read_tsv()`: [**tabulator**]{.hl-purple}.
* `read_table()`: [**space**]{.hl-purple}.
* `read_delim()`: generic function for [**character delimited files**]{.hl-purple}.


:::

::: {.column width="50%"}

![](img/data-import-readr.png)
:::
::::

All of them need as **argument the file path** plus **other optional** (skip header or not, decimals, etc). See more at <https://readr.tidyverse.org/>

---

## Tabular data (.csv, .tsv)

The main advantage of `{readr}` is that it [**automates formatting**]{.hl-yellow} to go from a flat (unformatted) file to a tibble (in rows and columns, with formatting).

. . .

* File `.csv`: with `read_csv()` we will load [**comma separated**]{.hl-purple} files, passing as [**argument the path**]{.hl-yellow} in `file = ...`. Let's import the `chickens.csv` dataset (about cartoon chickens, why not). If you look at the output it gives us the type of variables.

```{r}
library(readr)
chickens <- read_csv(file = "./data/chickens.csv")
chickens
```

---

## Tabular data (.csv, .tsv)


The [**variable format**]{.hl-yellow} will normally be done [**automatically**]{.hl-yellow} by `read_csv()`, and we can query it with `spec()`.

```{r}
spec(chickens)
```

---

## Tabular data (.csv, .tsv)

Although it usually does it well automatically we can [**specify the format explicitly**]{.hl-yellow} in `col_types = list()` (in list format, with `col_xxx()` for each type of variable, for example `eggs_laid` will be imported as character). 


```{r}
chickens <-
  read_csv(file = "./data/chickens.csv",
           col_types = list(col_character(), col_character(),
                            col_character(), col_character()))
chickens
```

---

## Tabular data (.csv, .tsv)

We can even indicate that [**variables we want to select**]{.hl-yellow} (without occupying memory), by indicating it in `col_select = ...` (in list format, with `col_select = ...`).


```{r}
chickens <-
  read_csv(file = "./data/chickens.csv",
           col_select = c(chicken, sex, eggs_laid))
chickens
```

---

## Untabulated data (.txt)

What happens when the [**separator is not correct**]{.hl-red}?

. . .

If we use `read_csv()` it expects the separator between columns to be a comma but, as you can see with the following `.txt`, it interprets everything as a single column: [**has no comma and does not know where to separate**]{.hl-yellow}

```{r}
datos_txt <- read_csv(file = "./data/massey-rating.txt")
dim(datos_txt)
as_tibble(datos_txt)
```


---

## Untabulated data (.txt)

To do this we have.

* `read_csv2()` when the [**separator is semicolon**]{.hl-yellow}, `read_tsv()` when the [**is a tab**]{.hl-yellow} and `read_table()` when the [**is a space**]{.hl-yellow}.

* `read_delim()` in general.

```{r}
datos_txt <- read_table(file = "./data/massey-rating.txt")
as_tibble(datos_txt)
```


---

## Excel data (.xls, .xlsx)

Another key import package will be the `{readxl}` package for [**importing data from Excel**]{.hl-yellow}. Three functions will be key:

* `read_xls()` specific to `.xls`, `read_xlsx()` specific to `.xlsx`.
* `read_excel()`: for both `.xls` and `.xlsx`.

. . .

We are going to import `deaths.xlsx` with celebrity death records.

```{r}
library(readxl)
deaths <- read_xlsx(path = "./data/deaths.xlsx")
deaths
```

---

## Excel data (.xls, .xlsx)


```{r}
deaths |> slice(1:6)
```

One thing that is [**very common misfortune**]{.hl-yellow} is that there is some kind of comment or text at the beginning of the file, having to [**skip those rows**]{.hl-yellow}.

---

## Excel data (.xls, .xlsx)

We can [**skip these rows**]{.hl-yellow} directly in the load with `skip = ...` (indicating the number of rows to skip).

```{r}
deaths <- read_xlsx(path = "./data/deaths.xlsx", skip = 4)
deaths
```


---

## Excel data (.xls, .xlsx)

In addition with `col_names = ...` we can already rename the columns in the import (if [**provide names assumes 1st line already as a data**]{.hl-yellow})

```{r}
#| code-line-numbers: "2-3"
deaths <-
  read_xlsx(path = "./data/deaths.xlsx", skip = 5,
            col_names = c("name", "profession", "age", "kids", "birth", "death"))
deaths
```

---

## Excel data (.xls, .xlsx)

Sometimes [**Excel dates are incorrectly formatted**]{.hl-red} (surprise): we can use `convertToDate()` from the `{openxlsx}` package to convert it.


```{r}
library(openxlsx)
deaths$death <- convertToDate(deaths$death)
deaths
```
   

---

## Excel data (.xls, .xlsx)

We can also [**load an Excel with several sheets**]{.hl-yellow}: to [**indicate the sheet**]{.hl-yellow} (either by its name or by its number) we will use the argument `sheet = ...`.

```{r}
mtcars <- read_xlsx(path = "./data/datasets.xlsx", sheet = "mtcars")
mtcars
```

---

## Excel data (.xls, .xlsx)

 
We can even indicate the [**range of cells**]{.hl-yellow} to load with `range = ...`.

```{r}
iris <- read_xlsx(path = "./data/datasets.xlsx", sheet = "iris", range = "C1:E4")
iris
```

---

## Import from SAS/STATA/SPSS

The `{haven}` package within the tidyverse orbit will allow us to [**import files from the 3 most important payment software**]{.hl-yellow}: SAS, SPSS and Stata.

```{r}
library(haven)

# SAS
iris_sas <- read_sas(data_file = "./data/iris.sas7bdat")

# SPSS
iris_spss <- read_sav(file = "./data/iris.sav")

# Stata
iris_stata <- read_dta(file = "./data/iris.dta")
```


---


## Export

In the same way that we can import we can also [**export**]{.hl-yellow}

* exported in `.RData` (recommended option for variables stored in `R`). Remember that this extension [**can only be used in `R`**]{.hl-yellow}. To do so, just use `save(object, file = path)`.

```{r}
table <- tibble("a" = 1:4, "b" = 1:4)
save(table, file = "./data/table.RData")
rm(table) # eliminar
load("./data/table.RData")
table
```

---

## Export

In the same way that we can import we can also [**export**]{.hl-yellow}

* exported in `.RData` multiple objects

```{r}
table <- tibble("a" = 1:4, "b" = 1:4)
a <- 1
b <- c("javi", "sandra")
save(table, a, b, file = "./data/mult_obj.RData")
rm(list = c("a", "b", "table"))
load("./data/mult_obj.RData")
table
```

---

## Export

In the same way that we can import we can also [**export**]{.hl-yellow}

* exported in `.csv`. To do this we simply use `write_csv(object, file = path)`.

```{r}
write_csv(table, file = "./data/table.csv")
read_csv(file = "./data/table.csv")
```

---

## Import from website

One of the main advantages of `R` is that we can make use of all the previous functions of [**import but directly from a web**]{.hl-yellow}, without the need to perform the manual download: instead of passing it the local path we will indicate the [**link**]{.hl-yellow}. For example, we are going to download the covid data from ISCIII (<https://cnecovid.isciii.es/covid19/#documentaci%C3%B3n-y-datos>)

```{r}
#| eval: false
covid_data <-
  read_csv(file = "https://cnecovid.isciii.es/covid19/resources/casos_hosp_uci_def_sexo_edad_provres.csv")
covid_data
```

```{r}
#| echo: false
covid_data <-
  read_csv(file = "https://cnecovid.isciii.es/covid19/resources/casos_hosp_uci_def_sexo_edad_provres.csv", n_max = 500)
covid_data
```

---

## Import from wikipedia

The `{rvest}` package, one of the most useful of `{tidyverse}` allows us to import directly from an `html`. For example, to export wikipedia tables just `read_html()` to import the html, `html_element("table")` to extract the table objects, and `html_table()` to convert the html table to `tibble`.

```{r}
library(rvest)
wiki_jump <- 'https://en.wikipedia.org/wiki/Men%27s_long_jump_world_record_progression'
wiki_jump |> read_html() |> 
  html_element("table") |> 
  html_table()
```

---


## Import from google drive

Another option available (especially if we work with other people working) is to [**import from a Google Drive spreadsheet**]{.hl-yellow}, making use of `read_sheet()` from the `{googlesheets4}` package.

The first time you will be asked for a tidyverse permission to interact with your drive

```{r}
library(googlesheets4)
google_sheet <-
  read_sheet("https://docs.google.com/spreadsheets/d/1Uz38nHjl3bmftxDpcXj--DYyPo1I39NHVf-xjeg1_wI/edit?usp=sharing")
google_sheet
```

---

## Import from API (owid)

Another interesting option is the [**data download from an API**]{.hl-yellow}: an intermediary between an app or data provider and our `R`. For example, let's load the `{owidR}` library, which allows us to download data from the web <https://ourworldindata.org/>. For example, the `owid_covid()` function loads without realizing it more than 400 000 records with more than 60 variables from 238 countries.

```{r}
#| eval: false
library(owidR)
owid_covid() |> as_tibble()
```

```{r}
#| echo: false
library(owidR)
owid_covid() |> as_tibble() |> slice(1:7)
```

---

## Import from API (aemet)

In many occasions to connect to the API we will first have to [**register and obtain a key**]{.hl-yellow}, this is the case of the `{climaemet}` package to access [**Spanish meteorological data**]{.hl-yellow} (<https://opendata.aemet.es/centrodedescargas/inicio>).


Once we have the API key we register it in our RStudio to be able to use it in the future.

```{r}
#| eval: false
library(climaemet)

# Api key
apikey <- "eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqYXZhbHYwOUB1Y20uZXMiLCJqdGkiOiI4YTU1ODUxMS01MTE3LTQ4MTYtYmM4OS1hYmVkNDhiODBkYzkiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTY2NjQ2OTcxNSwidXNlcklkIjoiOGE1NTg1MTEtNTExNy00ODE2LWJjODktYWJlZDQ4YjgwZGM5Iiwicm9sZSI6IiJ9.HEMR77lZy2ASjmOxJa8ppx2J8Za1IViurMX3p1reVBU"

aemet_api_key(apikey, install = TRUE)
```


```{r}
#| echo: false
library(climaemet)
```

--- 

## Import from API (aemet)


With this package we can do a [**search for stations**]{.hl-yellow} to know both its postal code and its identifier code within the AEMET network

```{r}
stations <- aemet_stations()
stations
```

---

## Import from API (aemet)

For example, to get data from the station of the airport of El Prat, Barcelona, the code to provide is `"0076"`, obtaining **hourly data**

```{r}
aemet_last_obs("0076")
```


---


## Importar from API (US census)

One of the most useful tools in recent years is known as `{tidycensus}`: a tool for [**facilitating the process of downloading census data**]{.hl-yellow} for the United States from `R`.

```{r}
library(tidycensus)
```

* `get_decennial()`: to access the [**census data (US Decennial Census)**]{.hl-yellow}, done every 10 years (years 2000, 2010 and 2020).

* `get_acs()`: to access the [**annual and quinquennial (5 years) ACS (American Community Survey)**]{.hl-yellow} (census != survey)

* `get_estimates()`: to access the [**annual population, birth and death estimates**]{.hl-yellow} (census != survey)

* `get_pums()`: to access the [**microdata (unaggregated data) of the ACS (anonymized at the individual level)**]{.hl-yellow}

* `get_flows()`: to access the [**migration flow**]{.hl-yellow} data.


---

## Importar from API (US census)

For example, we will download the **census data** (`get_decennial()`) at the state level (`geography = â€œstateâ€`) for the population (variable `variables = â€œP001001â€`) for the year 2010 (see variables in `tidycensus::load_variables()`).

```{r}
total_population_10 <-
  get_decennial(geography = "state", 
  variables = "P001001",
  year = 2010)
total_population_10
```



---

## Import from API 

Other options:

* `{chessR}`: data from chess matches. See <https://github.com/JaseZiv/chessR>

* `{spotifyr}`: data from Spotify. See <https://www.rcharlie.com/spotifyr/>

* `{gtrendsR}`: data from Google Trends. See <https://github.com/PMassicotte/gtrendsR>

* `{scholar}`: data from <https://github.com/jkeirstead/scholar>

---

## ğŸ’» Your turn {#tu-turno-7-1}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

ğŸ“ The `who` dataset we have used in previous exercises, export it to a native `R` format in the `data` folder of the project

```{r}
#| code-fold: true
#| eval: false
library(tidyr)
save(who, file = "./data/who.RData")
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Loads the `who` dataset but from the data folder (import the file created in the previous exercise)

```{r}
#| code-fold: true
#| eval: false
load("./data/who.RData")
```

### [**Exercise 3**]{.hl-yellow}

ğŸ“ Repeats the same (export and import) in 4 formats: `.csv`, `.xlsx`, `.sav` (spss) and `.dta` (stata)

```{r}
#| code-fold: true
#| eval: false

# csv
library(readr)
write_csv(who, file = "./data/who.csv")
who_data <- read_csv(file = "./data/who.csv")

# excel
library(openxlsx)
write.xlsx(who, file = "./data/who.xlsx")
who_data <- read_xlsx(path = "./data/who.xlsx")

# sas y stata
library(haven)
write_sav(who, path = "./data/who.sav")
who_data <- read_spss(path = "./data/who.sav")

write_dta(who, path = "./data/who.dta")
who_data <- read_dta(path = "./data/who.dta")
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Repeat the loading of `who.csv` but only select the first 4 columns already in the load.

```{r}
#| code-fold: true
#| eval: false
who_select <-
  read_csv(file = "./data/who.csv",
           col_select = c("country", "iso2", "iso3", "year"))
```


:::

---

## ğŸ£ Case study I: SPSS {#caso-practico-7-1}

---

## ğŸ£ Case study II: Brexit {#caso-practico-7-2}


# L8: [factors and lists]{.flow} {#clase-8}

[**Handling with factors and lists**]{style="color:#444442;"}

* [ğŸ’» Solved exercises: lists](#tu-turno-8-1) 

* [ğŸ’» Solved exercises: factors](#tu-turno-8-2) 

* [ğŸ£ Workbook/case study I](#caso-practico-8-1)

* [ğŸ£ Workbook/case study II](#caso-practico-8-2)

* [ğŸ“† Planning](#planificacion-curso)

---

## Lists

We have already seen that lists are an object in R that allows us to store [**collections of variables of different type**]{.hl-yellow} (as with `data.frame` and `tibble`) but also [**different lengths**]{.hl-purple}, with totally heterogeneous structures (even a list can have inside it another list).

```{r}
name <- "Javi"
age <- 34
marks <- c(7, 8, 5, 3, 10, 9)
parents <- c("Paloma", "Goyo")

list_var <- list("name" = name, "age" = age, "marks" = marks, "parents" = parents)
```


```{r}
list_var$name
list_var$marks
```



---

## Lists


We can also make [**lists with other lists inside**]{.hl-yellow}, so that to access each level we must use the `[[]]` operator.

```{r}
list_of_lists <- list("list_1" = list_var[1:2], "list_2" = list_var[3:4])
names(list_of_lists)
```

```{r}
names(list_of_lists[[1]])
```

```{r}
list_of_lists[[1]][[1]]
```

. . .

We are allowed to store [**n-dimensional data**]{.hl-yellow}!

---

## Lists

One of the disadvantages is that a list [**cannot be vectorized**]{.hl-yellow} immediately, so any arithmetic operation applied to a list will give [**error**]{.hl-red}.

```{r}
#| error: true
data <- list("a" = 1:5, "b" = 10:20)
data / 2
```

. . .

For this purpose, one of the common (but outdated) options is to make use of the `lapply()` family.

```{r}
lapply(data, FUN = function(x) { x / 2})
```

By default, the output of `lapply()`is always a [**list of equal length**]{.hl-yellow}.

---

## Lists


A more flexible and versatile option is to make use of the `{purrr}` package of the `{tidyverse}` environment.

```{r}
library(purrr)
```

This package is intended to mimic the [**functional programming**]{.hl-yellow} of other languages such as Scala or Hadoop's [**map-reduce strategy**]{.hl-yellow} (from Google).

![](img/purrr.png)

---

## Lists

The simplest function of the `{purrr}` package is the `map()` function, which [**applies a vectorized function**]{.hl-yellow} to each of the elements of a list. Let's see a first example applied to vectors

. . .

`map()` allows us to [**"map" each list**]{.hl-yellow} and apply the function element by element (if applicable).

```{r}
x <- list("x1" = 1:4, "x2" = 11:20)
map(x, sqrt) 
```

. . .


::: callout-warning
## Be careful

With vectors we have a default vectorization because `R` performs element-by-element operations. Note that, by default, the [**output of `map` is a list**]{.hl-yellow}.
:::


---

## Lists

Let's look at another example. Define in a list two samples from 2 normal distributions, of different sample size and different mean. Compute the mean of each one.

```{r}
#| code-fold: true
x <- list(rnorm(n = 1500, mean = 0, sd = 0.7),
          rnorm(n = 2800, mean = 2, sd = 1.5))
map(x, mean)
```

---

## Lists

What if we want to calculate the mean of their squared values?

```{r}
#| code-fold: true
map(x, function(x) { mean(x^2) })
```


---

## Lists

In addition to being [**more readable and efficient**]{.hl-yellow}, with `{purrr}` we can [**decide the output format**]{.hl-yellow} after the operation

* output as [**numeric (double) vector**]{.hl-purple} with `map_dbl()`
* output as [**numeric (int) vector**]{.hl-purple} with `map_int()`
* output as [**character vector**]{.hl-purple} with `map_chr()`
* output as [**logical vector**]{.hl-purple} with `map_lgl()`

```{r}
map_dbl(x, mean)
map_chr(x, function(x) { glue("Mean is {round(mean(x), 5)}") })
```

---

## Lists

```{r}
c(x[[1]][3], x[[2]][3])
```


Also, if you pass it a [**number**]{.hl-yellow} instead of a function, it will return the [**ith element of each list**]{.hl-yellow}.

```{r}
map_dbl(x, 3)
```


---


## Lists

We also have the option of generalizing it to be able to use functions that [**need two arguments in the form of a list**]{.hl-yellow} (binary operations), with `map2()`


```{r}
x <- list("a" = 1:3, "b" = 4:6)
y <- list("c" = c(-1, 4, 0), "b" = c(5, -4, -1))
map2(x, y, function(x, y) { x^2 + y^2})
```

---

## Lists

We can obtain the output in the form of `data.frame` by adding `list_rbind()` or `list_cbind()`, which [**converts a list into a table**]{.hl-yellow}.


```{r}
x <- c("a", "b", "c")
y <- 1:3
map2(x, y, function(x, y) { tibble(x, y) }) |> list_rbind()
```

---

## Lists

We can generalize it further with `pmap_xxx()` which allows us to use [**multiple arguments (multiple lists)**]{.hl-yellow}.


```{r}
x <- list(1, 1, 1)
y <- list(10, 20, 30)
z <- list(100, 200, 300)
pmap_dbl(list(x, y, z), sum)
```

---

## Lists

We have other types of iterators that, although they assume inputs, do not return anything, as `walk()` (just one input argument), `walk2()` (two arguments) and `pwalk()` (multiple arguments), all [**invisibly return**]{.hl-yellow}, just call a function for its [**side effects**]{.hl-yellow} rather than its return value.

```{r}
list("a" = 1:3, "b" = 4:6) |>
  map2(list("a" = 11:13, "b" = 14:16),
       function(x, y) { x + y }) |> 
  walk(print)
```

---

## ğŸ’» It's your turn {#tu-turno-8-1}


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ Define a list of 4 elements of different types and access the second of them (I will include one that is a tibble so that you can see that in a list there is room for everything).

```{r}
#| code-fold: true
#| eval: false
list_example <-
  list("name" = "Javier", "cp" = 28019,
       "siblings" = TRUE,
       "marks" = tibble("maths" = c(7.5, 8, 9),
                        "lang" = c(10, 5, 6)))
list_example
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ From the list above, access the elements that occupy places 1 and 4 of the list defined above.

```{r}
#| code-fold: true
#| eval: false

list_example[c(1, 4)]

list_example$name
list_example$marks

list_example[c("name", "marks")]
```



### [**Exercise 3**]{.hl-yellow}

ğŸ“  Load the `starwars` dataset from the `{dplyr}` package and access the second movie that appears in `starwars$films` (for each character). Determine which ones do not appear in more than one movie.

```{r}
second_film <- map(starwars$films, 2)
map_lgl(second_film, is.null)
```

:::

---

## ğŸ£ Case study I: ... {#caso-practico-8-1}

---


## Quali: factors

In statistics, when we talk about [**qualitative variables**]{.hl-yellow}, we will call **levels or modalities** the **different values** that these data can take. For example, in the case of the `sex` variable of the `starwars` set, we have 4 allowed levels: `female`, `hermaphroditic`, `male` and `none` (in addition to missing data).

```{r}
starwars |> count(sex)
```



---

## Quali: factors

These kinds of variables are known in `R` as [**factors**]{.hl-yellow}, and the fundamental package to deal with them is `{forcats}` (from the `{tidyverse}` environment). 


![](img/factors.jpg)


---

## Quali: factors

This package allows us to set the [**levels**]{.hl-yellow} (stored internally as `levels`) that a given categorical variable takes so that no mistakes, errors in data collection and generation can be generated. It also makes their analysis less computationally expensive when doing searches and comparisons, giving them a [**different treatment than normal text strings**]{.hl-yellow}.

. . .

Let's see a simple example simulating a `party` variable taking the values `"PP"`, `"PSOE"` and `"SUMAR"` (of size 15)

```{r}
set.seed(1234567)
party <- sample(x = c("PP", "PSOE", "SUMAR"), size = 15, replace = TRUE)
party
```

The `party` variable is currently of [**type text**]{.hl-yellow}, of type `chr`, something we can check with `class(state)`.

```{r}
class(party)
```

---

## Quali: factors

From a statistical and computational point of view, for `R` this variable right now would be equivalent to a named variable. But statistically [**a variable as a string**]{.hl-yellow} is not the same as a categorical variable that [**can only take those 3 levels**]{.hl-yellow}. How to [**convert to factor**]{.hl-yellow}? 

. . .

By making use of the `as_factor()` function from the `{forcats}` package.

```{r}
library(tidyverse)
party_fct <- tibble("id" = 1:length(party),
                    "party" = as_factor(party))
party_fct
```

---

## Quali: factors

Not only the class of the variable  has  changed, but now, below the saved value, the sentence `Levels: ...` appears: these are the [**modalities or levels**]{.hl-yellow} of our qualitative. 

```{r}
party_fct |> pull(party)
```

---


## Quali: factors

Imagine that we are defining the database of deputies of the Congress and that the deputies of the PP did not attend that day to the plenary session: although our variable does not take that value THAT DAY, the state `PSOE` is a [**allowed level in the database**]{.hl-yellow} (so even if we eliminate it, because it is a factor, the level remains, we do not have it now but it is an allowed level).


```{r}
party_fct |> 
  filter(party %in% c("PP", "SUMAR")) |> 
  pull(party)
```

---

## Quali: factors

With `factor()` function we can [**explicitly specify**]{.hl-yellow} the names of the modalities and using `levels = ...` we can explicitly tell it the [**"order" of the modalities**]{.hl-yellow} 


```{r}
party_fct <-
  tibble(id = 1:length(party),
         party = factor(party, levels = c("SUMAR", "PP", "PSOE")))
party_fct |> pull(party)
```


---


## Quali: factors

The previous "order" is just in the sense which it will be counted/plotted first) but [**we don't have (yet) an ordinal variable**]{.hl-purple}


```{r}
party_fct$party < "SUMAR"
```

. . .

What if we want to [**define a qualitative variable ORDINAL**]{.hl-yellow}? Inside `factor()` we must indicate that `ordered = TRUE`.

```{r}
marks <- c("A", "E", "F", "B", "A+", "A", "C", "C", "D", "B", "A", "C", "C", "E", "F", "D", "A+")
marks_database <-
  tibble("student" = 1:length(marks),
         "marks" =
           factor(marks, levels = c("F", "E", "D", "C", "B", "A", "A+"),
                  ordered = TRUE))
marks_database |> pull(marks)
```

---

## Quali: factors

What changes? If you notice now, although the variable is still qualitative, we can [**make comparisons and order the records**]{.hl-yellow} because there is a [**hierarchy**]{.hl-purple} between the modalities.

```{r}
marks_database |> filter(marks >= "B")
```

---

## Quali: factors


:::: columns
::: {.column width="45%"}

If we want to tell it to [**drop an unused level**]{.hl-yellow} at that moment (and that we want to [**exclude from the definition**]{.hl-purple}) we can do it with `fct_drop()`.

```{r}
marks_database |> 
  filter(marks %in% c("F", "E", "D", "C", "B", "A")) |> 
  pull(marks)
```

:::

::: {.column width="55%"}


```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/drop_factor.jpg")
``` 

:::

::::

```{r}
marks_database |> 
  filter(marks %in% c("F", "E", "D", "C", "B", "A")) |> 
  mutate(marks = fct_drop(marks)) |>  
  pull(marks)
```

---

## Quali: factors


:::: columns
::: {.column width="45%"}


Just as we can delete levels we can [**expand existing levels**]{.hl-yellow} (even if there is no data for that level at that time) with `fct_expand()`.

:::

::: {.column width="55%"}


```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factor_expand.jpg")
``` 

:::
::::

```{r}
marks_database |> 
  mutate(marks = fct_expand(marks, c("F-", "A+", "A++"))) %>% 
  pull(marks)
```

---

## Quali: factors

:::: columns
::: {.column width="45%"}

In addition with `fct_explicit_na()` we can [**assign a level to the missing values**]{.hl-yellow} to be included in the analysis and visualizations.

:::

::: {.column width="55%"}


```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factor_explicit.jpg")
``` 

:::
::::

```{r}
fct_explicit_na(factor(c("a", "b", NA)))
```

---

## Quali: factors

Even once defined we can [**reorder the levels**]{.hl-yellow} with `fct_relevel()`.


```{r}
marks_database_expand <- 
  marks_database |>  
  mutate(marks = fct_expand(marks, c("F-", "A+", "A++"))) |> 
  pull(marks)

marks_database_expand |> 
  fct_relevel(c("F-", "F", "E", "D", "C", "B", "A", "A+", "A++"))
  
```


---

## Quali: factors

:::: columns
::: {.column width="55%"}

This way of working with qualitative variables allows us to give a [**theoretical definition**]{.hl-yellow} of our database, and we can even count values that do not yet exist (but could), making use of `fct_count()`.

:::

::: {.column width="45%"}


```{r echo = FALSE,  out.width = "70%", fig.align = "left"}
knitr::include_graphics("./img/fct_count.jpg")
``` 

:::
::::

```{r}
marks_database |> 
  mutate(marks = fct_expand(marks, c("F-", "A+", "A++"))) |> 
  pull(marks) |> 
  fct_count()
```


---

## Quali: factors

The levels can also be [**sorted by frequency**]{.hl-yellow} with `fct_infreq()`.

```{r}
marks_database |> 
  mutate(marks = fct_infreq(marks)) |> 
  pull(marks)

marks_database |> 
  mutate(marks = fct_infreq(marks)) |> 
  pull(marks) |> 
  fct_count()
```

---

## Quali: factors


Sometimes we will want to [**group levels**]{.hl-yellow}, for example, not allowing levels that [**do not happen a minimum number of times**]{.hl-yellow} with `fct_lump_min(..., min = ..)` (observations that do not meet this will go to a **generic level** called `Other`, although this can be changed with the `other_level` argument). 

:::: columns
::: {.column width="50%"}


```{r}
marks_database |> 
  pull(marks) %>% 
  fct_lump_min(min = 3)
```

:::

::: {.column width="50%"}


```{r}
marks_database |> 
  pull(marks) |>
  fct_lump_min(min = 3,
               other_level = "Less frequent")
```

:::
::::

---

## Quali: factors


We can do something equivalent but based on its [**relative frequency**]{.hl-yellow} with `fct_lump_prop()`.


```{r}
marks_database |> 
  pull(marks) |> 
  fct_lump_prop(prop = 0.15,
                other_level = "less frequent")
```

---


## Quali: factors

We can apply this to our datasets to [**recategorize variables**]{.hl-yellow} very quickly.

```{r}
starwars |>  
  drop_na(species) |> 
  mutate(species =
           fct_lump_min(species, min = 3,
                        other_level = "Others")) |>  
  count(species)
```

---

## Quali: factors



With `fct_reorder()` we can also indicate that we want to [**order the factors**]{.hl-yellow} according to a function applied to another variable.


```{r}
starwars_factor <- 
  starwars |>  
  drop_na(height, species) |> 
  mutate(species =
           fct_lump_min(species, min = 3,
                        other_level = "Others"))
```

:::: columns
::: {.column width="50%"}


```{r}
starwars_factor |>  pull(species)
```

:::

::: {.column width="50%"}


```{r}
starwars_factor |> 
  mutate(species = fct_reorder(species, height, mean)) |> 
  pull(species)
```

:::
::::


---

## ğŸ’» It's your turn {#tu-turno-8-2}


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

ğŸ“ Given the variable `months` defined below (defined as a character vector), convert this variable to factor (just that)

```{r}
months <- c("Jan", "Feb", "Mar", "Apr")
```

```{r}
#| code-fold: true
#| eval: false
months <- c("Jan", "Feb", "Mar", "Apr")
months_fct <- as_factor(months)
months_fct
```

### [**Exercise 2**]{.hl-yellow}

ğŸ“ Given the variable `months` defined below converts this variable to a factor but indicating the levels correctly.

```{r}
months <- c(NA, "Apr", "Jan", "Oct", "Jul", "Jan", "Sep", NA, "Feb", "Dic",
           "Jul", "Mar", "Jan", "Mar", "Feb", "Apr", "May", "Oct", "Sep",  NA,
           "Dic", "Jul", "Nov", "Feb", "Oct", "Jun", "Sep", "Oct", "Oct", "Sep")
```



```{r}
#| code-fold: true
#| eval: false
months_fct <-
  factor(months,
         levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dic"))
months_fct
```

  
### [**Exercise 3**]{.hl-yellow}

ğŸ“ Count how many values there are for each month but keep in mind that they are factors (maybe there are unused levels and you should get a 0 for them).


```{r}
#| code-fold: true
#| eval: false
meses_fct |>  fct_count()
```

### [**Exercise 4**]{.hl-yellow}

ğŸ“ Since there are missing values, it indicates that the absentee is a thirteenth level labeled `"missing"`.

```{r}
#| code-fold: true
#| eval: false
months_fct <- 
  months_fct |> 
  fct_explicit_na(na_level = "missing")
months_fct
```

### [**Exercise 5**]{.hl-yellow}

ğŸ“ Removes unused levels.


```{r}
#| code-fold: true
#| eval: false
months_fct <- 
  months_fct %>%
  fct_drop()
months_fct
```


### [**Exercise 6**]{.hl-yellow}

ğŸ“ Sort the levels by frequency of occurrence.


```{r}
#| code-fold: true
#| eval: false
months_fct |> 
  fct_infreq()
```

### [**Exercise 7**]{.hl-yellow}

ğŸ“ Group levels so that any level that does not appear at least 7% of the time is grouped in a level called `"other months"`.
  
```{r}
#| code-fold: true
#| eval: false
months_fct <-
  months_fct |> 
  fct_lump_prop(prop = 0.07, other_level = "other months")
months_fct 
```

:::

---

## ğŸ£ Case study II: ... {#caso-practico-8-2}

# L9: [dbplyr and github]{.flow} {#clase-9}

---

## dbplyr: SQL connection


We are going to introduce the `{dbplyr}` package, which will allow us to combine `SQL` code into `R` to perform [**database queries**]{.hl-yellow}

```{r}
#| eval: false
install.packages("dbplyr")
```

&nbsp;

If you are using R to do data analysis, most of the data you need probably already lives in a database. We will learn how to [**load data in to a local database**]{.hl-yellow}.


---

## dbplyr: SQL connection

```{r}
#| eval: false
install.packages("RSQLite")
```


We will also need to install a [**DBI backend package**]{.hl-yellow} (an interface that allows `{dplyr}` to work with many different databases using the same code). Five commonly used backends are:

* `RMariaDB` connects to MySQL and MariaDB

* `RPostgres` connects to Postgres and Redshift.

* `RSQLite` embeds a SQLite database.

* `odbc` connects to many commercial databases via the open database connectivity protocol.

* `bigrquery` connects to Googleâ€™s BigQuery.

. . .

In the following, we are going to use the [**RSQLite backend**]{.hl-yellow} (automatically installed when you install `{dbplyr}`).

---

## dbplyr: SQL connection

If we want to [**work with a database adopting dplyr grammar**]{.hl-yellow}, we must first connect to it. The connection will be done by using `DBI::dbConnect()`. The arguments to `DBI::dbConnect()` vary from database to database, but the first argument is always the database backend. SQLite only needs a path to the database. 


```{r}
connection <- DBI::dbConnect(RSQLite::SQLite(), dbname = ":memory:")
connection
```

Here, the string `":memory:"` is a special path that creates [**a temporary in-memory database**]{.hl-yellow}.

---

## dbplyr: SQL connection

The temporary database previously created has no yet data in it. We will [**copy an existing database**]{.hl-yellow} (for example, `gapminder` from `{gapminder}` package) using `copy_to()`. Using `tbl()` we "obtain" the database (called as named in `copy_to()`).

The main difference is that not it is a [**remote source in a SQLite database**]{.hl-yellow}.

```{r}
copy_to(connection, gapminder::gapminder, overwrite = TRUE, name = "gapminder_database")
gapminder_db <- tbl(connection, "gapminder_database")
gapminder_db
```

---

## dbplyr: SQL connection


The main goal of `{dbplyr}` is to [**automatically generate SQL from `dplyr` grammar**]{.hl-yellow} that we are already familiar with.

```{r}
gapminder_db |>
  select(country, year, lifeExp)
```

---

## dbplyr: SQL connection



The most important difference between ordinary tibbles and remote database queries is that now [**our `R` code is translated into SQL and executed in the database on the remote server**]{.hl-yellow}, not in R on your local machine: it never pulls data into R unless you explicitly ask for it, [**delaying doing any work until the last possible moment**]{.hl-purple} (sends it to the database in one step).

. . .

It is not [**until we ask for the data**]{.hl-yellow} (writing `gapminder_query` in console, for example), `dplyr` verbs generates the SQL and requests the results from the database. 

```{r}
gapminder_query <- 
  gapminder_db |>
  select(country, year, lifeExp)
gapminder_query
```

---

## dbplyr: SQL connection

**What is happening behind the scenes?**

. . . 

`{dplyr} ` is [**translating our R code into SQL verbs**]{.hl-yellow}, that we can check (without doing) by using `show_query()`

```{r}
gapminder_query |> 
  show_query()
```

---

## dbplyr: SQL connection

As commented, our remote database queries is not in R on your local machine: it never pulls data into R unless you explicitly ask for it. To do it, you can iterate a few times before you figure out what data you need, and then we use `collect()`.

```{r}
gapminder_tibble <-
  gapminder_query |> 
  collect()
gapminder_tibble
```

---

## dbplyr: SQL connection

You can also use `translate_sql()` to translate individual expressions from `dplyr` to SQL

```{r}
dbplyr::translate_sql((x + y) / 2, con = connection)
```

